{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import scipy.sparse\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression as lm\n",
    "from scipy import stats\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize, punkt\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import matplotlib.collections as plt1\n",
    "import matplotlib.pyplot as plt2\n",
    "from matplotlib.legend_handler import HandlerLineCollection, HandlerTuple\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import spacy\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frame with only labeled abstracts\n",
    "df_lab = pd.read_csv(\"/home/kno5cac/git/publicrd/data/prd/Digital_abstract_labelled/labelled_abstracts.csv\")\n",
    "\n",
    "#data frame with all of the abstracts\n",
    "df = pd.read_pickle(\"/home/kno5cac/git/publicrd/data/prd/Paper/FR_meta_and_final_tokens_23DEC21.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Null Abstracts. Reset the index and create a variable index to link with PROJECT_ID\n",
    "df = df[~df.ABSTRACT.isnull()]\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df['index'] = df.index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = df_lab[['PROJECT_ID','ABSTRACT','Is it related to Big-Data','label']]\n",
    "df_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with the labelled data using PROJECT_ID.\n",
    "df['PROJECT_ID'] = pd.to_numeric(df['PROJECT_ID'])\n",
    "df_merge = df.merge(df_lab[['PROJECT_ID','Is it related to Big-Data','label']], how='left', on='PROJECT_ID')\n",
    "len(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save project ID of labelled data\n",
    "project_id_lab = list(df_lab['PROJECT_ID'])\n",
    "\n",
    "# Get the index of labelled abstract\n",
    "subset_df = df_merge.loc[df_merge['PROJECT_ID'].isin(project_id_lab),['index', 'PROJECT_ID']]\n",
    "index_lab = list(subset_df['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Doc2Vec approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Vectorize, build the training and test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = df['ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicies = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]\n",
    "#tagged_df = pd.DataFrame(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose k - number of abstracts for analysis\n",
    "k = 200000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating subset of dataset\n",
    "data = df['ABSTRACT']\n",
    "df = df[0:k]\n",
    "data = data[0:k,]\n",
    "indicies = data.index\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]\n",
    "tagged_df = pd.DataFrame(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing indexes that are inside the range 0-2000000\n",
    "m = 0 \n",
    "for i in index_lab:\n",
    "        if i < k:\n",
    "            m = m + 1\n",
    "            \n",
    "\n",
    "index_lab = index_lab[0:m]\n",
    "project_id_lab = project_id_lab[0:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Doc2Vec model and train using labelled data\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=100, epochs=100) #min_count=2 - min number of times it shows up\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Doc2Vec model\n",
    "model = Doc2Vec.load(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = []\n",
    "for i in range(0, len(tagged_df)):\n",
    "    vectorthis = (model.dv[tagged_df['tags'][i]]).tolist()\n",
    "    vector.append(vectorthis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = []\n",
    "for i in vector:\n",
    "    for x in i:\n",
    "        mat.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.DataFrame(mat)\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model on labeled and whole corpus\n",
    "trainingnp = training.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training and test sample: randomly select 80% of index_lab as training and the rest as test\n",
    "import random\n",
    "\n",
    "# Build the index for the training and the test\n",
    "index_training = random.sample(index_lab, int(0.8 * len(index_lab)))\n",
    "index_test = list(set(index_lab) - set(index_training))\n",
    "\n",
    "# sort those index (sort help to extract the Y value for each set)\n",
    "index_training.sort()\n",
    "index_test.sort()\n",
    "\n",
    "# convert to lists\n",
    "index_training = list(index_training)\n",
    "index_test = list(index_test)\n",
    "\n",
    "# Extract those index in the Doc2Vec matrix and compute the X training and Test\n",
    "X_train_doc2vec = [mat[i] for i in index_training]\n",
    "X_test_doc2vec = [mat[i] for i in index_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Y for training and test using the index order from the sampling\n",
    "Y_train_doc2vec = [df_merge.loc[df_merge['index']== i,'label'].values.tolist() for i in index_training]\n",
    "Y_train_doc2vec = sum(Y_train_doc2vec, [])\n",
    "\n",
    "Y_test_doc2vec = [df_merge.loc[df_merge['index']== i,'label'].values.tolist() for i in index_test]\n",
    "Y_test_doc2vec = sum(Y_test_doc2vec, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neighbors\n",
    "k = int(math.sqrt(len(Y_train_doc2vec)))\n",
    "print('Number of neighbors:', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors= k)\n",
    "classifier.fit(X_train_doc2vec,Y_train_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification\n",
    "Y_pred_doc2vec = classifier.predict(X_test_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(Y_test_doc2vec, Y_pred_doc2vec)\n",
    "#print(confusion)\n",
    "print(classification_report(Y_test_doc2vec, Y_pred_doc2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "ax = sns.heatmap(confusion, annot=labels, fmt='', cmap='Blues')\n",
    "ax.set_title('KNN Confusion Matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt2.show()\n",
    "plt2.savefig('doc2vec_KNN.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification for the whole data: use the whole Doc2Vec\n",
    "Y_doc2vec = classifier.predict(mat)\n",
    "\n",
    "# The Doc2Vec keep the order from index. Just add the prediction as new variable\n",
    "df['Prediction_KNN'] = Y_doc2vec\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of projects that is Big data related\n",
    "df_bigdata = df[df['Prediction_KNN']=='Big-data']\n",
    "print('Number of abstracts related to Big data:', len(df_bigdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_pal = {\"blue\":'#377eb8', \"orange\":'#ff7f00', \"green\":'#4daf4a', \"pink\":'#f781bf', \"brown\":'#a65628', \n",
    "          \"purple\":'#984ea3', \"gray\":'#999999', \"red\":'#e41a1c', \"yellow\":'#dede00'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution over time and agencies\n",
    "df_bigdata[\"FY\"] = df_bigdata[\"FY\"].astype('int')\n",
    "year_counts = df_bigdata['FY'].value_counts().sort_index(ascending=True)\n",
    "\n",
    "# Distribution\n",
    "year = year_counts.index.tolist()\n",
    "count = year_counts.values\n",
    "\n",
    "fig = plt2.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_axisbelow(True)\n",
    "plt2.grid(True, color = \"whitesmoke\")\n",
    "plt2.bar(year, count, color='navy')\n",
    "#plt.xlim(-0.7, len(year)-0.3)\n",
    "plt2.xlim(2007.3,2020.7)\n",
    "plt2.xticks(year, rotation=45)\n",
    "ax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\n",
    "#x_ticks = ax.xaxis.get_major_ticks()\n",
    "#x_ticks[-1].label1.set_visible(False)\n",
    "plt2.xlabel(\"FY\")\n",
    "plt2.ylabel(\"Number of Projects\")\n",
    "plt2.title(\"Big data sample\")\n",
    "\n",
    "plt2.savefig(\"big_data_time.png\", dpi = 800, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_counts = 100*df_bigdata[\"DEPARTMENT\"].value_counts()/len(df_bigdata)\n",
    "agency = agency_counts.index.tolist()\n",
    "count = agency_counts.values\n",
    "\n",
    "fig = plt2.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_axisbelow(True)\n",
    "plt2.grid(True, color = \"whitesmoke\")\n",
    "plt2.bar(agency, count, color=cb_pal['blue'])\n",
    "plt2.ylim(0,100)\n",
    "plt2.xlabel(\"Agency\")\n",
    "plt2.ylabel(\"Percent of Dataset\")\n",
    "plt2.title(\"Project Distribution by Funding Agency\")\n",
    "\n",
    "plt2.savefig(\"big_data_agency.png\", dpi = 800, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "#df_bigdata.to_csv(\"/project/biocomplexity/sdad/projects_data/ncses/prd/Digital_abstract_labelled/doc2vec_method.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run SVM with default parameters provides by Sklearn. We train the model\n",
    "from sklearn import svm\n",
    "classifier_svm = svm.SVC()\n",
    "classifier_svm.fit(X_train_doc2vec,Y_train_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification\n",
    "Y_pred_doc2vec = classifier_svm.predict(X_test_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(Y_test_doc2vec, Y_pred_doc2vec)\n",
    "#print(confusion)\n",
    "print(classification_report(Y_test_doc2vec, Y_pred_doc2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "ax = sns.heatmap(confusion, annot=labels, fmt='', cmap='Blues')\n",
    "ax.set_title('KNN Confusion Matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt2.show()\n",
    "plt2.savefig('doc2vec_SVM.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification for the whole data: use the whole Doc2Vec\n",
    "Y_doc2vec = classifier_svm.predict(mat)\n",
    "\n",
    "# The Doc2Vec keep the order from index. Just add the prediction as new variable\n",
    "df['Prediction_SVM'] = Y_doc2vec\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross comparision between SVM and KNN\n",
    "pd.crosstab(df['Prediction_KNN'], df['Prediction_SVM'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default parameters provides by SKLearn and train the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier_DT = DecisionTreeClassifier()\n",
    "classifier_DT.fit(X_train_doc2vec,Y_train_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification\n",
    "Y_pred_doc2vec = classifier_DT.predict(X_test_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(Y_test_doc2vec, Y_pred_doc2vec)\n",
    "#print(confusion)\n",
    "print(classification_report(Y_test_doc2vec, Y_pred_doc2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "ax = sns.heatmap(confusion, annot=labels, fmt='', cmap='Blues')\n",
    "ax.set_title('KNN Confusion Matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt2.show()\n",
    "plt2.savefig('doc2vec_DT.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification for the whole data: use the whole Doc2Vec\n",
    "Y_doc2vec = classifier_DT.predict(mat)\n",
    "\n",
    "# The Doc2Vec keep the order from index. Just add the prediction as new variable\n",
    "df['Prediction_DT'] = Y_doc2vec\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross comparision between NN and SVM\n",
    "pd.crosstab(df['Prediction_DT'], df['Prediction_SVM'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross comparision between NN and KNN\n",
    "pd.crosstab(df['Prediction_DT'], df['Prediction_KNN'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default parameters provides by SKLearn and train the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_RF = RandomForestClassifier()\n",
    "classifier_RF.fit(X_train_doc2vec,Y_train_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification\n",
    "Y_pred_doc2vec = classifier_RF.predict(X_test_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(Y_test_doc2vec, Y_pred_doc2vec)\n",
    "#print(confusion)\n",
    "print(classification_report(Y_test_doc2vec, Y_pred_doc2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "ax = sns.heatmap(confusion, annot=labels, fmt='', cmap='Blues')\n",
    "ax.set_title('KNN Confusion Matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt2.show()\n",
    "plt2.savefig('doc2vec_RF.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification for the whole data: use the whole Doc2Vec\n",
    "Y_doc2vec = classifier_RF.predict(mat)\n",
    "\n",
    "# The Doc2Vec keep the order from index. Just add the prediction as new variable\n",
    "df['Prediction_RF'] = Y_doc2vec\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross comparision between RF and DT\n",
    "pd.crosstab(df['Prediction_RF'], df['Prediction_DT'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross comparision between RF and SVM\n",
    "pd.crosstab(df['Prediction_RF'], df['Prediction_SVM'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross comparision between RF and SVM\n",
    "pd.crosstab(df['Prediction_RF'], df['Prediction_KNN'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default parameters provides by SKLearn and train the model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier_nn = MLPClassifier()\n",
    "classifier_nn.fit(X_train_doc2vec,Y_train_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification\n",
    "Y_pred_doc2vec = classifier_nn.predict(X_test_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(Y_test_doc2vec, Y_pred_doc2vec)\n",
    "#print(confusion)\n",
    "print(classification_report(Y_test_doc2vec, Y_pred_doc2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "ax = sns.heatmap(confusion, annot=labels, fmt='', cmap='Blues')\n",
    "ax.set_title('KNN Confusion Matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt2.show()\n",
    "plt2.savefig('doc2vec_NN.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification for the whole data: use the whole Doc2Vec\n",
    "Y_doc2vec = classifier_nn.predict(mat)\n",
    "\n",
    "# The Doc2Vec keep the order from index. Just add the prediction as new variable\n",
    "df['Prediction_NN'] = Y_doc2vec\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross comparision between NN and KNN\n",
    "pd.crosstab(df['Prediction_NN'], df['Prediction_KNN'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross comparision between NN and SVM\n",
    "pd.crosstab(df['Prediction_NN'], df['Prediction_SVM'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross comparision between NN and DT\n",
    "pd.crosstab(df['Prediction_NN'], df['Prediction_DT'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross comparision between NN and RF\n",
    "pd.crosstab(df['Prediction_NN'], df['Prediction_RF'], margins=True, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "df.to_csv(\"/project/biocomplexity/sdad/projects_data/ncses/prd/Digital_abstract_labelled/FR_final_predicted_doc2vec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Decision rule based on all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a score to be identify as big data\n",
    "df = pd.read_csv(\"/project/biocomplexity/sdad/projects_data/ncses/prd/Digital_abstract_labelled/FR_final_predicted_doc2vec.csv\")\n",
    "df['score'] = np.where(df['Prediction_KNN'].str.contains(\"Non Big-data\"), 0, 1) + np.where(df['Prediction_SVM'].str.contains(\"Non Big-data\"), 0, 1) + np.where(df['Prediction_DT'].str.contains(\"Non Big-data\"), 0, 1) + np.where(df['Prediction_RF'].str.contains(\"Non Big-data\"), 0, 1) + np.where(df['Prediction_NN'].str.contains(\"Non Big-data\"), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of abstracts\n",
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used a rule (majority votes from classifiers) to identify Big-data abstracts. Useful because we have an impair number of classifier\n",
    "df['Big_data'] = 0\n",
    "df.loc[df['score']>2,'Big_data'] = 1\n",
    "df['Big_data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the data to big-data and save\n",
    "df_bigdata = df[df['Big_data']==1]\n",
    "df_bigdata.to_csv(\"/project/biocomplexity/sdad/projects_data/ncses/prd/Digital_abstract_labelled/abstracts_classification_big_data_doc2vec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics of our Big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution over time and agencies\n",
    "df_bigdata[\"FY\"] = df_bigdata[\"FY\"].astype('int')\n",
    "year_counts = df_bigdata['FY'].value_counts().sort_index(ascending=True)\n",
    "\n",
    "# Distribution\n",
    "year = year_counts.index.tolist()\n",
    "count = year_counts.values\n",
    "\n",
    "fig = plt2.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_axisbelow(True)\n",
    "plt2.grid(True, color = \"whitesmoke\")\n",
    "plt2.bar(year, count, color='navy')\n",
    "#plt.xlim(-0.7, len(year)-0.3)\n",
    "plt2.xlim(2007.3,2020.7)\n",
    "plt2.xticks(year, rotation=45)\n",
    "ax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\n",
    "#x_ticks = ax.xaxis.get_major_ticks()\n",
    "#x_ticks[-1].label1.set_visible(False)\n",
    "plt2.xlabel(\"FY\")\n",
    "plt2.ylabel(\"Number of Projects\")\n",
    "plt2.title(\"Big data sample\")\n",
    "\n",
    "plt2.savefig(\"big_data_time.png\", dpi = 800, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_counts = 100*df_bigdata[\"DEPARTMENT\"].value_counts()/len(df_bigdata)\n",
    "agency = agency_counts.index.tolist()\n",
    "count = agency_counts.values\n",
    "\n",
    "fig = plt2.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_axisbelow(True)\n",
    "plt2.grid(True, color = \"whitesmoke\")\n",
    "plt2.bar(agency, count, color=cb_pal['blue'])\n",
    "plt2.ylim(0,100)\n",
    "plt2.xlabel(\"Agency\")\n",
    "plt2.ylabel(\"Percent of Dataset\")\n",
    "plt2.title(\"Project Distribution by Funding Agency\")\n",
    "\n",
    "plt2.savefig(\"big_data_agency.png\", dpi = 800, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
