{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pickle\n",
    "import time\n",
    "import joblib\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import islice\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "from gensim.matutils import hellinger\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "\n",
    "# Create a new document term matrix using the topic distribution\n",
    "def create_matrix(windows_H, windows_terms):\n",
    "    \"\"\"\n",
    "    Create the topic-term matrix from all window topics that have been added so far.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    windows_H: windiws topic distribution of top n words\n",
    "    windows_terms: windows terms used for each fiscal year\n",
    "    \"\"\"\n",
    "    # Set a list of all terms unique terms across windows (all_terms) and the combine windows terms (all_windows_terms)\n",
    "    all_windows_terms = sum(windows_terms,[])\n",
    "    \n",
    "    # Create a block diagonal matrix of all topics: the number of rows is the same as the length of list_terms\n",
    "    M = block_diag(*windows_H)\n",
    "    \n",
    "    # Identify duplicated terms (columns) and sum them\n",
    "    # The fastest way is to transform M into data frame with\n",
    "    dfM = pd.DataFrame(data = M, columns=all_windows_terms).groupby(level=0, axis=1).sum()\n",
    "    \n",
    "    # Transform back the dataframe to matrix and get the variable names (in the order in the matrix) as the final all terms\n",
    "    M_concat = dfM.to_numpy()\n",
    "    all_terms = list(dfM.columns)\n",
    "    \n",
    "    \n",
    "    print('--- New document-terms have been created ---')\n",
    "    \n",
    "    return M_concat, all_terms\n",
    "\n",
    "\n",
    "\n",
    "# Track the dynamic of a given topic (option topic)\n",
    "def track_dynamic(topic,W,windows_topic_list):\n",
    "    \"\"\"\n",
    "    Link topics in the first stage with topic in second stage using the matrix W\n",
    "    Parameters:\n",
    "    ----------\n",
    "    topic: topic to track the dynamic\n",
    "    W: weigth matrix from the second stage\n",
    "    windows_topic_list: topic list from the first stage\n",
    "    \"\"\"\n",
    "    # For each topic from the first stage (rows) find the topic in the second stage (columns) with the higher weight\n",
    "    topic_second = []\n",
    "    for i, topic_first in enumerate(W):\n",
    "        topic_second.append(topic_first.argmax())\n",
    "        \n",
    "    # Split topics classification in the first by year\n",
    "    it = iter(topic_second)\n",
    "    topic_first_year = [[next(it) for _ in range(size)] for size in windows_topic]\n",
    "    \n",
    "    # For each topic, identify the correspondance for each year\n",
    "    dynamic_topic_list = []\n",
    "    for y in range(0, len(year)):\n",
    "        topic_year = [i for i, e in enumerate(topic_first_year[y]) if e == topic]\n",
    "        dynamic_topic_list.append(topic_year)\n",
    "\n",
    "    # Compute the list of list of topics (list of year and list of main topic)\n",
    "    dynamic_topic = []\n",
    "    for y in range(0, len(year)):\n",
    "        dynamic_list = dynamic_topic_list[y]\n",
    "        fy_topic = [windows_topic_list[y][dynamic_list[i]] for i in range(0,len(dynamic_list))] \n",
    "        dynamic_topic.append(fy_topic)\n",
    "        \n",
    "    # Print the result in a dataframe\n",
    "    topic_print = []\n",
    "    names = []\n",
    "\n",
    "    # print the dynamic topic\n",
    "    for y in range(0,len(year)):\n",
    "        for t in range(0,len(dynamic_topic[y])):\n",
    "            topic_print.append(dynamic_topic[y][t])\n",
    "            names.append('Year_'+str(year[y])+'_'+str(t))\n",
    "        \n",
    "    df = pd.DataFrame (topic_print).transpose()\n",
    "    df.columns = names\n",
    "    \n",
    "    return df, dynamic_topic_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new term-document matrix: Combining all the top term from the windiws nmf\n",
    "path = '/project/biocomplexity/sdad/projects_data/ncses/prd/Dynamic_Topics_Modelling/nmf_fullabstract/'\n",
    "batch = 7\n",
    "n_topics = list(range(20,61,5))\n",
    "\n",
    "windows_topic_list = []\n",
    "windows_W = []\n",
    "windows_H = []\n",
    "windows_terms = []\n",
    "\n",
    "# Build the windows H matrix\n",
    "for fy in year:\n",
    "    # Upload the nmf model \n",
    "    (nmf_time,topics_list,W_list,H_list) = joblib.load( path+'nmf_out/windows_nmf'+str(fy)+'.pkl' )\n",
    "    \n",
    "    # Upload model from the first stage\n",
    "    (model, max_coherence) = joblib.dump( '/project/biocomplexity/sdad/projects_data/ncses/prd/Dynamic_Topics_Modelling/nmf_fullabstract/first_stage.pkl' )\n",
    "\n",
    "    # Build the list of terms for all topics (top_n) in a given fiscal year\n",
    "    k = model(year.index(select_year))\n",
    "    index = n_topics.index(k)\n",
    "    fy_topic_list = topics_list[index]\n",
    "    \n",
    "    # Get the H and W matrix for the model\n",
    "    W = W_list[index]\n",
    "    H = H_list[index]\n",
    "        \n",
    "    # select the index of terms that appear in the topics and subset the matrix H to those terms\n",
    "    topic_terms = list(set(sum(fy_topic_list,[])))\n",
    "    indcol = [terms.index(i) for i in topic_terms]\n",
    "    subH = H[:,indcol]\n",
    "        \n",
    "    # For each topic (rows) set the weigth of terms that are not listed the topic to 0.\n",
    "    for i,j in enumerate(subH):\n",
    "        # by row find the index of top_n terms\n",
    "        indtopic = [topic_terms.index(p) for p in fy_topic_list[i]]\n",
    "        notop = [k for k in range(len(topic_terms)) if k not in indtopic]\n",
    "        j[notop]=0\n",
    "\n",
    "    # append the result\n",
    "    windows_topic_list.append(fy_topic_list)\n",
    "    windows_topic.append(topic_select)\n",
    "    windows_W.append(W)\n",
    "    windows_H.append(subH)\n",
    "    windows_terms.append(topic_terms)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Build the new document-term matrix M\n",
    "(M, all_terms) = create_matrix(windows_H, windows_terms)\n",
    "    \n",
    "# Run am nmf model from the new document term matrix\n",
    "(nmf_time,topics_list,W_list,H_list) = nmf_models(doc_term_matrix=M, n_topics=n_topics, vectorizer=all_terms, rand_start = (batch)*len(n_topics))\n",
    "\n",
    "# Save the result for the second nmf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
