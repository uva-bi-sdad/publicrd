{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import joblib\n",
    "import gensim\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to list topic (modified function from https://nlpforhackers.io/topic-modeling/)\n",
    "def list_topics(topic_term_dist, vectorizer, top_n=10):\n",
    "\n",
    "    #input. top_n: how many words to list per topic.  If -1, then list all words.  \n",
    "    topic_words = []\n",
    "    \n",
    "    for idx, topic in enumerate(topic_term_dist):  # loop through each row of H.  idx = row index.  topic = actual row\n",
    "            \n",
    "        if top_n == -1: \n",
    "            # check if the vectorized has an attribute get_features_names. if not vectorized contains terms hasattr('abc', 'lower')\n",
    "            if hasattr(vectorizer, 'get_feature_names'):\n",
    "                topic_words.append([vectorizer.get_feature_names()[i] for i in topic.argsort()[::-1]])\n",
    "            else:\n",
    "                topic_words.append([vectorizer[i] for i in topic.argsort()[::-1]])\n",
    "        else:\n",
    "            if hasattr(vectorizer, 'get_feature_names'):\n",
    "                topic_words.append([vectorizer.get_feature_names()[i] for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "            else:\n",
    "                topic_words.append([vectorizer[i] for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        \n",
    "    return topic_words\n",
    "\n",
    "\n",
    "# function to solve the nmf (modified from https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/)\n",
    "def nmf_models(doc_term_matrix, n_topics, vectorizer, rand_start):\n",
    "    \"\"\"\n",
    "    Compute NMF model, save topics list for coherence calc\n",
    "    Parameters:\n",
    "    ----------\n",
    "    doc_term_matrix: document-terms matrix\n",
    "    n_topics: list of topics number\n",
    "    vectorizer: vector of terms\n",
    "    rand_start: random seed\n",
    "    \"\"\"\n",
    "    \n",
    "    nmf_time = []\n",
    "    topics_list = []\n",
    "    W_list = []\n",
    "    H_list = []\n",
    "    \n",
    "    i = rand_start\n",
    "    for num_topics in n_topics:\n",
    "\n",
    "        # create model\n",
    "        t1 = time.time()\n",
    "        nmf_model = NMF(n_components=num_topics, random_state = i)\n",
    "        nmf_model.fit_transform(doc_term_matrix)\n",
    "        t2 = time.time()\n",
    "        nmf_time.append(t2-t1)\n",
    "        #print(f\"  Model time: {t2-t1}\", flush=True)\n",
    "        \n",
    "        # create list of topics\n",
    "        topics = list_topics(nmf_model.components_, vectorizer, top_n=10)\n",
    "        topics_list.append(topics)\n",
    "        \n",
    "        # output completion message\n",
    "        i = i+1\n",
    "        #print('Number of topics =', num_topics, \"complete.\", flush=True)\n",
    "        \n",
    "        # save the matrix W and H\n",
    "        W = nmf_model.fit_transform(doc_term_matrix)\n",
    "        W_list.append(W)\n",
    "        H = nmf_model.components_\n",
    "        \n",
    "        # truncate the H matrix: set the weight of the non top n words to zero\n",
    "        #top_n = 10\n",
    "        #for idx, topic in enumerate(H):\n",
    "        #    thresold = numpy.nanmin(topic[topic.argsort()[:-top_n-1:-1]])\n",
    "        #    topic[topic<thresold]=0  \n",
    "        H_list.append(H)\n",
    "\n",
    "    return nmf_time, topics_list, W_list, H_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "df = pd.read_pickle(\"/project/biocomplexity/sdad/projects_data/ncses/prd/Paper/FR_meta_and_final_tokens_23DEC21.pkl\")\n",
    "df.head()\n",
    "\n",
    "# Compute the time variable\n",
    "year = df['FY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an nmf model for each fiscal year\n",
    "del df\n",
    "path = '/project/biocomplexity/sdad/projects_data/ncses/prd/Dynamic_Topics_Modelling/nmf_fullabstract/'\n",
    "n_topics = list(range(20,61,5))\n",
    "batch = 7\n",
    "\n",
    "for fy in year[2:len(year)]:\n",
    "    # Load the document-terms matrix for a given fiscal year and solve the nmf model\n",
    "    (tf_idf,tfidf_vectorizer,docs) = joblib.load( path+'Term_docs_'+str(fy)+'.pkl' )\n",
    "            \n",
    "    (nmf_time, topics_list, W_list, H_list) = nmf_models(doc_term_matrix=tf_idf, n_topics=n_topics, vectorizer=tfidf_vectorizer, rand_start = (batch)*len(n_topics))\n",
    "\n",
    "    # save output for the first stage\n",
    "    joblib.dump((nmf_time,topics_list,W_list,H_list), path+'nmf_out/windows_nmf'+str(fy)+'.pkl' )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
