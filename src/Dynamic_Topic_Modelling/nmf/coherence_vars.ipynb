{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_pickle(\"/project/biocomplexity/sdad/projects_data/ncses/prd/Paper/FR_meta_and_final_tokens_23DEC21.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a new dictionary and corpus\n",
    "def createLDAvars(docs):\n",
    "\n",
    "    # Create the variables needed for LDA from df[final_frqwds_removed]: dictionary (id2word), corpus\n",
    "    \n",
    "    # Create Dictionary\n",
    "    id2word = gensim.corpora.Dictionary(docs)\n",
    "\n",
    "    #Filter words to only those found in at least a set number of documents (min_appearances)\n",
    "    id2word.filter_extremes(no_below=20, no_above=0.6)\n",
    "    \n",
    "    # filter out stop words - \"use\" already filtered out by previous line\n",
    "    id2word.filter_tokens(bad_ids=[id2word.token2id['research'], id2word.token2id['project']])\n",
    "\n",
    "    # Create Corpus (Term Document Frequency)\n",
    "\n",
    "    #Creates a count for each unique word appearing in the document, where the word_id is substituted for the word\n",
    "    # corpus not need for c_v coherence\n",
    "    corpus = [id2word.doc2bow(doc) for doc in docs]\n",
    "\n",
    "    return id2word, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split final tokens into a list of tokens\n",
    "df[\"list_final_tokens\"] = df[\"final_tokens\"].str.split(' ').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build docs, dictionary and corpus\n",
    "docs = df[\"list_final_tokens\"]\n",
    "[dictionary, corpus] = createLDAvars(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "file = open('/project/biocomplexity/sdad/projects_data/ncses/prd/Dynamic_Topics_Modelling/nmf_fullabstract/Coherence/coherence_vars.sav', 'wb')\n",
    "pickle.dump([id2word, docs, year], file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
