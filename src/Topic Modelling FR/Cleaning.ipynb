{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Set up Environment\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "from string import ascii_letters\n",
    "import sys\n",
    "import re\n",
    "#Preprocessing\n",
    "import nltk\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TextCleaning\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns\n",
      "Index(['PROJECT_ID', 'ABSTRACT', 'FY', 'FIRST_CHAR', 'LAST_CHAR', 'DEPARTMENT',\n",
      "       'AGENCY', 'IC_CENTER', 'PROJECT_NUMBER', 'PROJECT_TITLE',\n",
      "       'PROJECT_TERMS', 'CONTACT_PI_PROJECT_LEADER', 'OTHER_PIS',\n",
      "       'ORGANIZATION_NAME', 'CFDA_CODE', 'FY_TOTAL_COST'],\n",
      "      dtype='object')\n",
      "Descriptive Stats\n",
      "         PROJECT_ID             FY  FY_TOTAL_COST\n",
      "count  5.500880e+05  550088.000000   4.256850e+05\n",
      "mean   4.980384e+05    2012.247477   4.509841e+05\n",
      "std    3.262050e+05       3.183765   1.727112e+06\n",
      "min    1.008600e+04    2008.000000   1.000000e+00\n",
      "25%    1.790538e+05    2009.000000   1.390020e+05\n",
      "50%    4.880660e+05    2012.000000   2.917820e+05\n",
      "75%    7.817102e+05    2015.000000   4.500000e+05\n",
      "max    1.101940e+06    2018.000000   3.227983e+08\n",
      "Length\n",
      "550088\n"
     ]
    }
   ],
   "source": [
    "#Visualize data\n",
    "#raw_df=pd.read_csv('/sfs/qumulo/qhome/sc2pg/src/prnd/publicrd/data/prd/DigitalOcean_Backup/public_rd/working/federal_reporter/abstracts_federal_reporter_combined.csv',engine='python')\n",
    "\n",
    "# reading from new link on Rivanna\n",
    "raw_df=pd.read_csv('~/prd/publicrd/data/prd/RND Topic Modelling/abstracts_federal_reporter_combined.csv',engine='python')\n",
    "\n",
    "print('Columns')\n",
    "print(raw_df.columns)\n",
    "print('Descriptive Stats')\n",
    "print(raw_df.describe())\n",
    "print('Length')\n",
    "print(len(raw_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 nulls in  ABSTRACT . These rows removed.\n",
      "11 duplicate abstracts removed\n",
      "0 project ID duplicates - not removed\n"
     ]
    }
   ],
   "source": [
    "df = TextCleaning.remove_nulls(raw_df, \"ABSTRACT\")\n",
    "df = TextCleaning.remove_duplicates(df)\n",
    "df = TextCleaning.create_working_abstract_col(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270 short abstracts removed\n"
     ]
    }
   ],
   "source": [
    "#importlib.reload(TextCleaning)\n",
    "df = TextCleaning.remove_short_abstracts(df,limit=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start phrases to remove\n",
    "\n",
    "start_phrases=['****TECHNICAL ABSTRACT****','****Technical Abstract****',\n",
    "               '****Non Technical Abstract****','*** Non- Technical Abstract ***','**Non-Technical Abstract**',\n",
    "               '*****NON-TECHNICAL ABSTRACT*****','***** NON-TECHNICAL ABSTRACT *****',\n",
    "               '****NONTECHNICAL ABSTRACT****','****Non-Technical Abstract****','*Non-technical Abstract*',\n",
    "               '*****NON-TECHNICAL ABSTRACT*****','****NON-TECHNICAL ABSTRACT****',\n",
    "               '***NON-TECHNICAL ABSTRACT***','****Nontechnical abstract****',\n",
    "               'TECHNICAL SUMMARY', 'NONTECHNICAL SUMMARY','NON-TECHNICAL SUMMARY','Non-technical description',\n",
    "               'DESCRIPTION (Provided by the applicant)','DESCRIPTION (provided by investigator)',  'DESCRIPTION (provided by applicant)',\n",
    "               'Project Summary/Abstract','PROJECT SUMMARY/ABSTRACT',\n",
    "               'ABSTRACT','abstract','Proposal Abstract','Abstract','RESEARCH ABSTRACT',\n",
    "               'PROJECT SUMMARY','Project Summary','SUMMARY','RESEARCH SUMMARY',\n",
    "               'Proposal',\n",
    "               'DESCRIPTION','Description','PROJECT DESCRIPTION'\n",
    "               'NARRATIVE',\n",
    "               '(See instructions):','\\t',\n",
    "              'FOR CENTER APPLICATION (provided by the investigator):','Objective(s)',      'EXCEED THE SPACE PROVIDED',\n",
    "               'Provided by Applicant','Provided by applicant','provided by applicant','PROVIDED BY APPLICANT',\n",
    "               'Provided by Candidate','Provided by candidate','provided by candidate','PROVIDED BY CANDIDATE',\n",
    "              'one page and must contain a summary of the proposed activity suitable for dissemination to thepublic. It should be a self-contained description of the project and should contain a statement of objectives and methods to be employed.It should be informative to other persons working in the same or related fields and insofar as possible understandable to a technically liter-ate lay reader. This Abstract must not include any proprietary/confidential information.* Please click the add attachment button to complete this entry.']\n",
    "\n",
    "wa = 'working_abstract'\n",
    "\n",
    "df[wa]=df[wa].apply(str.lstrip,args=[' ?-_^. :,!;¿|()[]]#%>﻿&\\''])\n",
    "\n",
    "#Remove found phrases\n",
    "for phrase in start_phrases:\n",
    "    df[wa]=df[wa].apply(TextCleaning.remove_phrase,args=[phrase,'Start']).apply(str.lstrip,args=[' :./)'])\n",
    "#Repeated in case the order of project summary/abstract varies\n",
    "for phrase in start_phrases:\n",
    "    df[wa]=df[wa].apply(TextCleaning.remove_phrase,args=[phrase,'Start']).apply(str.lstrip,args=[' :./)'])\n",
    "\n",
    "df[wa]=df[wa].apply(str.lstrip,args=['?-*_^. :,!;=¿|]#%>&-\\t\\n']) #Often, sentences will start with - or *, but they indicate other quality issues and don't end with them,so it's okay to remove them\n",
    "    \n",
    "df.drop(df[df[wa].apply(len)==0].index,axis=0,inplace=True)\n",
    "    \n",
    "# update Start Char column in df\n",
    "df['Start Char']=df[wa].apply(lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(End of Abstract)\n",
      "End of Abstract\n",
      "(Abstract end)(END OF ABSTRACT)\n",
      "(End of abstract.)\n",
      "(Abstract End)\n",
      "(End 0f Abstract)\n",
      "(End of Abstract.)\n",
      "(End of Absract)\n",
      "(Abstract below)\n",
      "(End of Reviewers' Comment)\n",
      "(End Abstract)\n",
      "(End of abstract)\n",
      "(End of abstract)\n",
      "PERFORMANCE SITE ========================================Section End===========================================\n",
      "KEY PERSONNEL ========================================Section End===========================================\n",
      "[summary truncated at 7800 characters]\n",
      "This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.\n",
      "Project Description Page 6\n",
      "Page 1 of 1\n",
      "Project Summary/Abstract Page 6\n",
      "Project Description Page 7\n",
      "Project Summary/Abstract Page 7\n",
      "Pag 1 o 1\n",
      "Page 2 Number pages consecutively at the bottom throughout Form Page 2\n",
      "This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.\n"
     ]
    }
   ],
   "source": [
    "# remove junk at end\n",
    "\n",
    "end_phrases = ['(End of Abstract)',\"End of Abstract\", '(Abstract end)' \"(END OF ABSTRACT)\", '(End of abstract.)','(Abstract End)','(End 0f Abstract)','(End of Abstract.)','(End of Absract)',\n",
    "               '(Abstract below)','(End of Reviewers\\' Comment)','(End Abstract)','(End of abstract)','(End of abstract)',\n",
    "               'PERFORMANCE SITE ========================================Section End===========================================',\n",
    "                'KEY PERSONNEL ========================================Section End===========================================',\n",
    "               '[summary truncated at 7800 characters]', \n",
    "               'This award reflects NSF\\'s statutory mission and has been deemed worthy of support through evaluation using the Foundation\\'s intellectual merit and broader impacts review criteria.',\n",
    "               'Project Description Page 6', 'Page 1 of 1', 'Project Summary/Abstract Page 6',\n",
    "               'Project Description Page 7', 'Project Summary/Abstract Page 7', 'Pag 1 o 1', \n",
    "               'Page 2 Number pages consecutively at the bottom throughout Form Page 2',\n",
    "               'This award reflects NSF\\'s statutory mission and has been deemed worthy of support through evaluation using the Foundation\\'s intellectual merit and broader impacts review criteria.']\n",
    "\n",
    "df = TextCleaning.remove_junk_end(df, 'working_abstract', end_phrases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/compiler/gcc/7.1.0/jupyter_conda/2019.10-py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "punctuation=['!','?','.']\n",
    "\n",
    "#y='*' #Generally if last char is '*', it comes in as '***' following a complete sentence, so unlikely to be \n",
    "# cut-of'\n",
    "\n",
    "#Fixes '***' if that makes the last character a punctuation ending mark, otherwise should remove\n",
    "y='*' \n",
    "entries_ending_right=df.loc[df['LAST_CHAR']==y]\n",
    "entries_ending_right['new_last_char_possible']= entries_ending_right.apply(lambda x:TextCleaning.remove_phrase(x[wa],'***',loc='End')[-1],axis=1)\n",
    "entries_to_fix=list(entries_ending_right[entries_ending_right['new_last_char_possible'].isin(punctuation)]['PROJECT_ID'])\n",
    "\n",
    "df[wa]=df.apply(lambda x: TextCleaning.remove_phrase(x[wa],'***','End') \n",
    "                if x['PROJECT_ID'] in entries_to_fix else x[wa],axis=1)\n",
    "\n",
    "df['LAST_CHAR']=df[wa].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using regular expressions to remove \"junk\" within text body - not necessarily at the start or end\n",
    "\n",
    "#'Enter the text here tha' ending with 'lines of text.'\n",
    "expression=re.compile('Enter the text here that.*lines of text')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "expression=re.compile('PHS .*?Continuation Format Page')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "expression=re.compile('OMB No .*?Continuation Format Page')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "\n",
    "\n",
    "df[wa]=df[wa].replace('Project Summary/Abstract','')\n",
    "\n",
    "\"\"\"If it starts with 'one page and must contain',\n",
    "#This is an NIH thing and there aren't that many of them, but come from 3 different cfda\n",
    "it will start with \"one page and must contain a summary of the proposed activity suitable for dissemination to thepublic. \n",
    "It should be a self-contained description of the project and should contain a statement of objectives and methods to be employed.\n",
    "It should be informative to other persons working in the same or related fields and insofar as possible understandable to a technically liter-ate lay reader. \n",
    "This Abstract must not include any proprietary/confidential information.* \n",
    "Please click the add attachment button to complete this entry.\" plus some attachments, which includes tracking number, twice:\n",
    "following the second trackign number, there is a grant number followed by the actual content\" \n",
    "\n",
    "At the end of these files, they all end in 'Project Narrative File'(last instance) followed by more attachments, all of which can be discarded\n",
    "\"\"\"\n",
    "expression1=re.compile('one page and must.*?Tracking Number.*?(Tracking Number)')\n",
    "expression2=re.compile('Project Narrative File.*')\n",
    "def fix_abstract(abstract):\n",
    "    if abstract.startswith('one page and must contain'):\n",
    "        abstract=re.sub(expression1,'',abstract)\n",
    "        return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "\n",
    "df[wa]=df[wa].apply(fix_abstract)\n",
    "\n",
    "\n",
    "df[wa]=df[wa].apply(lambda x: x.lstrip(',;\\n\\t&-!'))\n",
    "df=df.loc[df[wa].apply(len)>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting_exact_phrases to remove\n",
    "#'This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.'\n",
    "#'This subproject is one of many research subprojects utilizing theresources provided by a Center grant funded by NIH/NCRR. The subproject andinvestigator (PI) may have received primary funding from another NIH source,and thus could be represented in other CRISP entries. The institution listed isfor the Center, which is not necessarily the institution for the investigator.'\n",
    "df[wa]=df[wa].apply(lambda x: x.replace('This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.',\n",
    "                                       ''))\n",
    "\n",
    "expression=re.compile('This subproject is one of many research subprojects.*not necessarily the institution for the investigator.')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "expression=re.compile('This subproject is one of many research subprojects.*to the subproject or subproject staff.')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_long_phrase(record):\n",
    "    \"\"\" ignores case to remove multi-word phrases in a particular order, especially those likely to run into other words,\n",
    "    e.g. Institution university of washingtonPI mary williams. This doesn't work when titles or insititutions have escape characters in them, which is a bummer\n",
    "    see for example ENHANCING THE USE OF NASA EARTH SCIENCE RESULTS / DATA / AND TECHNOLOGY BY ENGAGING THE FEDERATION OF EARTH SCIENCE INFORMATION PARTNERS COMMUNITIES OF\n",
    "    PRACTICE IN TARGET AREAS OF INTEREST TO NASA THE FEDERATION OF EARTH SCIENCE INFORMATION PARTNERS (''FED\"\"\"\n",
    "    title=record['PROJECT_TITLE']\n",
    "    try:\n",
    "        new_abstract=re.sub(title,'',record[wa],flags=re.IGNORECASE)      \n",
    "        return re.sub(record['ORGANIZATION_NAME'],'',new_abstract,flags=re.IGNORECASE)   \n",
    "    except:\n",
    "        try:\n",
    "            return re.sub(record['ORGANIZATION_NAME'],'',record[wa],flags=re.IGNORECASE)   \n",
    "        except:\n",
    "            return record[wa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[wa]=df.apply(lambda x: remove_long_phrase(x),axis=1)\n",
    "\n",
    "expression=re.compile('Project Summary/Abstract Page.*')\n",
    "\n",
    "def remove_contact_pd(x):\n",
    "    \"\"\"removes clause at end that tends to occur: eg Project Summary/Abstract Page 222Contact PD/PI: Sampson, HughNarrative (\"\"\"\n",
    "    if x.startswith('Contact PD/PI'):\n",
    "        return re.sub(expression,'',x)\n",
    "    else:\n",
    "        return x\n",
    "df[wa]=df[wa].apply(remove_contact_pd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop those that are now length 0 (ie were all punctuation or removable phrases\n",
    "df.drop(list(df[df[wa].apply(lambda x: len(x)==0)].index),inplace=True)\n",
    "df['Start Char']=df[wa].apply(lambda x:x[0])\n",
    "df['LAST_CHAR']=df[wa].apply(lambda x:x[-1])\n",
    "#df.drop(df[df[wa].apply(len)==0].index[0],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df \n",
    "\n",
    "df.to_pickle(\"./clean_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to CSV\n",
    "\n",
    "df = pd.read_pickle(\"./clean_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('FRAbstractsSqueakyClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not running - check with Sam to make sure this is correct\n",
    "\n",
    "\n",
    "#####################\n",
    "#Additional expressions we could choose to remove\n",
    "#Identify abstracts with excessive amounts of other fields to uncover additional bad abstract types\n",
    "#If we wanted to be on the safe side, some EDA makes me think we could remove anything with more than 3 or 4 of these fields. It's where they start getting wonky.\n",
    "###################\n",
    "\n",
    "fields=['Principal Investigator','Program Director','Attachment','Instructions','Lines',\n",
    "        'Space Provided','Performance Site','Organization','Key Personnel']\n",
    "all_fields=fields.copy()\n",
    "all_fields.extend([x.lower() for x in fields])\n",
    "all_fields.extend([x.upper() for x in fields])\n",
    "all_fields.extend(['PI','Form','Page','Title','.pdf','.doc'])\n",
    "\n",
    "def count_up_fields(abstract):\n",
    "    count=0\n",
    "    for field in all_fields:\n",
    "        if field in abstract:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "df['Field Count']=df[wa].apply(count_up_fields)\n",
    "\n",
    "\n",
    "###########################\n",
    "#Additional expressions we could remove, but there is a small possibility of some information being lost\n",
    "##########################\n",
    "\n",
    "#Issues: 'Close FormNextPrint PageAbout OMB Number']#This is usually ended with \"Project summary\", \n",
    "#so anything between those 2 can be delete, and #ended with a clause starting with 'Close FormProject' and ending in'Narrative File'\n",
    "\n",
    "#expression1=re.compile('Close FormNext.*?Project Summary')\n",
    "#expression2=re.compile('Close FormProject.*Narrative File')\n",
    "def fix_abstract(abstract):\n",
    "    if abstract.startswith('Close FormNext'):\n",
    "        abstract=re.sub(expression1,'',abstract)\n",
    "        return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "#df[wa]=df[wa].apply(fix_abstract)\n",
    "\n",
    "#If ends in 'Description,', then go to last instance of PERFORMANCE (for Performance SITES), otherwise \"KEY PERSONNEL\", upper case, and cut all that follows\n",
    "\n",
    "#expression1=re.compile('PERFORMANCE.*Description,$')\n",
    "#expression2=re.compile('KEY PERSONNEL.*Description,$')\n",
    "\n",
    "def apply_expressions(abstract):\n",
    "    if abstract.endswith('Description,'):\n",
    "        if re.search(expression1,abstract) != None:\n",
    "            return re.sub(expression1,'',abstract)\n",
    "        else:\n",
    "            return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "    \n",
    "#df[wa]=df[wa].apply(apply_expressions)\n",
    "\n",
    "#expression1=re.compile('PERFORMANCE.*Page 3$')\n",
    "#expression2=re.compile('KEY PERSONNEL.*Page 3,$')\n",
    "\n",
    "def apply_expressions(abstract):\n",
    "    if abstract.endswith('Description,'):\n",
    "        if re.search(expression1,abstract) != None:\n",
    "            return re.sub(expression1,'',abstract)\n",
    "        else:\n",
    "            return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "    \n",
    "#df[wa]=df[wa].apply(apply_expressions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
