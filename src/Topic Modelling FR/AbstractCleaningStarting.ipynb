{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Set up Environment\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "from string import ascii_letters\n",
    "import sys\n",
    "import re\n",
    "#Preprocessing\n",
    "import nltk\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns\n",
      "Index(['PROJECT_ID', 'ABSTRACT', 'FY', 'FIRST_CHAR', 'LAST_CHAR', 'DEPARTMENT',\n",
      "       'AGENCY', 'IC_CENTER', 'PROJECT_NUMBER', 'PROJECT_TITLE',\n",
      "       'PROJECT_TERMS', 'CONTACT_PI_PROJECT_LEADER', 'OTHER_PIS',\n",
      "       'ORGANIZATION_NAME', 'CFDA_CODE', 'FY_TOTAL_COST'],\n",
      "      dtype='object')\n",
      "Descriptive Stats\n",
      "         PROJECT_ID             FY  FY_TOTAL_COST\n",
      "count  5.500880e+05  550088.000000   4.256850e+05\n",
      "mean   4.980384e+05    2012.247477   4.509841e+05\n",
      "std    3.262050e+05       3.183765   1.727112e+06\n",
      "min    1.008600e+04    2008.000000   1.000000e+00\n",
      "25%    1.790538e+05    2009.000000   1.390020e+05\n",
      "50%    4.880660e+05    2012.000000   2.917820e+05\n",
      "75%    7.817102e+05    2015.000000   4.500000e+05\n",
      "max    1.101940e+06    2018.000000   3.227983e+08\n",
      "Length\n",
      "550088\n"
     ]
    }
   ],
   "source": [
    "#Visualize data\n",
    "raw_df=pd.read_csv('/sfs/qumulo/qhome/sc2pg/src/prnd/publicrd/data/prd/DigitalOcean_Backup/public_rd/working/federal_reporter/abstracts_federal_reporter_combined.csv',engine='python')\n",
    "\n",
    "print('Columns')\n",
    "print(raw_df.columns)\n",
    "print('Descriptive Stats')\n",
    "print(raw_df.describe())\n",
    "print('Length')\n",
    "print(len(raw_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length550074\n",
      "Project ID duplicates:\n",
      "Series([], Name: PROJECT_ID, dtype: int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "#Remove nulls and duplicates\n",
    "#Currently removes only duplicates based on ABSTRACTS and only in the same YEAR\n",
    "#The rationale here is that we may do year-by-year modelling and don't want to exclude projects\n",
    "#But if we do all-in-one modelling (e.g. across all years), we will want to reconsider\n",
    "#Also will want to do additional duplicate check once abstracts are cleaned\n",
    "###############\n",
    "\n",
    "#Drop projects with identical abstracts and year. Different year could indicate additional funding sent to this project.\n",
    "df=raw_df.loc[pd.notnull(raw_df['ABSTRACT'])]\n",
    "df.drop_duplicates(subset=['ABSTRACT','FY'],inplace=True) \n",
    "print('Length'+str(len(df)))\n",
    "\n",
    "####################\n",
    "#Check for additional duplicates\n",
    "#Note that the project id isnt necessarily identical for each transaction on same grant--e.g. one number could be added, so this isnt that strict\n",
    "#and why checking astract is needed\n",
    "#####################\n",
    "print('Project ID duplicates:')\n",
    "vc=df['PROJECT_ID'].value_counts()\n",
    "print(vc[vc>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#Function for removing any text we don't like at start, end, or anywhere within a string\n",
    "#CASE SENSITIVE\n",
    "################\n",
    "\n",
    "def remove_phrase(x, phrase,loc='Start'):\n",
    "    \"\"\"returns x with phrase removed. location can be \"Start\" of string, \"End\" of string, or \"Anywhere_All\"--anywhere will remove all instances and Anywhere_First will remove the first instane\"\"\"\n",
    "    assert loc in ['Start','End','Anywhere_All','Anywhere_First']\n",
    "    if loc=='End':\n",
    "        if x.endswith(phrase):\n",
    "            return x[:-1*len(phrase)].strip()\n",
    "        else:\n",
    "            return x\n",
    "    elif loc=='Start':\n",
    "        if x.startswith(phrase):\n",
    "            return x[len(phrase):].strip()\n",
    "        else:\n",
    "            return x\n",
    "    elif loc=='Anywhere_All':\n",
    "        return x.replace(phrase,'')\n",
    "    elif loc=='Anywhere_First':\n",
    "        return x.replace(phrase,'',1)\n",
    "    else:\n",
    "        return 'Error'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#Define a new series which is an abstract that keeps the raw text, but can be continuously manipulated.\n",
    "wa='working_abstract'\n",
    "df[wa]=df['ABSTRACT'].apply(str.strip)\n",
    "\n",
    "#An illustrative case that Fedearl Reporter is NOT all R&D and why semantic content, rather than simple tagging, is better\n",
    "#print(df.loc[df['ABSTRACT']== 'Not R&D, do not report',[wa,'PROJECT_TERMS']])\n",
    "#print(df.loc[df['ABSTRACT']== 'Technical support services contract, not R&D',[wa,'PROJECT_TERMS']])\n",
    "\n",
    "\n",
    "#Remove too short abstracts\n",
    "df['nchar']=df[wa].apply(len)\n",
    "limit=150 #Less than 150 chars is not an abstract\n",
    "#[x for x in df.loc[df['nchar']<=limit,'ABSTRACT'].head(40)]\n",
    "#This seems like a good cutoff, but it does lose some useful information.\n",
    "df=df.loc[df['nchar']>=limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#2.1--phrases noticed through investigation of starting characters, as well as those identified in R Analysis\n",
    "######################\n",
    "\n",
    "start_phrases=['****TECHNICAL ABSTRACT****','****Technical Abstract****',\n",
    "               '****Non Technical Abstract****','*** Non- Technical Abstract ***','**Non-Technical Abstract**',\n",
    "               '*****NON-TECHNICAL ABSTRACT*****','***** NON-TECHNICAL ABSTRACT *****',\n",
    "               '****NONTECHNICAL ABSTRACT****','****Non-Technical Abstract****','*Non-technical Abstract*',\n",
    "               '*****NON-TECHNICAL ABSTRACT*****','****NON-TECHNICAL ABSTRACT****',\n",
    "               '***NON-TECHNICAL ABSTRACT***','****Nontechnical abstract****',\n",
    "               'TECHNICAL SUMMARY', 'NONTECHNICAL SUMMARY','NON-TECHNICAL SUMMARY','Non-technical description',\n",
    "               'DESCRIPTION (Provided by the applicant)','DESCRIPTION (provided by investigator)',  'DESCRIPTION (provided by applicant)',\n",
    "               'Project Summary/Abstract','PROJECT SUMMARY/ABSTRACT',\n",
    "               'ABSTRACT','abstract','Proposal Abstract','Abstract','RESEARCH ABSTRACT',\n",
    "               'PROJECT SUMMARY','Project Summary','SUMMARY','RESEARCH SUMMARY',\n",
    "               'Proposal',\n",
    "               'DESCRIPTION','Description','PROJECT DESCRIPTION'\n",
    "               'NARRATIVE',\n",
    "               '(See instructions):','\\t',\n",
    "              'FOR CENTER APPLICATION (provided by the investigator):','Objective(s)',      'EXCEED THE SPACE PROVIDED',\n",
    "               'Provided by Applicant','Provided by applicant','provided by applicant','PROVIDED BY APPLICANT',\n",
    "               'Provided by Candidate','Provided by candidate','provided by candidate','PROVIDED BY CANDIDATE']\n",
    "\n",
    "df[wa]=df[wa].apply(str.lstrip,args=[' ?-_^. :,!;¿|()[]]#%>﻿&\\''])\n",
    "df.drop(df[df[wa].apply(len)==0].index[0],axis=0,inplace=True)\n",
    "#Remove found phrases\n",
    "for phrase in start_phrases:\n",
    "    df[wa]=df[wa].apply(remove_phrase,args=[phrase,'Start']).apply(str.lstrip,args=[' :./)'])\n",
    "#Repeated in case the order of project summary/abstract varies\n",
    "for phrase in start_phrases:\n",
    "    df[wa]=df[wa].apply(remove_phrase,args=[phrase,'Start']).apply(str.lstrip,args=[' :./)'])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Examining Titles for Duplication (Instead of Project IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"vc=df.groupby('CONTACT_PI_PROJECT_LEADER')['First 50'].value_counts()\\nvc[vc>1]\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "#Exploratory Data Analaysis at different levels to look for patterns to remove\n",
    "#################\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "#Finding repeats other than by project ID: using titles\n",
    "#Title is not a good indicator of whether a project is repeated--many grants all have same title but very different abstracts and PIs\n",
    "#You can run this code to see very common titles used by more than one PI. Don't rely on titles\n",
    "########\n",
    "\"\"\"vc=df['PROJECT_TITLE'].value_counts()\n",
    "vc=vc[vc>1]\n",
    "#First 50 sets that occur more than once\n",
    "dup_strings=list(vc.index)\n",
    "\n",
    "#Dataframe of common titles, which PIs use is and how many unique PIs\n",
    "vc=df.loc[df['PROJECT_TITLE'].isin(dup_strings)].groupby('PROJECT_TITLE')['CONTACT_PI_PROJECT_LEADER'].unique()\n",
    "common=pd.DataFrame([vc,vc.apply(len)],index=['Unique PIs','Num_Unique_PIs']).T\n",
    "#Titles that appear more than once and are used by at least 2 PIS\n",
    "common=common.loc[common['Num_Unique_PIs']>1]\"\"\"\n",
    "\n",
    "###############33\n",
    "#2: Pulling out duplicate first sentences\n",
    "#Pull out starts that are absolutely high (not relatively by CFDA)\n",
    "#If you run this BEFORE taking out all the starts in the cell above, you get very different results.\n",
    "#Many of these are documented below, but we do not remove them since they are content.\n",
    "################\n",
    "\n",
    "#df['First 50']=df[wa].apply(lambda x: x[:50])\n",
    "#vc=df['First 50'].value_counts()\n",
    "#vc[vc>2]\n",
    "\n",
    "##########################\n",
    "#2: Starts\n",
    "#Pull out starts that are proportionally high to check for uninformative/duplicate sentences\n",
    "#Show how frequent certain first chars are by cfda by grouping, relative frequnecyy\n",
    "#Again based on First Char, repeat with first actual sentence\n",
    "##########################\n",
    "\n",
    "#Put together a table that groups first char by CFDA code and instead of counts, see how frequently it occurs within that CFDA code\n",
    "\"\"\"rel_freq=pd.DataFrame(df.groupby('CFDA_CODE')['First 50'].value_counts())\n",
    "rel_freq=rel_freq.join(df['CFDA_CODE'].value_counts(),on='CFDA_CODE')\n",
    "rel_freq['Relative Frequency']=rel_freq['First 50']/rel_freq['CFDA_CODE']\n",
    "\n",
    "#Limit analysis to those items that occur at least 3 times and in at least 1% of abstracts (arbitrary)\n",
    "a=rel_freq['First 50']>3 \n",
    "b=rel_freq['Relative Frequency']>.01\n",
    "rel_freq.loc[(a&b)] #Some first sentences are a very good indicator of a particular CFDA, suggesting they have particular formatting rules that would be a give away for the\n",
    "#CFDA code, rather than the actual research conducted\n",
    "#rel_freq.loc[(a&b)].to_csv('Common First 50.csv')\n",
    "rel_freq.loc[(a&b)]\"\"\"\n",
    "\n",
    "#############\n",
    "#Demonsrate that individuals tend to reuse the same sentences across grants\n",
    "#There are over 70,000 unique first 50 characters that are used more than once by the same PI\n",
    "#############\n",
    "\n",
    "\"\"\"vc=df.groupby('CONTACT_PI_PROJECT_LEADER')['First 50'].value_counts()\n",
    "vc[vc>1]\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Examining First Few Characters to Find Tags (Instead of sentences, because common first sentences have same first few characters!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"vc=df['First 50'].value_counts()\\nvc=vc[vc>1]\\n#First 50 sets that occur more than once\\ndup_strings=list(vc.index)\\n\\n#Dataframe of common first phrases, which PIs use is and how many unique PIs\\nvc=df.loc[df['First 50'].isin(dup_strings)].groupby('First 50')['CONTACT_PI_PROJECT_LEADER'].unique()\\ncommon=pd.DataFrame([vc,vc.apply(len)],index=['Unique PIs','Num_Unique_PIs']).T\\ncommon=common.loc[common['Num_Unique_PIs']>1]\\nprint(common.sort_values(by=['Num_Unique_PIs'],ascending=False))\\n\\n#Here is a case where multiple investigators use very similar first sentences\\nfor row in df.loc[df['First 50']=='Land-use change is a primary driver of the losses '].iterrows():\\n    print(row[1]['ABSTRACT'])\""
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########\n",
    "#Grouping by first 50, we can pull out first_sentences that are used by more than one PI, suggesting this is not just a PI thing, but a grant level or in some case prject  thing\n",
    "#Identifying more sentences to be examined and removed\n",
    "#########\n",
    "\n",
    "\"\"\"vc=df['First 50'].value_counts()\n",
    "vc=vc[vc>1]\n",
    "#First 50 sets that occur more than once\n",
    "dup_strings=list(vc.index)\n",
    "\n",
    "#Dataframe of common first phrases, which PIs use is and how many unique PIs\n",
    "vc=df.loc[df['First 50'].isin(dup_strings)].groupby('First 50')['CONTACT_PI_PROJECT_LEADER'].unique()\n",
    "common=pd.DataFrame([vc,vc.apply(len)],index=['Unique PIs','Num_Unique_PIs']).T\n",
    "common=common.loc[common['Num_Unique_PIs']>1]\n",
    "print(common.sort_values(by=['Num_Unique_PIs'],ascending=False))\n",
    "\n",
    "#Here is a case where multiple investigators use very similar first sentences\n",
    "for row in df.loc[df['First 50']=='Land-use change is a primary driver of the losses '].iterrows():\n",
    "    print(row[1]['ABSTRACT'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some numbers of (*s, non or not) (space, -, or not), (technical abstract), (some number of stars)\\nsome numbers (with . between) followed by abstract\\n(abstract) (of whichever capitalization, within parentheses)\\n(numbers + .)repeated endign with either + \\'Project Summary/Abstract\\'\\nPHS 398/2590 + anything followed by + Page Continuation Format Page\\nIf it starts with \\'one page and must contain\\',\\n#This is an NIH thing and there aren\\'t that many of them, but come from 3 different cfda\\nit will start with \"one page and must contain a summary of the proposed activity suitable for dissemination to thepublic. \\nIt should be a self-contained description of the project and should contain a statement of objectives and methods to be employed.\\nIt should be informative to other persons working in the same or related fields and insofar as possible understandable to a technically liter-ate lay reader. \\nThis Abstract must not include any proprietary/confidential information.* \\nPlease click the add attachment button to complete this entry.\" plus some attachments, which includes tracking number, twice:\\nfollowing the second trackign number, there is a grant number followed by the actual content\" \\n\\nAt the end of these files, they all end in \\'Project Narrative File\\'(last instance) followed by more attachments, all of which can be discarded\\n\\n\\'Enter the text here tha\\' ending with \\'lines of text.\\'\\n\\'Close FormNextPrint PageAbout OMB Number\\'] #This is usually ended with \"Project summary\", so anything between those 2 can be delete, and ended with a clause starting with \\'Close FormProject\\' and ending in\\'Narrative File\\'\\n#If ends in \\'Description,\\', then go to last instance of PERFORMANCE (for Performance SITES), otherwise \"KEY PERSONNEL\", upper case, and cut all that follows\\n#Starting characters to remove\\n#[\\',\\',\\';\\',\\'\\n\\',\\'\\t\\',\\'&\\',\\'-\\',\\'!\\']\\n\\n#starting_exact_phrases to remove\\n\\'This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.\\'\\n\\'This subproject is one of many research subprojects utilizing theresources provided by a Center grant funded by NIH/NCRR. The subproject andinvestigator (PI) may have received primary funding from another NIH source,and thus could be represented in other CRISP entries. The institution listed isfor the Center, which is not necessarily the institution for the investigator.\\'\\n\\n\\n#############\\n#Some exampes of junk we cant remove--not regular expressiony or even if low info, is some info\\n#############\\n#Occurs often, but not about content of grants\\n\\'This award reflects NSF\\'s statutory mission and has been deemed worthy of support through evaluation using the Foundation\\'s intellectual merit and broader impacts review criteria.\\'\\n#The presence of \\'American Recovery and Reinvestment Act\\' is a strong indicator of CFDA_CODE 47.082. This could present problems moving forward\\n\\'Program Director/Principal Investigator (Last, First, Middle): \\', #What follows is usually a mix of existing info, but before a description that is usefull,  but not going to be possible to regular expression\\n\\'IGF::OT::IGF\\', #Not truncated but usually abstract as a whole is lacking in inofrmation: #Keep\\n#Variations of abstracts ending with Page 3, 4, etc.\\n\\n#####################\\n#Based on analysis of CFDA numbers, these are starting phrases that make up a disproportionate amount of a CFDA number, but do not provide\\n#Information on the grant itself beyond the name. The impetus to remove them is that they may signal a grant OPPORTUNITY (i.e. CFDA ), rather \\n#Than broad content found in numerous topics\\n##The presence of \\'American Recovery and Reinvestment Act\\' is a strong indicator of CFDA_CODE 47.082. This could present problems moving forward\\n###############################################\\n\\n#Examples:\\n\\'The broader impact/commercial potential of this I-Corps project\\'\\n\\'The broader impact/commercial potential of this project\\',\\n\\'The broader impact/commercial potential of this PFI project\\',\\n\\'The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I\\',\\n\\'The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II\\',\\n\\'The broader impacts/commercial potential of this Small Business Innovation Research (SBIR) Phase I\\',\\n\\'The broader impact/commercial potential of this Small Business Innovation Research (SBIR)\\',\\n\\'The broader impact/commercial potential of this Small Business Technology Transfer (STTR) Phase II\\',\\n\\'The broader impact/commercial potential of this Small Business Technology Transfer (STTR) Phase I\\',\\n\\'The broader impact/commercial potential of this Small Business Technology Transfer (STTR)\\',\\n\\'The broader impact/commercial potential of this Small Business Technology Transfer Phase II\\',\\n\\'The broader impact/commercial potential of this Small Business Technology Transfer Phase I\\',\\n\\'The broader impact/commercial potential of this Small Business Technology Transfer\\',\\n\\'The broader impact/commercial potential of this Small Business Innovation Research Phase II\\',\\n\\'The broader impact/commercial potential of this Small Business Innovation Research Phase I\\',\\n\\'The broader impact/commercial potential of this Small Business Innovation Research\\',\\n\\'This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\\',\\n\\'This award is made as part of the FY 2018 Mathematical Sciences Postdoctoral Research Fellowships\\',\\n\\'This application addresses broad Challenge Area\\''"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################\n",
    "#Issues identified through looking at either first character or first 50 characters\n",
    "#To finish this, add in longer phrases identified in thousands, rather than scrolling through things\n",
    "##############################\n",
    "\n",
    "#Starting regular expressions to remove:\n",
    "\"\"\"Some numbers of (*s, non or not) (space, -, or not), (technical abstract), (some number of stars)\n",
    "some numbers (with . between) followed by abstract\n",
    "(abstract) (of whichever capitalization, within parentheses)\n",
    "(numbers + .)repeated endign with either + 'Project Summary/Abstract'\n",
    "PHS 398/2590 + anything followed by + Page Continuation Format Page\n",
    "If it starts with 'one page and must contain',\n",
    "#This is an NIH thing and there aren't that many of them, but come from 3 different cfda\n",
    "it will start with \"one page and must contain a summary of the proposed activity suitable for dissemination to thepublic. \n",
    "It should be a self-contained description of the project and should contain a statement of objectives and methods to be employed.\n",
    "It should be informative to other persons working in the same or related fields and insofar as possible understandable to a technically liter-ate lay reader. \n",
    "This Abstract must not include any proprietary/confidential information.* \n",
    "Please click the add attachment button to complete this entry.\" plus some attachments, which includes tracking number, twice:\n",
    "following the second trackign number, there is a grant number followed by the actual content\" \n",
    "\n",
    "At the end of these files, they all end in 'Project Narrative File'(last instance) followed by more attachments, all of which can be discarded\n",
    "\n",
    "'Enter the text here tha' ending with 'lines of text.'\n",
    "'Close FormNextPrint PageAbout OMB Number'] #This is usually ended with \"Project summary\", so anything between those 2 can be delete, and ended with a clause starting with 'Close FormProject' and ending in'Narrative File'\n",
    "#If ends in 'Description,', then go to last instance of PERFORMANCE (for Performance SITES), otherwise \"KEY PERSONNEL\", upper case, and cut all that follows\n",
    "#Starting characters to remove\n",
    "#[',',';','\\n','\\t','&','-','!']\n",
    "\n",
    "#starting_exact_phrases to remove\n",
    "'This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.'\n",
    "'This subproject is one of many research subprojects utilizing theresources provided by a Center grant funded by NIH/NCRR. The subproject andinvestigator (PI) may have received primary funding from another NIH source,and thus could be represented in other CRISP entries. The institution listed isfor the Center, which is not necessarily the institution for the investigator.'\n",
    "\n",
    "\n",
    "#############\n",
    "#Some exampes of junk we cant remove--not regular expressiony or even if low info, is some info\n",
    "#############\n",
    "#Occurs often, but not about content of grants\n",
    "'This award reflects NSF\\'s statutory mission and has been deemed worthy of support through evaluation using the Foundation\\'s intellectual merit and broader impacts review criteria.'\n",
    "#The presence of 'American Recovery and Reinvestment Act' is a strong indicator of CFDA_CODE 47.082. This could present problems moving forward\n",
    "'Program Director/Principal Investigator (Last, First, Middle): ', #What follows is usually a mix of existing info, but before a description that is usefull,  but not going to be possible to regular expression\n",
    "'IGF::OT::IGF', #Not truncated but usually abstract as a whole is lacking in inofrmation: #Keep\n",
    "#Variations of abstracts ending with Page 3, 4, etc.\n",
    "\n",
    "#####################\n",
    "#Based on analysis of CFDA numbers, these are starting phrases that make up a disproportionate amount of a CFDA number, but do not provide\n",
    "#Information on the grant itself beyond the name. The impetus to remove them is that they may signal a grant OPPORTUNITY (i.e. CFDA ), rather \n",
    "#Than broad content found in numerous topics\n",
    "##The presence of 'American Recovery and Reinvestment Act' is a strong indicator of CFDA_CODE 47.082. This could present problems moving forward\n",
    "###############################################\n",
    "\n",
    "#Examples:\n",
    "'The broader impact/commercial potential of this I-Corps project'\n",
    "'The broader impact/commercial potential of this project',\n",
    "'The broader impact/commercial potential of this PFI project',\n",
    "'The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I',\n",
    "'The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II',\n",
    "'The broader impacts/commercial potential of this Small Business Innovation Research (SBIR) Phase I',\n",
    "'The broader impact/commercial potential of this Small Business Innovation Research (SBIR)',\n",
    "'The broader impact/commercial potential of this Small Business Technology Transfer (STTR) Phase II',\n",
    "'The broader impact/commercial potential of this Small Business Technology Transfer (STTR) Phase I',\n",
    "'The broader impact/commercial potential of this Small Business Technology Transfer (STTR)',\n",
    "'The broader impact/commercial potential of this Small Business Technology Transfer Phase II',\n",
    "'The broader impact/commercial potential of this Small Business Technology Transfer Phase I',\n",
    "'The broader impact/commercial potential of this Small Business Technology Transfer',\n",
    "'The broader impact/commercial potential of this Small Business Innovation Research Phase II',\n",
    "'The broader impact/commercial potential of this Small Business Innovation Research Phase I',\n",
    "'The broader impact/commercial potential of this Small Business Innovation Research',\n",
    "'This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).',\n",
    "'This award is made as part of the FY 2018 Mathematical Sciences Postdoctoral Research Fellowships',\n",
    "'This application addresses broad Challenge Area'\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Looking just at the first character to check for truncation or start errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "#First characters of abstracts (after some cleaning)\n",
    "#Items with lowercase are not necessarily truncated, but certainly can be\n",
    "#Often, a lowercase indicates possible truncation,e.g. 'n the last decade' but it can also be, e.g. 'von Hippel-Lindau Dissease', gamma-crystallins,?-lactam\n",
    "#Characters that should be removed as a result of individual analysis of each unique, non uppercase starter:[',',';','\\n','\\t','&','-','!']\n",
    "#. is usually just a leftover from abstract removal\n",
    "#################\n",
    "#First character assignment, to see whether all abstracts are now starting with upper case letters (in the best case scenario)\n",
    "df['Start Char']=df[wa].apply(lambda x: x[0])\n",
    "vc=df['Start Char'].value_counts()\n",
    "#print(vc.loc[[x for x in vc.index if not x in string.ascii_uppercase+string.ascii_lowercase+'0123456789[(']])\n",
    "####################\n",
    "#2.2 Starting with first letter, do we see things are often completely surrounded by some sort of punctuation, in which case we can \n",
    "#make sure there isn't some starting clause we're missing\n",
    "###################\n",
    "df['Start Char']=df[wa].apply(lambda x:x[0])\n",
    "\n",
    "#print(df.loc[df['Start Char']=='-','LAST_CHAR'].value_counts()) #Again--not starting and ending with '-'\n",
    "#Although * is a common start, the whole thing isn't surrounded by *s\n",
    "#print(df.loc[df['Start Char']=='*','LAST_CHAR'].value_counts())\n",
    "#Although * is a common start, the whole thing isn't surrounded by *s\n",
    "#print(df.loc[df['Start Char']=='=','LAST_CHAR'].value_counts())\n",
    "\n",
    "#bad_starts=[x for x in vc.index if not x in string.ascii_uppercase]\n",
    "\n",
    "\n",
    "df[wa]=df[wa].apply(str.lstrip,args=['?-*_^. :,!;=¿|]#%>&-\\t\\n']) #Often, sentences will start with - or *, but they indicate other quality issues and don't end with them,so it's okay to remove them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: bad escape \\E\n",
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: bad escape \\N\n",
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: bad escape \\O\n",
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: bad escape \\G\n",
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: bad escape \\Y\n",
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: bad escape \\T\n",
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: bad escape \\K\n",
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: bad escape \\R\n",
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: bad escape \\H\n",
      "/home/sc2pg/.conda/envs/env_full/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: bad escape \\F\n"
     ]
    }
   ],
   "source": [
    "#'Enter the text here tha' ending with 'lines of text.'\n",
    "expression=re.compile('Enter the text here that.*lines of text')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "expression=re.compile('PHS .*?Continuation Format Page')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "expression=re.compile('OMB No .*?Continuation Format Page')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "\n",
    "\n",
    "df[wa]=df[wa].replace('Project Summary/Abstract','')\n",
    "\n",
    "\"\"\"If it starts with 'one page and must contain',\n",
    "#This is an NIH thing and there aren't that many of them, but come from 3 different cfda\n",
    "it will start with \"one page and must contain a summary of the proposed activity suitable for dissemination to thepublic. \n",
    "It should be a self-contained description of the project and should contain a statement of objectives and methods to be employed.\n",
    "It should be informative to other persons working in the same or related fields and insofar as possible understandable to a technically liter-ate lay reader. \n",
    "This Abstract must not include any proprietary/confidential information.* \n",
    "Please click the add attachment button to complete this entry.\" plus some attachments, which includes tracking number, twice:\n",
    "following the second trackign number, there is a grant number followed by the actual content\" \n",
    "\n",
    "At the end of these files, they all end in 'Project Narrative File'(last instance) followed by more attachments, all of which can be discarded\n",
    "\"\"\"\n",
    "expression1=re.compile('one page and must.*?Tracking Number.*?(Tracking Number)')\n",
    "expression2=re.compile('Project Narrative File.*')\n",
    "def fix_abstract(abstract):\n",
    "    if abstract.startswith('one page and must contain'):\n",
    "        abstract=re.sub(expression1,'',abstract)\n",
    "        return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "\n",
    "df[wa]=df[wa].apply(fix_abstract)\n",
    "\n",
    "\n",
    "df[wa]=df[wa].apply(lambda x: x.lstrip(',;\\n\\t&-!'))\n",
    "df=df.loc[df[wa].apply(len)>0]\n",
    "\n",
    "#starting_exact_phrases to remove\n",
    "#'This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.'\n",
    "#'This subproject is one of many research subprojects utilizing theresources provided by a Center grant funded by NIH/NCRR. The subproject andinvestigator (PI) may have received primary funding from another NIH source,and thus could be represented in other CRISP entries. The institution listed isfor the Center, which is not necessarily the institution for the investigator.'\n",
    "df[wa]=df[wa].apply(lambda x: x.replace('This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.',\n",
    "                                       ''))\n",
    "\n",
    "expression=re.compile('This subproject is one of many research subprojects.*not necessarily the institution for the investigator.')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "expression=re.compile('This subproject is one of many research subprojects.*to the subproject or subproject staff.')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "def remove_long_phrase(record):\n",
    "    \"\"\" ignores case to remove multi-word phrases in a particular order, especially those likely to run into other words,\n",
    "    e.g. Institution university of washingtonPI mary williams. This doesn't work when titles or insititutions have escape characters in them, which is a bummer\n",
    "    see for example ENHANCING THE USE OF NASA EARTH SCIENCE RESULTS / DATA / AND TECHNOLOGY BY ENGAGING THE FEDERATION OF EARTH SCIENCE INFORMATION PARTNERS COMMUNITIES OF\n",
    "    PRACTICE IN TARGET AREAS OF INTEREST TO NASA THE FEDERATION OF EARTH SCIENCE INFORMATION PARTNERS (''FED\"\"\"\n",
    "    title=record['PROJECT_TITLE']\n",
    "    try:\n",
    "        new_abstract=re.sub(title,'',record[wa],flags=re.IGNORECASE)      \n",
    "        return re.sub(record['ORGANIZATION_NAME'],'',new_abstract,flags=re.IGNORECASE)   \n",
    "    except:\n",
    "        try:\n",
    "            return re.sub(record['ORGANIZATION_NAME'],'',record[wa],flags=re.IGNORECASE)   \n",
    "        except:\n",
    "            return record[wa]\n",
    "\n",
    "df[wa]=df.apply(lambda x: remove_long_phrase(x),axis=1)\n",
    "\n",
    "expression=re.compile('Project Summary/Abstract Page.*')\n",
    "\n",
    "def remove_contact_pd(x):\n",
    "    \"\"\"removes clause at end that tends to occur: eg Project Summary/Abstract Page 222Contact PD/PI: Sampson, HughNarrative (\"\"\"\n",
    "    if x.startswith('Contact PD/PI'):\n",
    "        return re.sub(expression,'',x)\n",
    "    else:\n",
    "        return x\n",
    "df[wa]=df[wa].apply(remove_contact_pd)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop those that are now length 0 (ie were all punctuation or removable phrases\n",
    "df.drop(list(df[df[wa].apply(lambda x: len(x)==0)].index),inplace=True)\n",
    "df['Start Char']=df[wa].apply(lambda x:x[0])\n",
    "df['LAST_CHAR']=df[wa].apply(lambda x:x[0])\n",
    "#df.drop(df[df[wa].apply(len)==0].index[0],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#Additional expressions we could choose to remove\n",
    "#Identify abstracts with excessive amounts of other fields to uncover additional bad abstract types\n",
    "#If we wanted to be on the safe side, some EDA makes me think we could remove anything with more than 3 or 4 of these fields. It's where they start getting wonky.\n",
    "###################\n",
    "\n",
    "fields=['Principal Investigator','Program Director','Attachment','Instructions','Lines',\n",
    "        'Space Provided','Performance Site','Organization','Key Personnel']\n",
    "all_fields=fields.copy()\n",
    "all_fields.extend([x.lower() for x in fields])\n",
    "all_fields.extend([x.upper() for x in fields])\n",
    "all_fields.extend(['PI','Form','Page','Title','.pdf','.doc'])\n",
    "\n",
    "def count_up_fields(abstract):\n",
    "    count=0\n",
    "    for field in all_fields:\n",
    "        if field in abstract:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "df['Field Count']=df[wa].apply(count_up_fields)\n",
    "\n",
    "\n",
    "###########################\n",
    "#Additional expressions we could remove, but there is a small possibility of some information being lost\n",
    "##########################\n",
    "\n",
    "#Issues: 'Close FormNextPrint PageAbout OMB Number']#This is usually ended with \"Project summary\", \n",
    "#so anything between those 2 can be delete, and #ended with a clause starting with 'Close FormProject' and ending in'Narrative File'\n",
    "\n",
    "#expression1=re.compile('Close FormNext.*?Project Summary')\n",
    "#expression2=re.compile('Close FormProject.*Narrative File')\n",
    "def fix_abstract(abstract):\n",
    "    if abstract.startswith('Close FormNext'):\n",
    "        abstract=re.sub(expression1,'',abstract)\n",
    "        return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "#df[wa]=df[wa].apply(fix_abstract)\n",
    "\n",
    "#If ends in 'Description,', then go to last instance of PERFORMANCE (for Performance SITES), otherwise \"KEY PERSONNEL\", upper case, and cut all that follows\n",
    "\n",
    "#expression1=re.compile('PERFORMANCE.*Description,$')\n",
    "#expression2=re.compile('KEY PERSONNEL.*Description,$')\n",
    "\n",
    "def apply_expressions(abstract):\n",
    "    if abstract.endswith('Description,'):\n",
    "        if re.search(expression1,abstract) != None:\n",
    "            return re.sub(expression1,'',abstract)\n",
    "        else:\n",
    "            return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "    \n",
    "#df[wa]=df[wa].apply(apply_expressions)\n",
    "\n",
    "#expression1=re.compile('PERFORMANCE.*Page 3$')\n",
    "#expression2=re.compile('KEY PERSONNEL.*Page 3,$')\n",
    "\n",
    "def apply_expressions(abstract):\n",
    "    if abstract.endswith('Description,'):\n",
    "        if re.search(expression1,abstract) != None:\n",
    "            return re.sub(expression1,'',abstract)\n",
    "        else:\n",
    "            return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "    \n",
    "#df[wa]=df[wa].apply(apply_expressions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('FRAbstractsSqueakyClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['FY']==2008].to_csv('FedReporterAbstracts2008InProgressCleaning.csv')\n",
    "#df.to_csv('FRAbstractsInProgressCleaning.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
