{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing for use with Topic Models\n",
    "\n",
    "The text has already been cleaned.  This script will preprocess it - tokenize, remove stop words, add bigrams and trigrams, lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "import TextCleaning\n",
    "import LDAvariables\n",
    "import stanza\n",
    "\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I used this document to understand what was happening in pre-processing at a small scale. \n",
    "#Currently I deleted the original stanford model because I accidently override in wiht a small df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (1,7,13,14,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load saved df.  df['working_abstract'] contains clean text.\n",
    "df = pd.read_csv(\"../../data/original/working_federal_reporter_2020.csv\")\n",
    "df.reset_index(inplace = True)\n",
    "df.rename(columns={'index':'original index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa='ABSTRACT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original index                  int64\n",
       "PROJECT_ID                    float64\n",
       "ABSTRACT                       object\n",
       "FY.x                          float64\n",
       "PROJECT_TERMS                  object\n",
       "PROJECT_TITLE                  object\n",
       "DEPARTMENT                     object\n",
       "AGENCY                         object\n",
       "IC_CENTER                      object\n",
       "PROJECT_NUMBER                 object\n",
       "PROJECT_START_DATE             object\n",
       "PROJECT_END_DATE               object\n",
       "CONTACT_PI_PROJECT_LEADER      object\n",
       "OTHER_PIS                      object\n",
       "CONGRESSIONAL_DISTRICT         object\n",
       "DUNS_NUMBER                    object\n",
       "ORGANIZATION_NAME              object\n",
       "ORGANIZATION_CITY              object\n",
       "ORGANIZATION_STATE             object\n",
       "ORGANIZATION_ZIP               object\n",
       "ORGANIZATION_COUNTRY           object\n",
       "BUDGET_START_DATE              object\n",
       "BUDGET_END_DATE                object\n",
       "CFDA_CODE                      object\n",
       "FY.y                          float64\n",
       "FY_TOTAL_COST                 float64\n",
       "FY_TOTAL_COST_SUB_PROJECTS    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "#df = df.astype(str)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original index</th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>FY.x</th>\n",
       "      <th>PROJECT_TERMS</th>\n",
       "      <th>PROJECT_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>AGENCY</th>\n",
       "      <th>IC_CENTER</th>\n",
       "      <th>PROJECT_NUMBER</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_CITY</th>\n",
       "      <th>ORGANIZATION_STATE</th>\n",
       "      <th>ORGANIZATION_ZIP</th>\n",
       "      <th>ORGANIZATION_COUNTRY</th>\n",
       "      <th>BUDGET_START_DATE</th>\n",
       "      <th>BUDGET_END_DATE</th>\n",
       "      <th>CFDA_CODE</th>\n",
       "      <th>FY.y</th>\n",
       "      <th>FY_TOTAL_COST</th>\n",
       "      <th>FY_TOTAL_COST_SUB_PROJECTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89996.0</td>\n",
       "      <td>This is a project to explore Game-based, Metap...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Achievement; analog; base; Cognitive Science; ...</td>\n",
       "      <td>RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0814512</td>\n",
       "      <td>...</td>\n",
       "      <td>WHEELING</td>\n",
       "      <td>WV</td>\n",
       "      <td>26003-6243</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1999467.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89997.0</td>\n",
       "      <td>Institution: Franklin Institute Science Museum...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Active Learning; Child; Computer software; des...</td>\n",
       "      <td>ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0741659</td>\n",
       "      <td>...</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>19103-1115</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1799699.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>89998.0</td>\n",
       "      <td>Through programs (including small group conver...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Address; Age; Birth; Brain; Caregivers; Child;...</td>\n",
       "      <td>BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0813522</td>\n",
       "      <td>...</td>\n",
       "      <td>SAINT PAUL</td>\n",
       "      <td>MN</td>\n",
       "      <td>55102-1202</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1505858.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>89999.0</td>\n",
       "      <td>In partnership with the American Chemical Soci...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Advanced Development; American; Chemicals; Che...</td>\n",
       "      <td>FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0838627</td>\n",
       "      <td>...</td>\n",
       "      <td>DURHAM</td>\n",
       "      <td>NC</td>\n",
       "      <td>27709-3757</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.049</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Amphibian populations around the world are exp...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Amphibia; Central America; Communicable Diseas...</td>\n",
       "      <td>COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0815315</td>\n",
       "      <td>...</td>\n",
       "      <td>ITHACA</td>\n",
       "      <td>NY</td>\n",
       "      <td>14850-2820</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.074</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>370996.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>90001.0</td>\n",
       "      <td>The Center for Molecular Interfacing (CMI) wil...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Address; Architecture; Carbon Nanotubes; Catal...</td>\n",
       "      <td>CCI PHASE I: CENTER FOR MOLECULAR INTERFACING</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0847926</td>\n",
       "      <td>...</td>\n",
       "      <td>ITHACA</td>\n",
       "      <td>NY</td>\n",
       "      <td>14850-2820</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.049</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1519821.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>90002.0</td>\n",
       "      <td>DRU: Integrated optimization of evacuation and...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Accounting; Address; Affect; American; Area; b...</td>\n",
       "      <td>DRU: INTEGRATED OPTIMIZATION OF EVACUATION AND...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0826832</td>\n",
       "      <td>...</td>\n",
       "      <td>NEWARK</td>\n",
       "      <td>DE</td>\n",
       "      <td>19716-2553</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.075</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>757499.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>90003.0</td>\n",
       "      <td>The Flora of China (FOC) is an international c...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Accounting; Biodiversity; Botanicals; China; C...</td>\n",
       "      <td>FLORA OF CHINA</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0813935</td>\n",
       "      <td>...</td>\n",
       "      <td>SAINT LOUIS</td>\n",
       "      <td>MO</td>\n",
       "      <td>63110-3420</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.074</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>90004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Fellowship Program; Research</td>\n",
       "      <td>GRADUATE RESEARCH FELLOWSHIP PROGRAM</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0852410</td>\n",
       "      <td>...</td>\n",
       "      <td>MINNEAPOLIS</td>\n",
       "      <td>MN</td>\n",
       "      <td>55455-2070</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>4642186.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>90005.0</td>\n",
       "      <td>The overall goal of this project is to reconst...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Alaska; Aleutian Islands; Arctic Regions; Area...</td>\n",
       "      <td>COLLABORATIVE RESEARCH: COUPLED GLACIAL AND LA...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0823522</td>\n",
       "      <td>...</td>\n",
       "      <td>FLAGSTAFF</td>\n",
       "      <td>AZ</td>\n",
       "      <td>86011-4130</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.050</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>357187.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original index  PROJECT_ID  \\\n",
       "0               0     89996.0   \n",
       "1               1     89997.0   \n",
       "2               2     89998.0   \n",
       "3               3     89999.0   \n",
       "4               4     90000.0   \n",
       "5               5     90001.0   \n",
       "6               6     90002.0   \n",
       "7               7     90003.0   \n",
       "8               8     90004.0   \n",
       "9               9     90005.0   \n",
       "\n",
       "                                            ABSTRACT    FY.x  \\\n",
       "0  This is a project to explore Game-based, Metap...  2008.0   \n",
       "1  Institution: Franklin Institute Science Museum...  2008.0   \n",
       "2  Through programs (including small group conver...  2008.0   \n",
       "3  In partnership with the American Chemical Soci...  2008.0   \n",
       "4  Amphibian populations around the world are exp...  2008.0   \n",
       "5  The Center for Molecular Interfacing (CMI) wil...  2008.0   \n",
       "6  DRU: Integrated optimization of evacuation and...  2008.0   \n",
       "7  The Flora of China (FOC) is an international c...  2008.0   \n",
       "8                                                NaN  2008.0   \n",
       "9  The overall goal of this project is to reconst...  2008.0   \n",
       "\n",
       "                                       PROJECT_TERMS  \\\n",
       "0  Achievement; analog; base; Cognitive Science; ...   \n",
       "1  Active Learning; Child; Computer software; des...   \n",
       "2  Address; Age; Birth; Brain; Caregivers; Child;...   \n",
       "3  Advanced Development; American; Chemicals; Che...   \n",
       "4  Amphibia; Central America; Communicable Diseas...   \n",
       "5  Address; Architecture; Carbon Nanotubes; Catal...   \n",
       "6  Accounting; Address; Affect; American; Area; b...   \n",
       "7  Accounting; Biodiversity; Botanicals; China; C...   \n",
       "8                       Fellowship Program; Research   \n",
       "9  Alaska; Aleutian Islands; Arctic Regions; Area...   \n",
       "\n",
       "                                       PROJECT_TITLE DEPARTMENT AGENCY  \\\n",
       "0  RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...        NSF    NSF   \n",
       "1  ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...        NSF    NSF   \n",
       "2  BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...        NSF    NSF   \n",
       "3  FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...        NSF    NSF   \n",
       "4  COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...        NSF    NSF   \n",
       "5      CCI PHASE I: CENTER FOR MOLECULAR INTERFACING        NSF    NSF   \n",
       "6  DRU: INTEGRATED OPTIMIZATION OF EVACUATION AND...        NSF    NSF   \n",
       "7                                     FLORA OF CHINA        NSF    NSF   \n",
       "8               GRADUATE RESEARCH FELLOWSHIP PROGRAM        NSF    NSF   \n",
       "9  COLLABORATIVE RESEARCH: COUPLED GLACIAL AND LA...        NSF    NSF   \n",
       "\n",
       "  IC_CENTER PROJECT_NUMBER  ... ORGANIZATION_CITY ORGANIZATION_STATE  \\\n",
       "0       NaN        0814512  ...          WHEELING                 WV   \n",
       "1       NaN        0741659  ...      PHILADELPHIA                 PA   \n",
       "2       NaN        0813522  ...        SAINT PAUL                 MN   \n",
       "3       NaN        0838627  ...            DURHAM                 NC   \n",
       "4       NaN        0815315  ...            ITHACA                 NY   \n",
       "5       NaN        0847926  ...            ITHACA                 NY   \n",
       "6       NaN        0826832  ...            NEWARK                 DE   \n",
       "7       NaN        0813935  ...       SAINT LOUIS                 MO   \n",
       "8       NaN        0852410  ...       MINNEAPOLIS                 MN   \n",
       "9       NaN        0823522  ...         FLAGSTAFF                 AZ   \n",
       "\n",
       "  ORGANIZATION_ZIP ORGANIZATION_COUNTRY BUDGET_START_DATE BUDGET_END_DATE  \\\n",
       "0       26003-6243        UNITED STATES               NaN             NaN   \n",
       "1       19103-1115        UNITED STATES               NaN             NaN   \n",
       "2       55102-1202        UNITED STATES               NaN             NaN   \n",
       "3       27709-3757        UNITED STATES               NaN             NaN   \n",
       "4       14850-2820        UNITED STATES               NaN             NaN   \n",
       "5       14850-2820        UNITED STATES               NaN             NaN   \n",
       "6       19716-2553        UNITED STATES               NaN             NaN   \n",
       "7       63110-3420        UNITED STATES               NaN             NaN   \n",
       "8       55455-2070        UNITED STATES               NaN             NaN   \n",
       "9       86011-4130        UNITED STATES               NaN             NaN   \n",
       "\n",
       "  CFDA_CODE    FY.y FY_TOTAL_COST FY_TOTAL_COST_SUB_PROJECTS  \n",
       "0    47.076  2008.0     1999467.0                        NaN  \n",
       "1    47.076  2008.0     1799699.0                        NaN  \n",
       "2    47.076  2008.0     1505858.0                        NaN  \n",
       "3    47.049  2008.0       51000.0                        NaN  \n",
       "4    47.074  2008.0      370996.0                        NaN  \n",
       "5    47.049  2008.0     1519821.0                        NaN  \n",
       "6    47.075  2008.0      757499.0                        NaN  \n",
       "7    47.074  2008.0      250000.0                        NaN  \n",
       "8    47.076  2008.0     4642186.0                        NaN  \n",
       "9    47.050  2008.0      357187.0                        NaN  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create subset \n",
    "smalldf  = df[:10]\n",
    "smalldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original index</th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>FY.x</th>\n",
       "      <th>PROJECT_TERMS</th>\n",
       "      <th>PROJECT_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>AGENCY</th>\n",
       "      <th>IC_CENTER</th>\n",
       "      <th>PROJECT_NUMBER</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_STATE</th>\n",
       "      <th>ORGANIZATION_ZIP</th>\n",
       "      <th>ORGANIZATION_COUNTRY</th>\n",
       "      <th>BUDGET_START_DATE</th>\n",
       "      <th>BUDGET_END_DATE</th>\n",
       "      <th>CFDA_CODE</th>\n",
       "      <th>FY.y</th>\n",
       "      <th>FY_TOTAL_COST</th>\n",
       "      <th>FY_TOTAL_COST_SUB_PROJECTS</th>\n",
       "      <th>LEMMA_ABSTRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89996.0</td>\n",
       "      <td>This is a project to explore Game-based, Metap...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Achievement; analog; base; Cognitive Science; ...</td>\n",
       "      <td>RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0814512</td>\n",
       "      <td>...</td>\n",
       "      <td>WV</td>\n",
       "      <td>26003-6243</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1999467.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[this, be, a, project, to, explore, Game, -, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89997.0</td>\n",
       "      <td>Institution: Franklin Institute Science Museum...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Active Learning; Child; Computer software; des...</td>\n",
       "      <td>ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0741659</td>\n",
       "      <td>...</td>\n",
       "      <td>PA</td>\n",
       "      <td>19103-1115</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1799699.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[institution, :, Franklin, Institute, Science,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>89998.0</td>\n",
       "      <td>Through programs (including small group conver...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Address; Age; Birth; Brain; Caregivers; Child;...</td>\n",
       "      <td>BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0813522</td>\n",
       "      <td>...</td>\n",
       "      <td>MN</td>\n",
       "      <td>55102-1202</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1505858.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[through, program, (, include, small, group, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>89999.0</td>\n",
       "      <td>In partnership with the American Chemical Soci...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Advanced Development; American; Chemicals; Che...</td>\n",
       "      <td>FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0838627</td>\n",
       "      <td>...</td>\n",
       "      <td>NC</td>\n",
       "      <td>27709-3757</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.049</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[in, partnership, with, the, American, Chemica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Amphibian populations around the world are exp...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Amphibia; Central America; Communicable Diseas...</td>\n",
       "      <td>COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0815315</td>\n",
       "      <td>...</td>\n",
       "      <td>NY</td>\n",
       "      <td>14850-2820</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.074</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>370996.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[amphibian, population, around, the, world, be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original index  PROJECT_ID  \\\n",
       "0               0     89996.0   \n",
       "1               1     89997.0   \n",
       "2               2     89998.0   \n",
       "3               3     89999.0   \n",
       "4               4     90000.0   \n",
       "\n",
       "                                            ABSTRACT    FY.x  \\\n",
       "0  This is a project to explore Game-based, Metap...  2008.0   \n",
       "1  Institution: Franklin Institute Science Museum...  2008.0   \n",
       "2  Through programs (including small group conver...  2008.0   \n",
       "3  In partnership with the American Chemical Soci...  2008.0   \n",
       "4  Amphibian populations around the world are exp...  2008.0   \n",
       "\n",
       "                                       PROJECT_TERMS  \\\n",
       "0  Achievement; analog; base; Cognitive Science; ...   \n",
       "1  Active Learning; Child; Computer software; des...   \n",
       "2  Address; Age; Birth; Brain; Caregivers; Child;...   \n",
       "3  Advanced Development; American; Chemicals; Che...   \n",
       "4  Amphibia; Central America; Communicable Diseas...   \n",
       "\n",
       "                                       PROJECT_TITLE DEPARTMENT AGENCY  \\\n",
       "0  RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...        NSF    NSF   \n",
       "1  ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...        NSF    NSF   \n",
       "2  BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...        NSF    NSF   \n",
       "3  FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...        NSF    NSF   \n",
       "4  COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...        NSF    NSF   \n",
       "\n",
       "  IC_CENTER PROJECT_NUMBER  ... ORGANIZATION_STATE ORGANIZATION_ZIP  \\\n",
       "0       NaN        0814512  ...                 WV       26003-6243   \n",
       "1       NaN        0741659  ...                 PA       19103-1115   \n",
       "2       NaN        0813522  ...                 MN       55102-1202   \n",
       "3       NaN        0838627  ...                 NC       27709-3757   \n",
       "4       NaN        0815315  ...                 NY       14850-2820   \n",
       "\n",
       "  ORGANIZATION_COUNTRY BUDGET_START_DATE BUDGET_END_DATE CFDA_CODE    FY.y  \\\n",
       "0        UNITED STATES               NaN             NaN    47.076  2008.0   \n",
       "1        UNITED STATES               NaN             NaN    47.076  2008.0   \n",
       "2        UNITED STATES               NaN             NaN    47.076  2008.0   \n",
       "3        UNITED STATES               NaN             NaN    47.049  2008.0   \n",
       "4        UNITED STATES               NaN             NaN    47.074  2008.0   \n",
       "\n",
       "  FY_TOTAL_COST FY_TOTAL_COST_SUB_PROJECTS  \\\n",
       "0     1999467.0                        NaN   \n",
       "1     1799699.0                        NaN   \n",
       "2     1505858.0                        NaN   \n",
       "3       51000.0                        NaN   \n",
       "4      370996.0                        NaN   \n",
       "\n",
       "                                      LEMMA_ABSTRACT  \n",
       "0  [this, be, a, project, to, explore, Game, -, b...  \n",
       "1  [institution, :, Franklin, Institute, Science,...  \n",
       "2  [through, program, (, include, small, group, c...  \n",
       "3  [in, partnership, with, the, American, Chemica...  \n",
       "4  [amphibian, population, around, the, world, be...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#need to install python -m spacy download en \n",
    "\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "def getLemma(abstract):\n",
    "    abstract = str(abstract)\n",
    "    doc = nlp(abstract)\n",
    "    listoflemma = []\n",
    "    for word in doc:\n",
    "        l = word.lemma_\n",
    "        listoflemma.append(l)\n",
    "    return listoflemma\n",
    "smalldf['LEMMA_ABSTRACT'] = smalldf['ABSTRACT'].apply(getLemma)\n",
    "\n",
    "smalldf['LEMMA_ABSTRACT']\n",
    "\n",
    "smalldf.head()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "#Helper Functions\n",
    "#############################################\n",
    "\n",
    "#This function was used previously, but we were unaware it had already been included in 'Cleaning', and is redundant.        \n",
    "#def remove_institution(record):\n",
    "#    \"\"\"removes all instances of exact institution name from lowercase abstract string\"\"\"\n",
    "#    org=record['ORGANIZATION_NAME']\n",
    "#    if pd.notnull(org):\n",
    "#        return record['working_abstract'].replace(org.lower(),'')\n",
    "#    else:\n",
    "#        return record['working_abstract']\n",
    "    \n",
    "def remove_custom_words(record,col_to_clean):\n",
    "    \"\"\"Designates stopwords for a particular abstract that contain embedded info e.g. author names and removes them from a lowercase abstract\"\"\"\n",
    "    fields_to_replace=[]\n",
    "    if type(record[col_to_clean])!=list:\n",
    "        return np.nan\n",
    "    else:\n",
    "        #Main PI\n",
    "        #Adds all words in the pis names, excluding initials (hence why the commas and periods must be replaced)\n",
    "        if pd.notnull(record['CONTACT_PI_PROJECT_LEADER']):\n",
    "            fields_to_replace.extend([x.lower() for x in record['CONTACT_PI_PROJECT_LEADER'].replace(',','').replace('.','').replace('-',' ').split() if len(x)>1])\n",
    "        #Additional PIs\n",
    "        #For each pi, which are split by semicolons, and format is last,first;  #Sometimes a middle initial\n",
    "        if pd.notnull(record['OTHER_PIS']):\n",
    "            for i in record['OTHER_PIS'].split(';'):\n",
    "                i=i.strip() #Remove whitespace\n",
    "                i=i.replace('.','')#Periods for initials\n",
    "                i=i.replace(',','')#Commas between last, first\n",
    "                i=i.replace('-',' ')#Remove hyphen in hypenated names to make separate words once tokens.\n",
    "                fields_to_replace.extend([x.lower().strip() for x in i.split() if len(x)>1])\n",
    "        return [x.lower() for x in record[col_to_clean] if not x.lower() in fields_to_replace]\n",
    "\n",
    "def remove_first_x_tokens(tokened_abstract,bad_start_phrases,max_tokens_to_skip=3):\n",
    "    \"\"\"removes each bad_start_phrase occuring within max_tokens_to_skip of the front--phrases must be lowered.\n",
    "    be careful calling this, as order matters! It always starts looking at the first token, which will change between runs.\n",
    "    both tokened_abstract and each phrase in bad_start_phrases must be a list, not just a string\n",
    "    eg the phrase 'overall project summary' and 'technical abstract' should be input as a list of lists: [ ['overall','project','summary'],['technical','abstract']] \"\"\"\n",
    "    assert [type(phrase)==list for phrase in bad_start_phrases] #Make sure not just a string\n",
    "    assert [type(tokened_abstract)==list]\n",
    "    if type(tokened_abstract)!=list:\n",
    "        return np.nan\n",
    "    else:\n",
    "        for token_sequence in bad_start_phrases:\n",
    "            #Look for a match within up to 3 tokens from the start. The reasoning here is some abstract start with numbers indicating sections\n",
    "            #EG 8., 8.a, 8.1.1.--from EDA of first tokens\n",
    "            for idx in range(0,max_tokens_to_skip):\n",
    "                if tokened_abstract[idx:len(token_sequence)+idx]==token_sequence:\n",
    "                    tokened_abstract=tokened_abstract[len(token_sequence)+idx:]\n",
    "                    break\n",
    "        return tokened_abstract\n",
    "\n",
    "#Original list used to remove--must be updated now that lemmatization occurs before\n",
    "#start_phrases_to_remove=[['section'],['abstract'],['contact','pd','pi'],['technical'],['nontechnical'],['non','technical'],\n",
    "#                         ['project','summary','abstract'], ['overall','project','summary'],['project','abstract'],\n",
    "#                        ['project','narrative'],['abstract'],['summary'],['description','provided','by','the','applicant'],\n",
    "#                         ['description','provided','by','applicant'],['description','provided','by','candidate'],\n",
    "#                         ['provided','by','investigator'], ['provided','by','the','investigator'],['description']]\n",
    "\n",
    "start_phrases_to_remove=[['section'],['abstract'],['contact','pd','pi'],['nontechnical'],['non','technical'], ['non-technical'],['technical'],\n",
    "                         ['project','summary','abstract'], ['overall','project','summary'],['project','abstract'],\n",
    "                        ['project','narrative'],['abstract'],['summary'],['description','provide','applicant'],\n",
    "                         ['description','provide','applicant'],['description','provide','candidate'],\n",
    "                         ['provide','investigator'],['description']]\n",
    "\n",
    "\"\"\"\n",
    "#Prior function which used the spacy module--but spacy is not 'research-grade'\n",
    "def lemmatize_spacy(doc,punctuation_or_token='token'):\n",
    "\"\"\"\n",
    "\"\"\"use spacy to lemmatize a document. token takes a list of strings and is then turned into a string once again. Punctuation takes one string with punctuation and parses by sentence\"\"\"\n",
    "\"\"\"\n",
    "    assert punctuation_or_token in ['token','punctuation']\n",
    "    if punctuation_or_token=='token':\n",
    "        sentence=sp(' '.join(doc))\n",
    "    elif punctuation_or_token=='punctuation':\n",
    "        sentence=sp(doc)\n",
    "    new_tokens=[]\n",
    "    for word in sentence:\n",
    "        if word.pos_ in ['NOUN','VERB','ADJ','ADV']:\n",
    "            new_tokens.append(word.lemma_)\n",
    "        elif word.pos_ in ['PROPN','NUM','X','INTJ']:\n",
    "            new_tokens.append(word.text)\n",
    "    return new_tokens\n",
    "\"\"\"    \n",
    "def lemmatize_stanford(doc,pretokened=False,keep_numbers=True):\n",
    "    \"\"\"if pretokened, dont use this function, as it hasnt been adapted for it\"\"\"\n",
    "    ##to compare lemmatization functions, try test cases 463, 40, and 2247 (iloc)\n",
    "    assert not pretokened #If these are already tokened per another pipeline, this function won't work correctly\n",
    "    new_tokens=[]\n",
    "    if doc==' ': #Quirk that somehow two empty abstracts were not caught\n",
    "        return np.nan #Produces null abstracts that can mess up your code if you're not careful\n",
    "    else: \n",
    "        processed=nlp(doc)\n",
    "        print(processed)\n",
    "        for sent in processed.sentences:\n",
    "            for word in sent.words:\n",
    "                #If its a regular noun, verb, adj, or adverb, keep lemmatized form\n",
    "                if word.pos in ['NOUN','VERB','ADJ','ADV']:\n",
    "                    new_tokens.append(word.lemma)\n",
    "                #If you decided to retain numbers, their lemma is kept here. Note that number catching isnt perfect by this lemmatizing.\n",
    "                elif word.pos=='NUM' and keep_numbers:\n",
    "                    new_tokens.append(word.lemma)\n",
    "                #Exact phrases are kept here with no attempt at lemmatization: e.g. mars does not become mars, and hopefully scientific words e.g. chemicals will be tagged as propn, x, or intj if needed\n",
    "                elif word.pos in ['PROPN','X','INTJ']: \n",
    "                    new_tokens.append(word.text)\n",
    "                #Note that no other tokens are kept\n",
    "        return new_tokens\n",
    "\n",
    "\n",
    "def create_stopwords():\n",
    "    \"\"\" creates list of stopwords. stop words include the general English list and any additional we see sneaking through\n",
    "    #We no longer remove words specific to the corpus that do not aid in meaning like science/research\"\"\"\n",
    "    \n",
    "    stopWords = set(nltk.corpus.stopwords.words('english'))\n",
    "    \n",
    "    # format stop words the same way we formatted our corpus, ie. without apostrophes.  \n",
    "    stop_wds = stopWords.copy()\n",
    "    for word in stopWords:\n",
    "        if \"\\'\" in word:\n",
    "            stop_wds.discard(word)\n",
    "            stop_wds.add(word.replace(\"\\'\",\"\"))\n",
    "    \n",
    "    # more stop words that do not add meaning to topics\n",
    "    additional_stopwords=['another','well','addition', 'thus',\n",
    "                      'specifically', 'similar','including',\n",
    "                       'via','within', 'thus', 'particular', 'furthermore','include','also',\n",
    "                      'includes','however','whether','due', 'may','overall', 'whether','could',\n",
    "                      'many','finally', 'several', 'specific', 'additional', 'therefore', 'either', 'various',\n",
    "                       'within', 'among', 'would','research','project','subproject','1','cells','cell','2','data',\n",
    "                        'studies','development','study','specific','health','cancer','disease','3','provide','clinical','aim','based',\n",
    "                        'provided', 'program','human','pateints','understanding'] \n",
    "        \n",
    "    sw = stop_wds.union(additional_stopwords)\n",
    "    \n",
    "    return sw\n",
    "\n",
    "def remove_stopwords(doc, stop_words):\n",
    "    \"\"\"remove stopwords\"\"\"\n",
    "    #If no acceptable tokens, this is np.nan\n",
    "    if type(doc)!=list:\n",
    "        return np.nan\n",
    "    \n",
    "    return [word for word in doc if word not in stop_words] \n",
    "\n",
    "def apply_n_grams(abstract,function):\n",
    "    \"\"\"apply an n-gram--could be bi or tri gram--to abstract\"\"\"\n",
    "    #Non lists--aka no acceptable tokens\n",
    "    if type(abstract)==list:\n",
    "        return function[abstract]\n",
    "    else:\n",
    "        return abstract\n",
    "\n",
    "\n",
    "    import re\n",
    "\n",
    "def clean_up_tokens(doc):\n",
    "    \"\"\"determines for each doc which tokens to clean up formatting further in keep_token, and decides which of these cleaned up tokens will be kept\"\"\"\n",
    "    kept_tokens=[]\n",
    "    #Ignores documents that are abstracts with no valid tokens\n",
    "    if type(doc)!=list:\n",
    "        return np.nan\n",
    "    else:\n",
    "        for token in doc:\n",
    "            keep,altered_token=keep_token(token)\n",
    "            if keep:\n",
    "                kept_tokens.append(altered_token)\n",
    "        return kept_tokens\n",
    "        \n",
    "def keep_token(token):\n",
    "    \"\"\"strips hyphens, replaces internal hyphens with _, turns non-alphanumeric tokens into alphanumerics', strips leading _ if produced by alphamumeric,\n",
    "    then removes those updated tokens that: are numeric but not length 4, are tokens related to college names (see below) or are less than length 2.\"\"\"\n",
    "    token=token.strip('- ') #Removes leading and trailing hyphens\n",
    "    token=token.replace('-','_')\n",
    "    if not str.isalnum(token):\n",
    "        token=re.sub(r'\\W+', '', token)\n",
    "    token=token.strip('_')\n",
    "    #Names of universities\n",
    "    if 'university' in token or 'college' in token or 'universities' in token:\n",
    "        return (not token in college_tokens, token)\n",
    "    if str.isnumeric(token):\n",
    "        #keep years\n",
    "        return (len(token)==4,token)\n",
    "    else:\n",
    "        #Keep anything that is alphanumeric or alpha if its over length 2--allows mixed types e.g. h1n1\n",
    "        return (len(token)>=2,token)\n",
    "\n",
    "\n",
    "\n",
    "#Any specific university word is removed--schools within college/university, college names, etc. that cannot apply to multiple schools\n",
    "#This list was generated from all tokens that contained the string 'college','university',or 'universities'. The commented out parts of the list are terms\n",
    "#That could be considered \"generic\" ie apply to more than one school\n",
    "college_tokens=[#'college',\n",
    "'aga_khan_university',\n",
    "'ahmadu_bello_university',\n",
    "'alabama_aamp_university',\n",
    "'albert_einstein_college',\n",
    "'alcorn_state_university',\n",
    "'american_college_obstetricians',\n",
    "'american_college_surgeons',\n",
    "'americancollege',\n",
    "#'amongcollege',\n",
    "#'anduniversity',\n",
    "'anne_molloy_trinity_college',\n",
    "#'atuniversity',\n",
    "'auburn_university',\n",
    "'auburn_university_alabama',\n",
    "'auburn_university_au',\n",
    "'auburn_university_auburn',\n",
    "'auburn_university_montgomery',\n",
    "'auburn_university_tuskegee_university',\n",
    "'augustana_college',\n",
    "#'auniversity',\n",
    "'babes_bolyai_university',\n",
    "'barnard_college',\n",
    "'baruch_college',\n",
    "'bates_college',\n",
    "'baylor_college',\n",
    "'baylor_college_dentistry',\n",
    "'baylor_college_medicine',\n",
    "'baylor_college_ofmedicine',\n",
    "'baylor_collegeof',\n",
    "'baylorcollege_medicine',\n",
    "'baylorcollege_medicine_bcm',\n",
    "'ben_gurion_university',\n",
    "'benedict_college',\n",
    "'benedict_college_historically_black',\n",
    "'berea_college',\n",
    "'binghamton_university',\n",
    "#'black_colleges',\n",
    "'board_trinity_college',\n",
    "'bostonuniversity',\n",
    "'bowdoin_college',\n",
    "'brownuniversity',\n",
    "'bryn_mawr_college',\n",
    "'bucknell_university',\n",
    "#'cape_universities',\n",
    "'cardiff_university',\n",
    "'carleton_college',\n",
    "'carnegie_mellon_university',\n",
    "'carver_college',\n",
    "'carver_college_medicine',\n",
    "'case_western_reserveuniversity',\n",
    "'case_westernreserve_university',\n",
    "'catholic_university',\n",
    "'cerritos_college',\n",
    "'charles_drew_university',\n",
    "'chulalongkorn_university',\n",
    "'chulalongkorn_university_bangkok_thailand',\n",
    "'claflin_university',\n",
    "'claremont_colleges',\n",
    "'clark_atlanta_university',\n",
    "'colby_college',\n",
    "'colby_sawyer_college',\n",
    "#'college',\n",
    "#'college',\n",
    "#'college_american_pathologists',\n",
    "#'college_arts',\n",
    "#'college_arts_sciences',\n",
    "'college_brockport',\n",
    "'college_dentistry_nyucd',\n",
    "'college_dentistry_ufcd',\n",
    "#'college_goer',\n",
    "#'college_graduates',\n",
    "#'college_letters',\n",
    "#'college_letters_arts_sciences',\n",
    "#'college_letters_sciences',\n",
    "'college_lewiston',\n",
    "#'college_liberal_arts',\n",
    "'college_london',\n",
    "'college_medicine_aecom',\n",
    "'college_medicine_uccom',\n",
    "'college_menominee_nation',\n",
    "#'college_optometry',\n",
    "#'college_osteopathic_medicine',\n",
    "'college_park_umcp',\n",
    "'college_park_umd',\n",
    "#'college_physicians_surgeons',\n",
    "#'college_rheumatology_acr',\n",
    "'college_south_hadley',\n",
    "#'college_sports_medicine',\n",
    "'college_st_scholastica',\n",
    "'college_staten_island',\n",
    "#'college_students_basics',\n",
    "#'college_veterinary_medicine',\n",
    "#'college_veterinary_pathologists',\n",
    "#'college_veterinarymedicine',\n",
    "'college_wcmc',\n",
    "'college_wcmc_rockefeller_university',\n",
    "'college_william_mary',\n",
    "'college_wisconsin_mcw',\n",
    "'college_wooster',\n",
    "#'collegeand',\n",
    "#'collegeof',\n",
    "#'collegeof_medicine',\n",
    "#'colleges',\n",
    "#'colleges_arts_sciences',\n",
    "#'colleges_chicago',\n",
    "#'colleges_dentistry',\n",
    "#'colleges_dentistry_medicine',\n",
    "#'colleges_optometry',\n",
    "'colleges_rcc_umb', #Iffy--not sure what this is\n",
    "#'colleges_schools',\n",
    "#'colleges_universities',\n",
    "#'colleges_universities_hacu',\n",
    "#'collegesand',\n",
    "#'collegestudent',\n",
    "'columbia_university',\n",
    "'columbiauniversity',\n",
    "'comanche_nation_college',\n",
    "#'communitycollege',\n",
    "'creighton_university',\n",
    "'cross_university',\n",
    "'cross__university',\n",
    "'cuny_hunter_college',\n",
    "'del_mar_college',\n",
    "'depaul_university',\n",
    "'dine_college',\n",
    "'din_college',\n",
    "'diné_college',\n",
    "'diplomate_american_college',\n",
    "'doane_college',\n",
    "'doron_levy_university_maryland',\n",
    "'dukeuniversity',\n",
    "'eckerd_college',\n",
    "'emoryuniversity',\n",
    "'famu_fsu_college',\n",
    "'fort_lewis_college',\n",
    "'franklin_marshall_college',\n",
    "'fudan_university',\n",
    "'fudan_university_shanghai',\n",
    "'fudan_university_shanghai_china',\n",
    "'gallaudet_university',\n",
    "'george_mason_university',\n",
    "'george_washington_university',\n",
    "'georgetown_howard_universities',\n",
    "'georgetown_university',\n",
    "'georgia_regents_university',\n",
    "'gettysburg_college',\n",
    "#'grant_universities_aplu',\n",
    "'gu_howard_university',\n",
    "'hackensack_university',\n",
    "'hampton_university',\n",
    "'hanyang_university',\n",
    "'hartnell_college',\n",
    "'harvarduniversity',\n",
    "'harvey_mudd_college',\n",
    "#'historically_black_college',\n",
    "#'historically_black_colleges',\n",
    "#'historically_black_colleges_universities',\n",
    "'hokkaido_university',\n",
    "'hold_bates_college',\n",
    "'hold_colby_sawyer_college',\n",
    "'hold_stonehill_college_easton',\n",
    "'honors_college',\n",
    "'houston_baylor_college',\n",
    "'hunter_college',\n",
    "'imperial_college',\n",
    "'imperial_college_london',\n",
    "'imperial_college_london_uk',\n",
    "#'incollege',\n",
    "'indiana_university',\n",
    "'indianauniversity',\n",
    "#'inspect_certified_college',\n",
    "#'inter_college',\n",
    "#'inter_university',\n",
    "#'inter_university_consortium_political',\n",
    "#'interuniversity',\n",
    "#'interuniversity_consortium_political',\n",
    "#'intra_university',\n",
    "'james_cook_university',\n",
    "'james_madison_university',\n",
    "'jeffersonuniversity',\n",
    "'john_jay_college',\n",
    "'johns_hopkinsuniversity',\n",
    "'kennesaw_state_university',\n",
    "'king_college_london',\n",
    "'kwame_nkrumah_university',\n",
    "'kyoto_university',\n",
    "'kyushu_university',\n",
    "'langston_university',\n",
    "'lehman_college',\n",
    "'lehman_college_city',\n",
    "'lehman_college_cuny',\n",
    "'lemoyne_owen_college',\n",
    "'lewis_clark_college',\n",
    "#'liberal_art_college',\n",
    "'louisiana_universities_marine',\n",
    "'loyola_marymount_university',\n",
    "'loyola_university',\n",
    "'loyola_university_chicago',\n",
    "'macalester_college',\n",
    "'makerere_university',\n",
    "'makerere_university_kampala_uganda',\n",
    "'makerere_university_uganda',\n",
    "'makerereuniversity',\n",
    "'marquette_university',\n",
    "'marquette_university_milwaukee',\n",
    "'mbarara_university',\n",
    "'mcgill_university',\n",
    "'mcmaster_university',\n",
    "'medgar_evers_college',\n",
    "'medical_colleges_aamc',\n",
    "'medicalcollege',\n",
    "'medicaluniversity_south_carolina',\n",
    "'medicine_yeshiva_university',\n",
    "'meharrymedical_college',\n",
    "'mellon_university',\n",
    "'mellonuniversity',\n",
    "'mexico_highlands_university',\n",
    "'miami_dade_college',\n",
    "'middlebury_college',\n",
    "'millsaps_college',\n",
    "'monash_university',\n",
    "'monash_university_australia',\n",
    "#'montana_tribal_college',\n",
    "#'montana_tribal_colleges',\n",
    "'montclair_state_university',\n",
    "'morehouse_college',\n",
    "'morehouse_college_spelman_college',\n",
    "'mount_holyoke_college',\n",
    "'msm_tuskegee_university',\n",
    "'mt_marty_college',\n",
    "'muhimbili_university',\n",
    "#'multi_university',\n",
    "#'muniversity',\n",
    "'nakoda_college',\n",
    "'nanyang_technological_university',\n",
    "'nazarene_university',\n",
    "'nazareth_college',\n",
    "#'non_college',\n",
    "#'non_university',\n",
    "'northern_arizona_university',\n",
    "'northern_kentucky_university',\n",
    "'northshore_university',\n",
    "'northshore_university_healthsystem',\n",
    "'northwest_nazarene_university',\n",
    "'northwestern_university',\n",
    "'norwich_university',\n",
    "#'ofuniversity',\n",
    "'oglala_lakota_college',\n",
    "'ohio_stateuniversity',\n",
    "'old_dominion_university',\n",
    "'olin_college',\n",
    "#'otheruniversity',\n",
    "#'participatinguniversity',\n",
    "'pasadena_city_college',\n",
    "'peking_university',\n",
    "'peking_university_beijing_china',\n",
    "'pennsylvania_college_optometry',\n",
    "#'phduniversity',\n",
    "#'polytechnic_university',\n",
    "#'post__college',\n",
    "'prairie_view_university',\n",
    "#'pre_college',\n",
    "#'pre_university',\n",
    "#'pre__college',\n",
    "#'precollege',\n",
    "'queens_college',\n",
    "'regents_university',\n",
    "'researchuniversity',\n",
    "'rockefeller_university',\n",
    "'rockefeller_university_memorial_sloan',\n",
    "'rockefeller_university_ru',\n",
    "'rockefeller_university_weill_cornell',\n",
    "'rockefelleruniversity',\n",
    "'royal_college_surgeons',\n",
    "'rutgers_university',\n",
    "'rutgersuniversity',\n",
    "'saddleback_college',\n",
    "'saginaw_chippewa_tribal_college',\n",
    "'saint_michael_college',\n",
    "'salish_kootenai_college',\n",
    "'salve_regina_university',\n",
    "'sawyer_college',\n",
    "#'scienceuniversity', #This is likely ohsu, as bellow, but for parsimony, this is kept\n",
    "'scienceuniversity_ohsu',\n",
    "'serc_carleton_college',\n",
    "'shams_university',\n",
    "'shams_university_cairo_egypt',\n",
    "'shanghai_jiaotong_university',\n",
    "'simon_fraser_university',\n",
    "'sinte_gleska_university',\n",
    "'sisseton_wahpeton_college',\n",
    "'sitting_bull_college',\n",
    "'skc_tribal_college',\n",
    "'sokoine_university',\n",
    "'south_africa_university_witwatersrand',\n",
    "'southern_illinois_university_carbondale',\n",
    "'southern_illinois_university_edwardsville',\n",
    "'southern_methodist_university',\n",
    "'spelman_college',\n",
    "'st_edward_university',\n",
    "'st_mary_college',\n",
    "'st_olaf_college',\n",
    "'st_philip_college',\n",
    "'stanforduniversity',\n",
    "'state_university_dominguez', #Specific university\n",
    "#'stateuniversity', #This could be any state\n",
    "'stellenbosch_university',\n",
    "'stellenbosch_university_south_africa',\n",
    "'stonehill_college',\n",
    "'stonehill_college_easton_massachusetts',\n",
    "'stony_brook_university',\n",
    "'swarthmore_college',\n",
    "'tarrant_county_college',\n",
    "'tel_aviv_university',\n",
    "'templeuniversity',\n",
    "'texas_a_university',\n",
    "'texas_southmost_college',\n",
    "'texas_university_kingsville',\n",
    "#'thecollege',\n",
    "#'theuniversity',\n",
    "'theuniversity_california_san',\n",
    "'theuniversity_colorado',\n",
    "'theuniversity_maryland',\n",
    "'theuniversity_michigan',\n",
    "'theuniversity_minnesota',\n",
    "'theuniversity_north_carolina',\n",
    "'theuniversity_pennsylvania',\n",
    "'theuniversity_pittsburgh',\n",
    "'tougaloo_college',\n",
    "#'touniversity',\n",
    "#'triangle_universities_nuclear', #this is a government research center\n",
    "#'tribal_college',\n",
    "'tribal_college_haskell_indian', #specific university\n",
    "#'tribal_colleges',\n",
    "#'tribal_colleges_universities',\n",
    "#'tribal_colleges_universities_tcus',\n",
    "'trinity_college',\n",
    "'trinity_college_arts_sciences',\n",
    "'trinity_college_dublin',\n",
    "'tsinghua_university',\n",
    "'tsinghua_university_beijing',\n",
    "'tsinghua_university_beijing_china',\n",
    "'tsinghua_university_china',\n",
    "#'tsinghua_university_prof_roberto',\n",
    "'tulaneuniversity',\n",
    "'tuskegee_universities',\n",
    "'tuskegee_university',\n",
    "'tuskegee_university_hbcu',\n",
    "'uams_colleges',\n",
    "'ucsf_makerere_university',\n",
    "'umbc_university_maryland',\n",
    "'uniformed_services_university',\n",
    "'united_negro_college',\n",
    "#'universities',\n",
    "#'universities_aau', #this is an association of universities, not a university\n",
    "#'universities_hbcu',\n",
    "'universities_kansas_ku',\n",
    "#'universitiesand',\n",
    "#'universitiesin',\n",
    "#'university',\n",
    "#'university',\n",
    "'university_alabama_birmingham',\n",
    "'university_alabama_huntsville',\n",
    "'university_alabama_tuscaloosa',\n",
    "'university_alabama_ua',\n",
    "'university_alaska_anchorage',\n",
    "'university_alaska_fairbanks',\n",
    "'university_albany_suny',\n",
    "'university_arizona_ua',\n",
    "'university_arkansas_fayetteville',\n",
    "'university_arkansas_pine',\n",
    "'university_arkansas_ua',\n",
    "'university_buffalo_suny',\n",
    "'university_buffalo_ub',\n",
    "'university_california_berkeley',\n",
    "'university_california_davis',\n",
    "'university_california_irvine',\n",
    "'university_california_los',\n",
    "'university_california_merced',\n",
    "'university_california_riverside',\n",
    "'university_california_san',\n",
    "'university_california_sanfrancisco',\n",
    "'university_california_santa',\n",
    "'university_cincinnati_cincinnati',\n",
    "'university_college_dublin',\n",
    "'university_college_london',\n",
    "'university_colorado_anschutz',\n",
    "'university_colorado_boulder',\n",
    "'university_colorado_denver',\n",
    "'university_connecticut_uconn',\n",
    "'university_feinberg_school',\n",
    "'university_florida_gainesville',\n",
    "'university_florida_uf',\n",
    "'university_fullerton_csuf',\n",
    "'university_georgia_athens',\n",
    "'university_georgia_uga',\n",
    "'university_hawaii_hilo',\n",
    "'university_hawaii_manoa',\n",
    "'university_hawaii_uh',\n",
    "'university_hospitals_cleveland',\n",
    "'university_houston_downtown',\n",
    "'university_houston_uh',\n",
    "'university_illinois_chicago',\n",
    "'university_illinois_urbana',\n",
    "'university_indianapolis_iupui',\n",
    "'university_kansas_ku',\n",
    "'university_kansas_lawrence',\n",
    "'university_kingsville',\n",
    "'university_langone_medical',\n",
    "'university_louisiana_lafayette',\n",
    "'university_louisiana_monroe',\n",
    "'university_maryland',\n",
    "'university_maryland_baltimore',\n",
    "'university_maryland_baltimore_county',\n",
    "'university_maryland_baltimore_umb',\n",
    "'university_maryland_eastern_shore',\n",
    "'university_maryland_greenebaum',\n",
    "'university_maryland_marlene_stewart', \n",
    "'university_maryland_umd',\n",
    "'university_massachusetts_amherst',\n",
    "'university_massachusetts_dartmouth',\n",
    "'university_massachusetts_lowell',\n",
    "'university_massachusetts_umass',\n",
    "'university_miami_miller',\n",
    "'university_miami_um',\n",
    "'university_michigan_ann',\n",
    "'university_michigan_dearborn',\n",
    "'university_michigan_um',\n",
    "'university_minnesota',\n",
    "'university_minnesota_duluth',\n",
    "'university_minnesota_masonic',\n",
    "'university_minnesota_minneapolis',\n",
    "'university_minnesota_twin',\n",
    "'university_minnesota_umn',\n",
    "'university_missouri__columbia',\n",
    "'university_missouri_columbia',\n",
    "'university_missouri_kansas',\n",
    "'university_missouri_mu',\n",
    "'university_missouri_rolla',\n",
    "'university_missouri_st',\n",
    "'university_nebraska_lincoln',\n",
    "'university_nebraska_omaha',\n",
    "'university_nevada_las',\n",
    "'university_nevada_reno',\n",
    "'university_northcarolina_chapel',\n",
    "'university_northridge_csun',\n",
    "'university_ofalabama',\n",
    "'university_ofcalifornia',\n",
    "'university_ofcolorado',\n",
    "'university_ofmichigan',\n",
    "'university_ofminnesota',\n",
    "'university_ofpennsylvania',\n",
    "'university_ofrochester',\n",
    "'university_oftexas',\n",
    "'university_ofwashington',\n",
    "'university_ofwashington_uw',\n",
    "'university_ofwisconsin',\n",
    "'university_ofwisconsin_madison',\n",
    "'university_oklahoma_norman',\n",
    "'university_oklahoma_ou',\n",
    "'university_pennsylvania_upenn',\n",
    "'university_pittsburgh_pitt',\n",
    "'university_singapore_nus',\n",
    "'university_singapore_singapore',\n",
    "'university_tennessee_chattanooga',\n",
    "'university_tennessee_knoxville',\n",
    "'university_tennessee_memphis',\n",
    "'university_texas_arlington',\n",
    "'university_texas_austin',\n",
    "'university_texas_brownsville',\n",
    "'university_texas_dallas',\n",
    "'university_texas_el',\n",
    "'university_texas_pan',\n",
    "'university_texas_rio',\n",
    "'university_texas_southwestern',\n",
    "'university_texas_tyler',\n",
    "'university_toronto_toronto',\n",
    "'university_venda',\n",
    "'university_vermont_burlington',\n",
    "'university_vermont_uvm',\n",
    "'university_virginia_charlottesville',\n",
    "'university_virginia_uva',\n",
    "'university_washington_seattle',\n",
    "'university_washington_uw',\n",
    "'university_waterloo',\n",
    "'university_west_indies',\n",
    "'university_wisconsin_carbone',\n",
    "'university_wisconsin_eau',\n",
    "'university_wisconsin_madison',\n",
    "'university_wisconsin_milwaukee',\n",
    "'university_wisconsin_oshkosh',\n",
    "'university_wisconsin_platteville',\n",
    "'university_wisconsin_stout',\n",
    "'university_witwatersrand',\n",
    "'university_witwatersrand_south_africa',\n",
    "'university_witwatersrand_wits',\n",
    "#'universityabstract',\n",
    "#'universityand',\n",
    "#'universitycareer',\n",
    "#'universityco',\n",
    "#'universityhospitals',\n",
    "#'universityin',\n",
    "#'universityintellectual',\n",
    "#'universitymedical',\n",
    "#'universityof',\n",
    "'universityof_california_san',\n",
    "'universityof_chicago',\n",
    "'universityof_colorado',\n",
    "'universityof_kentucky',\n",
    "'universityof_michigan',\n",
    "'universityof_minnesota',\n",
    "'universityof_pennsylvania',\n",
    "'universityof_pittsburgh',\n",
    "'universityof_washington',\n",
    "#'universityproposal',\n",
    "#'universityresources',\n",
    "#'universitys',\n",
    "#'universityschool_medicine',\n",
    "#'universitytitle',\n",
    "'urmc_college_arts',\n",
    "'vanderbiltuniversity',\n",
    "'virginia_commonwealth_university',\n",
    "'wake_forest_university',\n",
    "'washingtonuniversity',\n",
    "'wayne_stateuniversity',\n",
    "'weinberg_college_arts',\n",
    "'wellesley_college',\n",
    "'wesley_college',\n",
    "'western_ontario_mcmaster_universities',\n",
    "'western_ontario_mcmasters_universities',\n",
    "'westminster_college',\n",
    "#'withuniversity',\n",
    "'xiamen_university',\n",
    "'xiamen_university_china',\n",
    "'yaleuniversity',\n",
    "'yeshiva_university',\n",
    "'yonsei_university',\n",
    "'yonsei_university_seoul_south',\n",
    "'yorkuniversity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf['LEMMA_ABSTRACT'].fillna(value=np.nan,inplace=True)\n",
    "no_pis=smalldf.apply(lambda x: remove_custom_words(x,'LEMMA_ABSTRACT'),axis=1)\n",
    "\n",
    "#no_pis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pis_no_start=no_pis.apply(remove_first_x_tokens,args=[start_phrases_to_remove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#Remove stopwords--nltk and those added on in 'additional_stopwords' function\n",
    "stopWords = create_stopwords()\n",
    "#tokened_docs_nostop = TextCleaning.remove_stopwords(no_pis, stopWords) #Old code--does not account for non list documents\n",
    "tokened_docs_nostop = no_pis_no_start.apply(remove_stopwords,args=[stopWords])\n",
    "smalldf['tokened_docs_nostop'] = tokened_docs_nostop\n",
    "\n",
    "#smalldf['tokened_docs_nostop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [explore, game, -, base, ,, metaphor, enhanced...\n",
       "1    [institution, :, franklin, institute, science,...\n",
       "2    [(, small, group, conversation, ,, citizen, co...\n",
       "3    [partnership, american, chemical, society, (, ...\n",
       "4    [amphibian, population, around, world, experie...\n",
       "5    [center, molecular, interfacing, (, cmi, ), en...\n",
       "6    [dru, :, integrate, optimization, evacuation, ...\n",
       "7    [flora, china, (, foc, ), international, colla...\n",
       "8                                                [nan]\n",
       "9    [goal, reconstruct, low, -, frequency, behavio...\n",
       "Name: tns_bi_tri_docs, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note that this is not trained on null abstracts\n",
    "bigram = gensim.models.Phrases(smalldf['tokened_docs_nostop'].dropna(), min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "#This function will return a bigram if\n",
    "bigram_docs=smalldf['tokened_docs_nostop'].apply(lambda x: apply_n_grams(x,bigram))\n",
    "trigram = gensim.models.Phrases(bigram_docs.dropna(), threshold=100)  \n",
    "tri_docs =bigram_docs.apply(lambda x: apply_n_grams(x,trigram))\n",
    "smalldf['tns_bi_tri_docs'] = tri_docs\n",
    "##################\n",
    "#Create bigrams and trigrams\n",
    "###################\n",
    "#Note that this is not trained on null abstracts\n",
    "bigram = gensim.models.Phrases(smalldf['tokened_docs_nostop'].dropna(), min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "#This function will return a bigram if\n",
    "bigram_docs=smalldf['tokened_docs_nostop'].apply(lambda x: apply_n_grams(x,bigram))\n",
    "trigram = gensim.models.Phrases(bigram_docs.dropna(), threshold=100)  \n",
    "tri_docs =bigram_docs.apply(lambda x: apply_n_grams(x,trigram))\n",
    "smalldf['tns_bi_tri_docs'] = tri_docs\n",
    "smalldf['tns_bi_tri_docs'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "smalldf['clean_tokens']=smalldf['tns_bi_tri_docs'].apply(clean_up_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed text\n",
    "smalldf.to_pickle(\"spacy_processed_smalldataset_stanford_lemma.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original index</th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>FY.x</th>\n",
       "      <th>PROJECT_TERMS</th>\n",
       "      <th>PROJECT_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>AGENCY</th>\n",
       "      <th>IC_CENTER</th>\n",
       "      <th>PROJECT_NUMBER</th>\n",
       "      <th>...</th>\n",
       "      <th>BUDGET_START_DATE</th>\n",
       "      <th>BUDGET_END_DATE</th>\n",
       "      <th>CFDA_CODE</th>\n",
       "      <th>FY.y</th>\n",
       "      <th>FY_TOTAL_COST</th>\n",
       "      <th>FY_TOTAL_COST_SUB_PROJECTS</th>\n",
       "      <th>LEMMA_ABSTRACT</th>\n",
       "      <th>tokened_docs_nostop</th>\n",
       "      <th>tns_bi_tri_docs</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89996.0</td>\n",
       "      <td>This is a project to explore Game-based, Metap...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Achievement; analog; base; Cognitive Science; ...</td>\n",
       "      <td>RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0814512</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1999467.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[this, be, a, project, to, explore, Game, -, b...</td>\n",
       "      <td>[explore, game, -, base, ,, metaphor, enhanced...</td>\n",
       "      <td>[explore, game, -, base, ,, metaphor, enhanced...</td>\n",
       "      <td>[explore, game, base, metaphor, enhanced, game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89997.0</td>\n",
       "      <td>Institution: Franklin Institute Science Museum...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Active Learning; Child; Computer software; des...</td>\n",
       "      <td>ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0741659</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1799699.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[institution, :, Franklin, Institute, Science,...</td>\n",
       "      <td>[institution, :, franklin, institute, science,...</td>\n",
       "      <td>[institution, :, franklin, institute, science,...</td>\n",
       "      <td>[institution, franklin, institute, science, mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>89998.0</td>\n",
       "      <td>Through programs (including small group conver...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Address; Age; Birth; Brain; Caregivers; Child;...</td>\n",
       "      <td>BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0813522</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1505858.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[through, program, (, include, small, group, c...</td>\n",
       "      <td>[(, small, group, conversation, ,, citizen, co...</td>\n",
       "      <td>[(, small, group, conversation, ,, citizen, co...</td>\n",
       "      <td>[small, group, conversation, citizen, conferen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>89999.0</td>\n",
       "      <td>In partnership with the American Chemical Soci...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Advanced Development; American; Chemicals; Che...</td>\n",
       "      <td>FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0838627</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.049</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[in, partnership, with, the, American, Chemica...</td>\n",
       "      <td>[partnership, american, chemical, society, (, ...</td>\n",
       "      <td>[partnership, american, chemical, society, (, ...</td>\n",
       "      <td>[partnership, american, chemical, society, acs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Amphibian populations around the world are exp...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Amphibia; Central America; Communicable Diseas...</td>\n",
       "      <td>COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0815315</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.074</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>370996.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[amphibian, population, around, the, world, be...</td>\n",
       "      <td>[amphibian, population, around, world, experie...</td>\n",
       "      <td>[amphibian, population, around, world, experie...</td>\n",
       "      <td>[amphibian, population, around, world, experie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original index  PROJECT_ID  \\\n",
       "0               0     89996.0   \n",
       "1               1     89997.0   \n",
       "2               2     89998.0   \n",
       "3               3     89999.0   \n",
       "4               4     90000.0   \n",
       "\n",
       "                                            ABSTRACT    FY.x  \\\n",
       "0  This is a project to explore Game-based, Metap...  2008.0   \n",
       "1  Institution: Franklin Institute Science Museum...  2008.0   \n",
       "2  Through programs (including small group conver...  2008.0   \n",
       "3  In partnership with the American Chemical Soci...  2008.0   \n",
       "4  Amphibian populations around the world are exp...  2008.0   \n",
       "\n",
       "                                       PROJECT_TERMS  \\\n",
       "0  Achievement; analog; base; Cognitive Science; ...   \n",
       "1  Active Learning; Child; Computer software; des...   \n",
       "2  Address; Age; Birth; Brain; Caregivers; Child;...   \n",
       "3  Advanced Development; American; Chemicals; Che...   \n",
       "4  Amphibia; Central America; Communicable Diseas...   \n",
       "\n",
       "                                       PROJECT_TITLE DEPARTMENT AGENCY  \\\n",
       "0  RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...        NSF    NSF   \n",
       "1  ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...        NSF    NSF   \n",
       "2  BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...        NSF    NSF   \n",
       "3  FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...        NSF    NSF   \n",
       "4  COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...        NSF    NSF   \n",
       "\n",
       "  IC_CENTER PROJECT_NUMBER  ... BUDGET_START_DATE BUDGET_END_DATE CFDA_CODE  \\\n",
       "0       NaN        0814512  ...               NaN             NaN    47.076   \n",
       "1       NaN        0741659  ...               NaN             NaN    47.076   \n",
       "2       NaN        0813522  ...               NaN             NaN    47.076   \n",
       "3       NaN        0838627  ...               NaN             NaN    47.049   \n",
       "4       NaN        0815315  ...               NaN             NaN    47.074   \n",
       "\n",
       "     FY.y FY_TOTAL_COST FY_TOTAL_COST_SUB_PROJECTS  \\\n",
       "0  2008.0     1999467.0                        NaN   \n",
       "1  2008.0     1799699.0                        NaN   \n",
       "2  2008.0     1505858.0                        NaN   \n",
       "3  2008.0       51000.0                        NaN   \n",
       "4  2008.0      370996.0                        NaN   \n",
       "\n",
       "                                      LEMMA_ABSTRACT  \\\n",
       "0  [this, be, a, project, to, explore, Game, -, b...   \n",
       "1  [institution, :, Franklin, Institute, Science,...   \n",
       "2  [through, program, (, include, small, group, c...   \n",
       "3  [in, partnership, with, the, American, Chemica...   \n",
       "4  [amphibian, population, around, the, world, be...   \n",
       "\n",
       "                                 tokened_docs_nostop  \\\n",
       "0  [explore, game, -, base, ,, metaphor, enhanced...   \n",
       "1  [institution, :, franklin, institute, science,...   \n",
       "2  [(, small, group, conversation, ,, citizen, co...   \n",
       "3  [partnership, american, chemical, society, (, ...   \n",
       "4  [amphibian, population, around, world, experie...   \n",
       "\n",
       "                                     tns_bi_tri_docs  \\\n",
       "0  [explore, game, -, base, ,, metaphor, enhanced...   \n",
       "1  [institution, :, franklin, institute, science,...   \n",
       "2  [(, small, group, conversation, ,, citizen, co...   \n",
       "3  [partnership, american, chemical, society, (, ...   \n",
       "4  [amphibian, population, around, world, experie...   \n",
       "\n",
       "                                        clean_tokens  \n",
       "0  [explore, game, base, metaphor, enhanced, game...  \n",
       "1  [institution, franklin, institute, science, mu...  \n",
       "2  [small, group, conversation, citizen, conferen...  \n",
       "3  [partnership, american, chemical, society, acs...  \n",
       "4  [amphibian, population, around, world, experie...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract IDs with no lemmas in them\n",
      "set()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'final_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'final_tokens'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3b203493c1ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#Just nsf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mnsf_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmalldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AGENCY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NSF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'final_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDAvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateLDAvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsf_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsf_docs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nsf_stanford_lemma.sav'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'final_tokens'"
     ]
    }
   ],
   "source": [
    "############\n",
    "#Create datasets for analysis\n",
    "############\n",
    "\n",
    "#All data\n",
    "docs = smalldf['clean_tokens'].dropna() #<--If you're having issues merging with a prior dataset, note that this will NOT be the same length as the df overall, because of nulls, so be careful appending\n",
    "id2word, corpus = LDAvariables.createLDAvars(docs)\n",
    "pickle.dump([corpus, id2word, docs], open('lda_data_stanford_lemma.sav','wb'))\n",
    "\n",
    "#The two IDs for abstracts that were a space\n",
    "print('Abstract IDs with no lemmas in them')\n",
    "print(set(range(len(docs)))-set(docs.index))\n",
    "\n",
    "#Just nsf\n",
    "nsf_docs=smalldf.groupby('AGENCY').get_group('NSF')['final_tokens'].dropna()\n",
    "id2word, corpus = LDAvariables.createLDAvars(nsf_docs)\n",
    "pickle.dump([corpus, id2word, nsf_docs], open('nsf_stanford_lemma.sav','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
