{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import ascii_letters\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TextCleaning\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in raw data\n",
    "\n",
    "df = pd.read_csv('../../data/original/raw_abstracts.csv',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550088, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>FY</th>\n",
       "      <th>FIRST_CHAR</th>\n",
       "      <th>LAST_CHAR</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>AGENCY</th>\n",
       "      <th>IC_CENTER</th>\n",
       "      <th>PROJECT_NUMBER</th>\n",
       "      <th>PROJECT_TITLE</th>\n",
       "      <th>PROJECT_TERMS</th>\n",
       "      <th>CONTACT_PI_PROJECT_LEADER</th>\n",
       "      <th>OTHER_PIS</th>\n",
       "      <th>ORGANIZATION_NAME</th>\n",
       "      <th>CFDA_CODE</th>\n",
       "      <th>FY_TOTAL_COST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89996</td>\n",
       "      <td>This is a project to explore Game-based, Metap...</td>\n",
       "      <td>2008</td>\n",
       "      <td>This is a project to explore Game-based, Metap...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0814512</td>\n",
       "      <td>RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...</td>\n",
       "      <td>Achievement; analog; base; Cognitive Science; ...</td>\n",
       "      <td>REESE, DEBBIE D</td>\n",
       "      <td>CARTER, BEVERLY; WOOD, CHARLES; HITT, BEN</td>\n",
       "      <td>WHEELING JESUIT UNIVERSITY</td>\n",
       "      <td>47.076</td>\n",
       "      <td>1999467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89997</td>\n",
       "      <td>Institution: Franklin Institute Science Museum...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Institution: Franklin Institute Science Museum...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0741659</td>\n",
       "      <td>ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...</td>\n",
       "      <td>Active Learning; Child; Computer software; des...</td>\n",
       "      <td>SNYDER, STEVEN</td>\n",
       "      <td>ELINICH, KAREN; YOON, SUSAN</td>\n",
       "      <td>FRANKLIN INSTITUTE</td>\n",
       "      <td>47.076</td>\n",
       "      <td>1799699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89998</td>\n",
       "      <td>Through programs (including small group conver...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Through programs (including small group conver...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0813522</td>\n",
       "      <td>BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...</td>\n",
       "      <td>Address; Age; Birth; Brain; Caregivers; Child;...</td>\n",
       "      <td>FINK, LAURIE KLEINBAUM</td>\n",
       "      <td>CADIGAN, KAREN; ELLENBOGEN, KIRSTEN</td>\n",
       "      <td>SCIENCE MUSEUM OF MINNESOTA</td>\n",
       "      <td>47.076</td>\n",
       "      <td>1505858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89999</td>\n",
       "      <td>In partnership with the American Chemical Soci...</td>\n",
       "      <td>2008</td>\n",
       "      <td>In partnership with the American Chemical Soci...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0838627</td>\n",
       "      <td>FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...</td>\n",
       "      <td>Advanced Development; American; Chemicals; Che...</td>\n",
       "      <td>JOST, JOHN W</td>\n",
       "      <td>MILLER, BRADLEY; BOWMAN, KATHERINE</td>\n",
       "      <td>INTERNATIONAL UNION OF PURE AND APPLIED CHEMISTRY</td>\n",
       "      <td>47.049</td>\n",
       "      <td>51000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90000</td>\n",
       "      <td>Amphibian populations around the world are exp...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Amphibian populations around the world are exp...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0815315</td>\n",
       "      <td>COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...</td>\n",
       "      <td>Amphibia; Central America; Communicable Diseas...</td>\n",
       "      <td>ZAMUDIO, KELLY R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CORNELL UNIVERSITY ITHACA</td>\n",
       "      <td>47.074</td>\n",
       "      <td>370996.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROJECT_ID                                           ABSTRACT    FY  \\\n",
       "0       89996  This is a project to explore Game-based, Metap...  2008   \n",
       "1       89997  Institution: Franklin Institute Science Museum...  2008   \n",
       "2       89998  Through programs (including small group conver...  2008   \n",
       "3       89999  In partnership with the American Chemical Soci...  2008   \n",
       "4       90000  Amphibian populations around the world are exp...  2008   \n",
       "\n",
       "                                          FIRST_CHAR LAST_CHAR DEPARTMENT  \\\n",
       "0  This is a project to explore Game-based, Metap...         .        NSF   \n",
       "1  Institution: Franklin Institute Science Museum...         .        NSF   \n",
       "2  Through programs (including small group conver...         .        NSF   \n",
       "3  In partnership with the American Chemical Soci...         .        NSF   \n",
       "4  Amphibian populations around the world are exp...         .        NSF   \n",
       "\n",
       "  AGENCY IC_CENTER PROJECT_NUMBER  \\\n",
       "0    NSF       NaN        0814512   \n",
       "1    NSF       NaN        0741659   \n",
       "2    NSF       NaN        0813522   \n",
       "3    NSF       NaN        0838627   \n",
       "4    NSF       NaN        0815315   \n",
       "\n",
       "                                       PROJECT_TITLE  \\\n",
       "0  RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...   \n",
       "1  ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...   \n",
       "2  BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...   \n",
       "3  FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...   \n",
       "4  COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...   \n",
       "\n",
       "                                       PROJECT_TERMS  \\\n",
       "0  Achievement; analog; base; Cognitive Science; ...   \n",
       "1  Active Learning; Child; Computer software; des...   \n",
       "2  Address; Age; Birth; Brain; Caregivers; Child;...   \n",
       "3  Advanced Development; American; Chemicals; Che...   \n",
       "4  Amphibia; Central America; Communicable Diseas...   \n",
       "\n",
       "  CONTACT_PI_PROJECT_LEADER                                  OTHER_PIS  \\\n",
       "0           REESE, DEBBIE D  CARTER, BEVERLY; WOOD, CHARLES; HITT, BEN   \n",
       "1            SNYDER, STEVEN                ELINICH, KAREN; YOON, SUSAN   \n",
       "2    FINK, LAURIE KLEINBAUM        CADIGAN, KAREN; ELLENBOGEN, KIRSTEN   \n",
       "3              JOST, JOHN W         MILLER, BRADLEY; BOWMAN, KATHERINE   \n",
       "4          ZAMUDIO, KELLY R                                        NaN   \n",
       "\n",
       "                                   ORGANIZATION_NAME CFDA_CODE  FY_TOTAL_COST  \n",
       "0                         WHEELING JESUIT UNIVERSITY    47.076      1999467.0  \n",
       "1                                 FRANKLIN INSTITUTE    47.076      1799699.0  \n",
       "2                        SCIENCE MUSEUM OF MINNESOTA    47.076      1505858.0  \n",
       "3  INTERNATIONAL UNION OF PURE AND APPLIED CHEMISTRY    47.049        51000.0  \n",
       "4                          CORNELL UNIVERSITY ITHACA    47.074       370996.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 nulls in  ABSTRACT . These rows removed.\n",
      "11 duplicate abstracts removed\n",
      "0 project ID duplicates - not removed\n"
     ]
    }
   ],
   "source": [
    "#importlib.reload(TextCleaning_updated)\n",
    "df = TextCleaning.remove_nulls(df, \"ABSTRACT\")\n",
    "df = TextCleaning.remove_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase all abstracts, strip leading and trailing whitespace,\n",
    "# and save in a working abstract column that will be updated as text is cleaned\n",
    "\n",
    "df[\"working_abstract\"] = [abstract.lower().strip() for abstract in df[\"ABSTRACT\"]] \n",
    "df = TextCleaning.drop_empties(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Start Char']=df['working_abstract'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>FY</th>\n",
       "      <th>FIRST_CHAR</th>\n",
       "      <th>LAST_CHAR</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>AGENCY</th>\n",
       "      <th>IC_CENTER</th>\n",
       "      <th>PROJECT_NUMBER</th>\n",
       "      <th>PROJECT_TITLE</th>\n",
       "      <th>PROJECT_TERMS</th>\n",
       "      <th>CONTACT_PI_PROJECT_LEADER</th>\n",
       "      <th>OTHER_PIS</th>\n",
       "      <th>ORGANIZATION_NAME</th>\n",
       "      <th>CFDA_CODE</th>\n",
       "      <th>FY_TOTAL_COST</th>\n",
       "      <th>working_abstract</th>\n",
       "      <th>Start Char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89996</td>\n",
       "      <td>This is a project to explore Game-based, Metap...</td>\n",
       "      <td>2008</td>\n",
       "      <td>This is a project to explore Game-based, Metap...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0814512</td>\n",
       "      <td>RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...</td>\n",
       "      <td>Achievement; analog; base; Cognitive Science; ...</td>\n",
       "      <td>REESE, DEBBIE D</td>\n",
       "      <td>CARTER, BEVERLY; WOOD, CHARLES; HITT, BEN</td>\n",
       "      <td>WHEELING JESUIT UNIVERSITY</td>\n",
       "      <td>47.076</td>\n",
       "      <td>1999467.0</td>\n",
       "      <td>this is a project to explore game-based, metap...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89997</td>\n",
       "      <td>Institution: Franklin Institute Science Museum...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Institution: Franklin Institute Science Museum...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0741659</td>\n",
       "      <td>ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...</td>\n",
       "      <td>Active Learning; Child; Computer software; des...</td>\n",
       "      <td>SNYDER, STEVEN</td>\n",
       "      <td>ELINICH, KAREN; YOON, SUSAN</td>\n",
       "      <td>FRANKLIN INSTITUTE</td>\n",
       "      <td>47.076</td>\n",
       "      <td>1799699.0</td>\n",
       "      <td>institution: franklin institute science museum...</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89998</td>\n",
       "      <td>Through programs (including small group conver...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Through programs (including small group conver...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0813522</td>\n",
       "      <td>BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...</td>\n",
       "      <td>Address; Age; Birth; Brain; Caregivers; Child;...</td>\n",
       "      <td>FINK, LAURIE KLEINBAUM</td>\n",
       "      <td>CADIGAN, KAREN; ELLENBOGEN, KIRSTEN</td>\n",
       "      <td>SCIENCE MUSEUM OF MINNESOTA</td>\n",
       "      <td>47.076</td>\n",
       "      <td>1505858.0</td>\n",
       "      <td>through programs (including small group conver...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89999</td>\n",
       "      <td>In partnership with the American Chemical Soci...</td>\n",
       "      <td>2008</td>\n",
       "      <td>In partnership with the American Chemical Soci...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0838627</td>\n",
       "      <td>FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...</td>\n",
       "      <td>Advanced Development; American; Chemicals; Che...</td>\n",
       "      <td>JOST, JOHN W</td>\n",
       "      <td>MILLER, BRADLEY; BOWMAN, KATHERINE</td>\n",
       "      <td>INTERNATIONAL UNION OF PURE AND APPLIED CHEMISTRY</td>\n",
       "      <td>47.049</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>in partnership with the american chemical soci...</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90000</td>\n",
       "      <td>Amphibian populations around the world are exp...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Amphibian populations around the world are exp...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0815315</td>\n",
       "      <td>COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...</td>\n",
       "      <td>Amphibia; Central America; Communicable Diseas...</td>\n",
       "      <td>ZAMUDIO, KELLY R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CORNELL UNIVERSITY ITHACA</td>\n",
       "      <td>47.074</td>\n",
       "      <td>370996.0</td>\n",
       "      <td>amphibian populations around the world are exp...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROJECT_ID                                           ABSTRACT    FY  \\\n",
       "0       89996  This is a project to explore Game-based, Metap...  2008   \n",
       "1       89997  Institution: Franklin Institute Science Museum...  2008   \n",
       "2       89998  Through programs (including small group conver...  2008   \n",
       "3       89999  In partnership with the American Chemical Soci...  2008   \n",
       "4       90000  Amphibian populations around the world are exp...  2008   \n",
       "\n",
       "                                          FIRST_CHAR LAST_CHAR DEPARTMENT  \\\n",
       "0  This is a project to explore Game-based, Metap...         .        NSF   \n",
       "1  Institution: Franklin Institute Science Museum...         .        NSF   \n",
       "2  Through programs (including small group conver...         .        NSF   \n",
       "3  In partnership with the American Chemical Soci...         .        NSF   \n",
       "4  Amphibian populations around the world are exp...         .        NSF   \n",
       "\n",
       "  AGENCY IC_CENTER PROJECT_NUMBER  \\\n",
       "0    NSF       NaN        0814512   \n",
       "1    NSF       NaN        0741659   \n",
       "2    NSF       NaN        0813522   \n",
       "3    NSF       NaN        0838627   \n",
       "4    NSF       NaN        0815315   \n",
       "\n",
       "                                       PROJECT_TITLE  \\\n",
       "0  RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...   \n",
       "1  ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...   \n",
       "2  BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...   \n",
       "3  FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...   \n",
       "4  COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...   \n",
       "\n",
       "                                       PROJECT_TERMS  \\\n",
       "0  Achievement; analog; base; Cognitive Science; ...   \n",
       "1  Active Learning; Child; Computer software; des...   \n",
       "2  Address; Age; Birth; Brain; Caregivers; Child;...   \n",
       "3  Advanced Development; American; Chemicals; Che...   \n",
       "4  Amphibia; Central America; Communicable Diseas...   \n",
       "\n",
       "  CONTACT_PI_PROJECT_LEADER                                  OTHER_PIS  \\\n",
       "0           REESE, DEBBIE D  CARTER, BEVERLY; WOOD, CHARLES; HITT, BEN   \n",
       "1            SNYDER, STEVEN                ELINICH, KAREN; YOON, SUSAN   \n",
       "2    FINK, LAURIE KLEINBAUM        CADIGAN, KAREN; ELLENBOGEN, KIRSTEN   \n",
       "3              JOST, JOHN W         MILLER, BRADLEY; BOWMAN, KATHERINE   \n",
       "4          ZAMUDIO, KELLY R                                        NaN   \n",
       "\n",
       "                                   ORGANIZATION_NAME CFDA_CODE  FY_TOTAL_COST  \\\n",
       "0                         WHEELING JESUIT UNIVERSITY    47.076      1999467.0   \n",
       "1                                 FRANKLIN INSTITUTE    47.076      1799699.0   \n",
       "2                        SCIENCE MUSEUM OF MINNESOTA    47.076      1505858.0   \n",
       "3  INTERNATIONAL UNION OF PURE AND APPLIED CHEMISTRY    47.049        51000.0   \n",
       "4                          CORNELL UNIVERSITY ITHACA    47.074       370996.0   \n",
       "\n",
       "                                    working_abstract Start Char  \n",
       "0  this is a project to explore game-based, metap...          t  \n",
       "1  institution: franklin institute science museum...          i  \n",
       "2  through programs (including small group conver...          t  \n",
       "3  in partnership with the american chemical soci...          i  \n",
       "4  amphibian populations around the world are exp...          a  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270 short abstracts removed\n"
     ]
    }
   ],
   "source": [
    "## what do we want to do here???\n",
    "\n",
    "#importlib.reload(TextCleaning)\n",
    "df = TextCleaning.remove_short_abstracts(df,limit=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start phrases to remove\n",
    "\n",
    "start_phrases=['****technical abstract****',\n",
    "               '****non technical abstract****',\n",
    "               '*** non- technical abstract ***',\n",
    "               '**non-technical abstract**',         \n",
    "               '*non-technical abstract*',\n",
    "               '*****non-technical abstract*****',\n",
    "               '***** non-technical abstract *****',\n",
    "               '****non-technical abstract****',\n",
    "               '***non-technical abstract***',\n",
    "               '****nontechnical abstract****',\n",
    "               'technical summary', \n",
    "               'nontechnical summary',\n",
    "               'non-technical summary',\n",
    "               'non-technical description',\n",
    "               'description (provided by the applicant)',\n",
    "               'description (provided by investigator)',  \n",
    "               'description (provided by applicant)',\n",
    "               'project summary/abstract',   \n",
    "               'abstract',\n",
    "               'proposal abstract',\n",
    "               'research abstract',\n",
    "               'project summary',\n",
    "               'summary',\n",
    "               'research summary',\n",
    "               'proposal',\n",
    "               'description',\n",
    "               'project description'\n",
    "               'narrative',\n",
    "               '(see instructions):',\n",
    "               'for center application (provided by the investigator):',\n",
    "               'objective(s)',      \n",
    "               'exceed the space provided',\n",
    "               'provided by applicant',\n",
    "               'provided by candidate',\n",
    "               'one page and must contain a summary of the proposed activity suitable for dissemination to thepublic. it should be a self-contained description of the project and should contain a statement of objectives and methods to be employed.it should be informative to other persons working in the same or related fields and insofar as possible understandable to a technically liter-ate lay reader. this abstract must not include any proprietary/confidential information.* please click the add attachment button to complete this entry.']\n",
    " # [hrd #######]\n",
    "wa = 'working_abstract'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ch = list(df[\"working_abstract\"].apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 'i',\n",
       " 't',\n",
       " 'i',\n",
       " 'a',\n",
       " 't',\n",
       " 'd',\n",
       " 't',\n",
       " 't',\n",
       " 'm',\n",
       " 't',\n",
       " 'o',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 's',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 's',\n",
       " 't',\n",
       " 'p',\n",
       " 't',\n",
       " 'g',\n",
       " 'i',\n",
       " 'i',\n",
       " 't',\n",
       " 's',\n",
       " 'c',\n",
       " 't',\n",
       " 'd',\n",
       " '[',\n",
       " 'c',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'c',\n",
       " 'a',\n",
       " 'u',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " '[',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " '*',\n",
       " 'p',\n",
       " '0',\n",
       " '0',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'm',\n",
       " 'm',\n",
       " 'o',\n",
       " 'c',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'l',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " 'c',\n",
       " 'g',\n",
       " 'm',\n",
       " 'i',\n",
       " 'o',\n",
       " 't',\n",
       " 'p',\n",
       " '0',\n",
       " 'c',\n",
       " 'h',\n",
       " 'i',\n",
       " 'e',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'd',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'c',\n",
       " 'b',\n",
       " 'c',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'i',\n",
       " 'd',\n",
       " 'c',\n",
       " 'l',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 's',\n",
       " 'i',\n",
       " 't',\n",
       " 'e',\n",
       " 't',\n",
       " 'c',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'c',\n",
       " 'c',\n",
       " 'g',\n",
       " 'i',\n",
       " 's',\n",
       " 'x',\n",
       " 'd',\n",
       " 'i',\n",
       " 't',\n",
       " 'e',\n",
       " 'i',\n",
       " 'v',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " 't',\n",
       " 'p',\n",
       " 't',\n",
       " 's',\n",
       " 'p',\n",
       " 'r',\n",
       " 't',\n",
       " 'd',\n",
       " 'e',\n",
       " 'm',\n",
       " 't',\n",
       " 'd',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'l',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'i',\n",
       " 't',\n",
       " 's',\n",
       " 't',\n",
       " 'f',\n",
       " 'n',\n",
       " 't',\n",
       " 's',\n",
       " 's',\n",
       " 't',\n",
       " 'd',\n",
       " 'p',\n",
       " 's',\n",
       " 'p',\n",
       " 'c',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 'n',\n",
       " 'c',\n",
       " '0',\n",
       " 'a',\n",
       " 'a',\n",
       " 'p',\n",
       " 'a',\n",
       " 'u',\n",
       " 'd',\n",
       " 'a',\n",
       " 't',\n",
       " 'v',\n",
       " 'p',\n",
       " 't',\n",
       " 't',\n",
       " 'f',\n",
       " 'o',\n",
       " 'o',\n",
       " 'a',\n",
       " 'c',\n",
       " 'm',\n",
       " 'a',\n",
       " 's',\n",
       " 't',\n",
       " 'p',\n",
       " 'c',\n",
       " 't',\n",
       " 'c',\n",
       " 'a',\n",
       " 'p',\n",
       " 'c',\n",
       " 'c',\n",
       " 'a',\n",
       " 'c',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'c',\n",
       " 't',\n",
       " 'b',\n",
       " 'd',\n",
       " 'e',\n",
       " 'd',\n",
       " 'a',\n",
       " 't',\n",
       " 's',\n",
       " 'p',\n",
       " 'a',\n",
       " 't',\n",
       " 'g',\n",
       " 'r',\n",
       " 'p',\n",
       " 'p',\n",
       " 'c',\n",
       " 'l',\n",
       " 't',\n",
       " 'd',\n",
       " '0',\n",
       " 'g',\n",
       " 't',\n",
       " 'c',\n",
       " 'o',\n",
       " 'a',\n",
       " 't',\n",
       " 'd',\n",
       " 'a',\n",
       " 'p',\n",
       " 's',\n",
       " 'u',\n",
       " 's',\n",
       " 'e',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 'i',\n",
       " 'a',\n",
       " 'h',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " 't',\n",
       " 't',\n",
       " 'h',\n",
       " 't',\n",
       " 'f',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " 'i',\n",
       " 'k',\n",
       " 'p',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'b',\n",
       " 't',\n",
       " 'a',\n",
       " 'w',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm',\n",
       " 's',\n",
       " 'g',\n",
       " 'c',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'w',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 'w',\n",
       " 't',\n",
       " 't',\n",
       " 'c',\n",
       " 'e',\n",
       " 'w',\n",
       " 'i',\n",
       " 't',\n",
       " 'd',\n",
       " 'c',\n",
       " 't',\n",
       " 't',\n",
       " 'f',\n",
       " 'n',\n",
       " 't',\n",
       " 'm',\n",
       " 'i',\n",
       " 'm',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'w',\n",
       " 'm',\n",
       " 'c',\n",
       " 'e',\n",
       " 'b',\n",
       " 'd',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 't',\n",
       " 'f',\n",
       " 'n',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'p',\n",
       " 't',\n",
       " 'i',\n",
       " 's',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'i',\n",
       " 's',\n",
       " 'a',\n",
       " 't',\n",
       " 'v',\n",
       " 's',\n",
       " 't',\n",
       " 'n',\n",
       " '0',\n",
       " 't',\n",
       " 'i',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 't',\n",
       " '0',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 'f',\n",
       " 'i',\n",
       " '8',\n",
       " 'h',\n",
       " 'c',\n",
       " 'u',\n",
       " 't',\n",
       " 'k',\n",
       " 't',\n",
       " 'g',\n",
       " 't',\n",
       " 'w',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'o',\n",
       " '0',\n",
       " 'p',\n",
       " 't',\n",
       " 'e',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'c',\n",
       " 't',\n",
       " 't',\n",
       " '0',\n",
       " 't',\n",
       " 'c',\n",
       " 't',\n",
       " 'u',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " '0',\n",
       " 't',\n",
       " 's',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'l',\n",
       " 'd',\n",
       " 'e',\n",
       " 't',\n",
       " 't',\n",
       " 's',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'o',\n",
       " 'c',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'p',\n",
       " 's',\n",
       " 'a',\n",
       " '0',\n",
       " 'q',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'd',\n",
       " 'r',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'r',\n",
       " 'c',\n",
       " 't',\n",
       " 't',\n",
       " 'u',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 'i',\n",
       " 'd',\n",
       " 't',\n",
       " 't',\n",
       " 'r',\n",
       " 't',\n",
       " 't',\n",
       " 'w',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'u',\n",
       " 'd',\n",
       " 'm',\n",
       " 'p',\n",
       " 'a',\n",
       " '0',\n",
       " 't',\n",
       " 'h',\n",
       " 'g',\n",
       " 't',\n",
       " 'f',\n",
       " 'u',\n",
       " 't',\n",
       " 'g',\n",
       " 'i',\n",
       " 'p',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'l',\n",
       " 'a',\n",
       " 't',\n",
       " 'a',\n",
       " 's',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 'h',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'g',\n",
       " 'i',\n",
       " 's',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'b',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 'd',\n",
       " 's',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'd',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'h',\n",
       " 'a',\n",
       " 'p',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 'n',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " '6',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'l',\n",
       " 't',\n",
       " 'l',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'i',\n",
       " 'a',\n",
       " 'p',\n",
       " 'p',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'c',\n",
       " 'n',\n",
       " 't',\n",
       " 'p',\n",
       " 't',\n",
       " 't',\n",
       " 'c',\n",
       " 'l',\n",
       " 'l',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 't',\n",
       " 'r',\n",
       " 't',\n",
       " 'f',\n",
       " 't',\n",
       " 'p',\n",
       " 'p',\n",
       " 't',\n",
       " 't',\n",
       " 'm',\n",
       " 'p',\n",
       " 'm',\n",
       " 'a',\n",
       " 'u',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'w',\n",
       " 't',\n",
       " 't',\n",
       " 'n',\n",
       " 'l',\n",
       " 'a',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 's',\n",
       " 'f',\n",
       " 'n',\n",
       " 'e',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " 'r',\n",
       " 'a',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'w',\n",
       " 'a',\n",
       " '*',\n",
       " 'o',\n",
       " 'p',\n",
       " 'o',\n",
       " 'a',\n",
       " 'c',\n",
       " 't',\n",
       " 'a',\n",
       " 'p',\n",
       " 'g',\n",
       " 't',\n",
       " 'c',\n",
       " 'r',\n",
       " 'w',\n",
       " 't',\n",
       " '[',\n",
       " 't',\n",
       " 's',\n",
       " 'a',\n",
       " 't',\n",
       " 'p',\n",
       " 't',\n",
       " 'w',\n",
       " 't',\n",
       " 'n',\n",
       " 'r',\n",
       " 't',\n",
       " 'n',\n",
       " 'a',\n",
       " 'i',\n",
       " 't',\n",
       " 'b',\n",
       " 'e',\n",
       " 'm',\n",
       " 't',\n",
       " 'a',\n",
       " 'g',\n",
       " 'd',\n",
       " 'i',\n",
       " 't',\n",
       " 'a',\n",
       " 'h',\n",
       " '0',\n",
       " 'c',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'p',\n",
       " 'r',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 'n',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " '[',\n",
       " 'o',\n",
       " 'c',\n",
       " 'p',\n",
       " 'd',\n",
       " 't',\n",
       " 'g',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'h',\n",
       " 't',\n",
       " 'a',\n",
       " 's',\n",
       " 't',\n",
       " 'c',\n",
       " 'r',\n",
       " 'r',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 't',\n",
       " 'a',\n",
       " 'c',\n",
       " 'd',\n",
       " 't',\n",
       " 'c',\n",
       " 'g',\n",
       " 'n',\n",
       " 'a',\n",
       " 'a',\n",
       " 'u',\n",
       " 't',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'b',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'd',\n",
       " 'd',\n",
       " 'l',\n",
       " 't',\n",
       " 't',\n",
       " 'w',\n",
       " 's',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'i',\n",
       " 'p',\n",
       " 't',\n",
       " 'w',\n",
       " 't',\n",
       " 'c',\n",
       " 'a',\n",
       " 't',\n",
       " 'c',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 't',\n",
       " 'q',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'c',\n",
       " 'e',\n",
       " 't',\n",
       " 'q',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'f',\n",
       " 'm',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " 'e',\n",
       " 'a',\n",
       " 'g',\n",
       " 'a',\n",
       " 'p',\n",
       " 's',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'g',\n",
       " 'i',\n",
       " 'k',\n",
       " 'c',\n",
       " 't',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 'l',\n",
       " 'c',\n",
       " 'l',\n",
       " 's',\n",
       " 'l',\n",
       " 't',\n",
       " 'a',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'g',\n",
       " 'g',\n",
       " 's',\n",
       " 'i',\n",
       " 'i',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 'i',\n",
       " 'e',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 'a',\n",
       " 'p',\n",
       " 'a',\n",
       " 'r',\n",
       " 'p',\n",
       " 't',\n",
       " 'n',\n",
       " 'd',\n",
       " 't',\n",
       " 't',\n",
       " 'm',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'u',\n",
       " 'h',\n",
       " 'd',\n",
       " 't',\n",
       " 't',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 't',\n",
       " 'p',\n",
       " 't',\n",
       " 'f',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'c',\n",
       " 'p',\n",
       " '[',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'g',\n",
       " 'a',\n",
       " 'c',\n",
       " 'p',\n",
       " 't',\n",
       " '(',\n",
       " 'e',\n",
       " 'm',\n",
       " 'f',\n",
       " 'p',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 'c',\n",
       " 'd',\n",
       " 'r',\n",
       " 'h',\n",
       " 'b',\n",
       " 'a',\n",
       " 'p',\n",
       " 'a',\n",
       " 'p',\n",
       " 'a',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 't',\n",
       " 'e',\n",
       " 'o',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 't',\n",
       " 'l',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'c',\n",
       " 'i',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm',\n",
       " 'g',\n",
       " 'c',\n",
       " 'c',\n",
       " 't',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " 'c',\n",
       " '(',\n",
       " 't',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 't',\n",
       " 'g',\n",
       " 'a',\n",
       " 'a',\n",
       " 'c',\n",
       " 'o',\n",
       " 'g',\n",
       " 'c',\n",
       " 't',\n",
       " 'g',\n",
       " 't',\n",
       " 'i',\n",
       " 'p',\n",
       " 't',\n",
       " 'p',\n",
       " 'm',\n",
       " 't',\n",
       " 'i',\n",
       " 'm',\n",
       " 'd',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'c',\n",
       " 'n',\n",
       " 's',\n",
       " 'c',\n",
       " 'p',\n",
       " 's',\n",
       " 'p',\n",
       " 't',\n",
       " 'e',\n",
       " 'c',\n",
       " '0',\n",
       " 't',\n",
       " 'c',\n",
       " 't',\n",
       " 'm',\n",
       " 'u',\n",
       " 't',\n",
       " 'p',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " 't',\n",
       " 'w',\n",
       " 't',\n",
       " 'n',\n",
       " 'o',\n",
       " 's',\n",
       " 'p',\n",
       " 'g',\n",
       " 'c',\n",
       " 'o',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4713\n"
     ]
    }
   ],
   "source": [
    "j = first_ch.index('2')\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714\n"
     ]
    }
   ],
   "source": [
    "i = df.index[j]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20 centimeter cold cell for bruker  summary: this is a letter proposal to design, fabricate and test a 20 centimeter cold cell that will be compatible with bruker michelson interferometers.  the cell path length will be compatible with the bruker sample'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[i, \"working_abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "abstract = df[\"working_abstract\"][54]  # 1620 starts with ?, 54 starts with **** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "23419\n",
      " time: 884.475515127182\n"
     ]
    }
   ],
   "source": [
    "# NOTE:  should we keep this removal of symbols?  Or just match on first alpha-numeric character?\n",
    "# SLOW but works ~ 15 mins\n",
    "\n",
    "# Old way\n",
    "#df[wa]=df[wa].apply(str.lstrip,args=[' ?-_^. :,!;¿|()[]]#%>﻿&\\''])\n",
    "\n",
    "# New way - regular expressions. Also gets rid of all symbol abstracts\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "p = re.compile('[^a-zA-Z0-9]+')\n",
    "count = 0\n",
    "\n",
    "idx = df[df[\"Start Char\"].str.isalnum() == False].index\n",
    "\n",
    "for i in idx:\n",
    "    \n",
    "    abstract = df.loc[i, 'working_abstract']\n",
    "    m = p.match(abstract)\n",
    "    \n",
    "    if (m is not None):\n",
    "        df.loc[i, \"working_abstract\"] = abstract[m.end():]    #p.sub('', abstract, count = 1)\n",
    "        count = count + 1\n",
    "        \n",
    "    if (count % 5000 == 0):\n",
    "        print(count)\n",
    "          \n",
    "            \n",
    "            \n",
    "df = TextCleaning.drop_empties(df)  # may need to reindex data frame after empty drops\n",
    "print(count)\n",
    "\n",
    "t2 = time.time()\n",
    "print(f\" time: {t2-t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'β'.isalnum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "3\n",
      "23419\n"
     ]
    }
   ],
   "source": [
    "# NOTE:  should we keep this removal of symbols?  Or just match on first alpha-numeric character?\n",
    "# SLOW but works ~ 10 mins\n",
    "\n",
    "\n",
    "# Old way\n",
    "#df[wa]=df[wa].apply(str.lstrip,args=[' ?-_^. :,!;¿|()[]]#%>﻿&\\''])\n",
    "\n",
    "\n",
    "# New way - regular expressions. Gets rid of all symbol abstracts\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "p = re.compile('[a-zA-Z0-9]')\n",
    "count_N = 0\n",
    "count = 0\n",
    "j = 0\n",
    "\n",
    "idx = df[df[\"Start Char\"].str.isalnum() == False].index\n",
    "\n",
    "for i in idx:\n",
    "    \n",
    "    abstract = df.loc[i, 'working_abstract']\n",
    "    m = p.search(abstract)\n",
    "    \n",
    "    if (m is None):\n",
    "        df.loc[i, \"working_abstract\"] = \"\" \n",
    "        count_N = count_N + 1\n",
    "        \n",
    "    elif (m.start() != 0):\n",
    "        #print(df.loc[idx, \"working_abstract\"])\n",
    "        df.loc[i, \"working_abstract\"] = abstract[m.start():] \n",
    "        #print(df.loc[idx, \"working_abstract\"])\n",
    "        #input()\n",
    "        count = count + 1\n",
    "    \n",
    "    if (j % 5000 == 0):\n",
    "        print(j)\n",
    "    j = j + 1\n",
    "       \n",
    "        \n",
    "df = TextCleaning.drop_empties(df)  # may need to reindex data frame after empty drops\n",
    "print(count_N)\n",
    "print(count)\n",
    "\n",
    "t2 = time.time()\n",
    "print(f\" time: {t2-t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 3), match='***'>\n"
     ]
    }
   ],
   "source": [
    "p = re.compile('[^a-zA-Z0-9]+')\n",
    "s = '***'\n",
    "m = p.search(s)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update Start Char column in df\n",
    "first_c = df[\"working_abstract\"].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dict(first_c.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': 219964,\n",
       " 't': 136215,\n",
       " 'p': 43877,\n",
       " 'a': 29678,\n",
       " 'i': 15636,\n",
       " 's': 12932,\n",
       " 'c': 12292,\n",
       " 'w': 10662,\n",
       " 'o': 9418,\n",
       " 'm': 8505,\n",
       " 'b': 7607,\n",
       " 'n': 6869,\n",
       " 'r': 5586,\n",
       " 'e': 5124,\n",
       " 'f': 4112,\n",
       " 'h': 3793,\n",
       " 'u': 3269,\n",
       " '1': 3232,\n",
       " 'g': 3159,\n",
       " 'l': 2761,\n",
       " '0': 1320,\n",
       " 'v': 1265,\n",
       " 'k': 564,\n",
       " '7': 512,\n",
       " 'j': 437,\n",
       " 'q': 338,\n",
       " '6': 154,\n",
       " 'y': 153,\n",
       " '2': 143,\n",
       " 'x': 109,\n",
       " '3': 98,\n",
       " 'z': 98,\n",
       " '5': 58,\n",
       " '4': 48,\n",
       " '9': 46,\n",
       " '8': 33,\n",
       " 'δ': 1,\n",
       " 'α': 1,\n",
       " 'γ': 1,\n",
       " 'β': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_phrases' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-b073496ad86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Remove found phrases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstart_phrases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwa\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwa\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTextCleaning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_phrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' :./)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Repeated in case the order of project summary/abstract varies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstart_phrases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_phrases' is not defined"
     ]
    }
   ],
   "source": [
    "#Remove found phrases\n",
    "for phrase in start_phrases:\n",
    "    df[wa]=df[wa].apply(TextCleaning.remove_phrase,args=[phrase,'Start']).apply(str.lstrip,args=[' :./)'])\n",
    "#Repeated in case the order of project summary/abstract varies\n",
    "for phrase in start_phrases:\n",
    "    df[wa]=df[wa].apply(TextCleaning.remove_phrase,args=[phrase,'Start']).apply(str.lstrip,args=[' :./)'])\n",
    "\n",
    "# Often, sentences will start with - or *, \n",
    "# but they indicate other quality issues and don't end with them,so it's okay to remove them\n",
    "df[wa]=df[wa].apply(str.lstrip,args=['?-*_^. :,!;=¿|]#%>&-\\t\\n'])   \n",
    "    \n",
    "df = TextCleaning.drop_empties(df)\n",
    "    \n",
    "# update Start Char column in df\n",
    "df['Start Char']=df[wa].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Start Char']=df['working_abstract'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(End of Abstract)\n",
      "End of Abstract\n",
      "(Abstract end)(END OF ABSTRACT)\n",
      "(End of abstract.)\n",
      "(Abstract End)\n",
      "(End 0f Abstract)\n",
      "(End of Abstract.)\n",
      "(End of Absract)\n",
      "(Abstract below)\n",
      "(End of Reviewers' Comment)\n",
      "(End Abstract)\n",
      "(End of abstract)\n",
      "(End of abstract)\n",
      "PERFORMANCE SITE ========================================Section End===========================================\n",
      "KEY PERSONNEL ========================================Section End===========================================\n",
      "[summary truncated at 7800 characters]\n",
      "This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.\n",
      "Project Description Page 6\n",
      "Page 1 of 1\n",
      "Project Summary/Abstract Page 6\n",
      "Project Description Page 7\n",
      "Project Summary/Abstract Page 7\n",
      "Pag 1 o 1\n",
      "Page 2 Number pages consecutively at the bottom throughout Form Page 2\n",
      "This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.\n"
     ]
    }
   ],
   "source": [
    "# remove junk at end\n",
    "\n",
    "end_phrases = ['(end of abstract)',\n",
    "               'end of abstract', \n",
    "               '(abstract end)',  \n",
    "               '(end of abstract.)',\n",
    "               '(end 0f abstract)',\n",
    "               '(end of absract)',\n",
    "               '(abstract below)',\n",
    "               '(end of reviewers\\' comment)',\n",
    "               '(end abstract)',\n",
    "               \n",
    "               'PERFORMANCE SITE ========================================Section End===========================================',\n",
    "               'KEY PERSONNEL ========================================Section End===========================================',\n",
    "               '[summary truncated at 7800 characters]', \n",
    "               'This award reflects NSF\\'s statutory mission and has been deemed worthy of support through evaluation using the Foundation\\'s intellectual merit and broader impacts review criteria.',\n",
    "               'Project Description Page 6', 'Page 1 of 1', 'Project Summary/Abstract Page 6',\n",
    "               'Project Description Page 7', 'Project Summary/Abstract Page 7', 'Pag 1 o 1', \n",
    "               'Page 2 Number pages consecutively at the bottom throughout Form Page 2']\n",
    "\n",
    "df = TextCleaning.remove_junk_end(df, 'working_abstract', end_phrases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/compiler/gcc/7.1.0/jupyter_conda/2019.10-py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "punctuation=['!','?','.']\n",
    "\n",
    "#y='*' #Generally if last char is '*', it comes in as '***' following a complete sentence, so unlikely to be \n",
    "# cut-of'\n",
    "\n",
    "#Fixes '***' if that makes the last character a punctuation ending mark, otherwise should remove\n",
    "y='*' \n",
    "entries_ending_right=df.loc[df['LAST_CHAR']==y]\n",
    "entries_ending_right['new_last_char_possible']= entries_ending_right.apply(lambda x:TextCleaning.remove_phrase(x[wa],'***',loc='End')[-1],axis=1)\n",
    "entries_to_fix=list(entries_ending_right[entries_ending_right['new_last_char_possible'].isin(punctuation)]['PROJECT_ID'])\n",
    "\n",
    "df[wa]=df.apply(lambda x: TextCleaning.remove_phrase(x[wa],'***','End') \n",
    "                if x['PROJECT_ID'] in entries_to_fix else x[wa],axis=1)\n",
    "\n",
    "df['LAST_CHAR']=df[wa].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using regular expressions to remove \"junk\" within text body - not necessarily at the start or end\n",
    "\n",
    "#'Enter the text here tha' ending with 'lines of text.'\n",
    "expression=re.compile('Enter the text here that.*lines of text')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "expression=re.compile('PHS .*?Continuation Format Page')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "expression=re.compile('OMB No .*?Continuation Format Page')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "\n",
    "\n",
    "df[wa]=df[wa].replace('Project Summary/Abstract','')\n",
    "\n",
    "\"\"\"If it starts with 'one page and must contain',\n",
    "#This is an NIH thing and there aren't that many of them, but come from 3 different cfda\n",
    "it will start with \"one page and must contain a summary of the proposed activity suitable for dissemination to thepublic. \n",
    "It should be a self-contained description of the project and should contain a statement of objectives and methods to be employed.\n",
    "It should be informative to other persons working in the same or related fields and insofar as possible understandable to a technically liter-ate lay reader. \n",
    "This Abstract must not include any proprietary/confidential information.* \n",
    "Please click the add attachment button to complete this entry.\" plus some attachments, which includes tracking number, twice:\n",
    "following the second trackign number, there is a grant number followed by the actual content\" \n",
    "\n",
    "At the end of these files, they all end in 'Project Narrative File'(last instance) followed by more attachments, all of which can be discarded\n",
    "\"\"\"\n",
    "expression1=re.compile('one page and must.*?Tracking Number.*?(Tracking Number)')\n",
    "expression2=re.compile('Project Narrative File.*')\n",
    "def fix_abstract(abstract):\n",
    "    if abstract.startswith('one page and must contain'):\n",
    "        abstract=re.sub(expression1,'',abstract)\n",
    "        return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "\n",
    "df[wa]=df[wa].apply(fix_abstract)\n",
    "\n",
    "\n",
    "df[wa]=df[wa].apply(lambda x: x.lstrip(',;\\n\\t&-!'))\n",
    "df=df.loc[df[wa].apply(len)>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting_exact_phrases to remove\n",
    "#'This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.'\n",
    "#'This subproject is one of many research subprojects utilizing theresources provided by a Center grant funded by NIH/NCRR. The subproject andinvestigator (PI) may have received primary funding from another NIH source,and thus could be represented in other CRISP entries. The institution listed isfor the Center, which is not necessarily the institution for the investigator.'\n",
    "df[wa]=df[wa].apply(lambda x: x.replace('This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.',\n",
    "                                       ''))\n",
    "\n",
    "expression=re.compile('This subproject is one of many research subprojects.*not necessarily the institution for the investigator.')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "expression=re.compile('This subproject is one of many research subprojects.*to the subproject or subproject staff.')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_long_phrase(record):\n",
    "    \"\"\" ignores case to remove multi-word phrases in a particular order, especially those likely to run into other words,\n",
    "    e.g. Institution university of washingtonPI mary williams. This doesn't work when titles or insititutions have escape characters in them, which is a bummer\n",
    "    see for example ENHANCING THE USE OF NASA EARTH SCIENCE RESULTS / DATA / AND TECHNOLOGY BY ENGAGING THE FEDERATION OF EARTH SCIENCE INFORMATION PARTNERS COMMUNITIES OF\n",
    "    PRACTICE IN TARGET AREAS OF INTEREST TO NASA THE FEDERATION OF EARTH SCIENCE INFORMATION PARTNERS (''FED\"\"\"\n",
    "    title=record['PROJECT_TITLE']\n",
    "    try:\n",
    "        new_abstract=re.sub(title,'',record[wa],flags=re.IGNORECASE)      \n",
    "        return re.sub(record['ORGANIZATION_NAME'],'',new_abstract,flags=re.IGNORECASE)   \n",
    "    except:\n",
    "        try:\n",
    "            return re.sub(record['ORGANIZATION_NAME'],'',record[wa],flags=re.IGNORECASE)   \n",
    "        except:\n",
    "            return record[wa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[wa]=df.apply(lambda x: remove_long_phrase(x),axis=1)\n",
    "\n",
    "expression=re.compile('Project Summary/Abstract Page.*')\n",
    "\n",
    "def remove_contact_pd(x):\n",
    "    \"\"\"removes clause at end that tends to occur: eg Project Summary/Abstract Page 222Contact PD/PI: Sampson, HughNarrative (\"\"\"\n",
    "    if x.startswith('Contact PD/PI'):\n",
    "        return re.sub(expression,'',x)\n",
    "    else:\n",
    "        return x\n",
    "df[wa]=df[wa].apply(remove_contact_pd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop those that are now length 0 (ie were all punctuation or removable phrases\n",
    "df.drop(list(df[df[wa].apply(lambda x: len(x)==0)].index),inplace=True)\n",
    "df['Start Char']=df[wa].apply(lambda x:x[0])\n",
    "df['LAST_CHAR']=df[wa].apply(lambda x:x[-1])\n",
    "df['nchar']=df[wa].apply(lambda x: len(x))\n",
    "#df.drop(df[df[wa].apply(len)==0].index[0],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####################\n",
    "#Additional expressions we could choose to remove\n",
    "#Identify abstracts with excessive amounts of other fields to uncover additional bad abstract types\n",
    "#If we wanted to be on the safe side, some EDA makes me think we could remove anything with more than 3 or 4 of these fields. It's where they start getting wonky.\n",
    "###################\n",
    "\n",
    "fields=['Principal Investigator','Program Director','Attachment','Instructions','Lines',\n",
    "        'Space Provided','Performance Site','Organization','Key Personnel']\n",
    "all_fields=fields.copy()\n",
    "all_fields.extend([x.lower() for x in fields])\n",
    "all_fields.extend([x.upper() for x in fields])\n",
    "all_fields.extend(['PI','Form','Page','Title','.pdf','.doc'])\n",
    "\n",
    "def count_up_fields(abstract):\n",
    "    count=0\n",
    "    for field in all_fields:\n",
    "        if field in abstract:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "df['Field Count']=df[wa].apply(count_up_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./clean_dataset.pkl\")\n",
    "df.to_csv('./FRAbstractsSqueakyClean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#Additional expressions we could remove, but there is a small possibility of some information being lost\n",
    "##########################\n",
    "\n",
    "#Issues: 'Close FormNextPrint PageAbout OMB Number']#This is usually ended with \"Project summary\", \n",
    "#so anything between those 2 can be delete, and #ended with a clause starting with 'Close FormProject' and ending in'Narrative File'\n",
    "\n",
    "#expression1=re.compile('Close FormNext.*?Project Summary')\n",
    "#expression2=re.compile('Close FormProject.*Narrative File')\n",
    "def fix_abstract(abstract):\n",
    "    if abstract.startswith('Close FormNext'):\n",
    "        abstract=re.sub(expression1,'',abstract)\n",
    "        return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "df[wa]=df[wa].apply(fix_abstract)\n",
    "\n",
    "#If ends in 'Description,', then go to last instance of PERFORMANCE (for Performance SITES), otherwise \"KEY PERSONNEL\", upper case, and cut all that follows\n",
    "\n",
    "#expression1=re.compile('PERFORMANCE.*Description,$')\n",
    "#expression2=re.compile('KEY PERSONNEL.*Description,$')\n",
    "\n",
    "def apply_expressions(abstract):\n",
    "    if abstract.endswith('Description,'):\n",
    "        if re.search(expression1,abstract) != None:\n",
    "            return re.sub(expression1,'',abstract)\n",
    "        else:\n",
    "            return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "    \n",
    "#df[wa]=df[wa].apply(apply_expressions)\n",
    "\n",
    "#expression1=re.compile('PERFORMANCE.*Page 3$')\n",
    "#expression2=re.compile('KEY PERSONNEL.*Page 3,$')\n",
    "\n",
    "def apply_expressions(abstract):\n",
    "    if abstract.endswith('Description,'):\n",
    "        if re.search(expression1,abstract) != None:\n",
    "            return re.sub(expression1,'',abstract)\n",
    "        else:\n",
    "            return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "    \n",
    "#df[wa]=df[wa].apply(apply_expressions)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
