{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('../../data/original/working_federal_reporter_2020.csv',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.reset_index(inplace = True)\n",
    "raw.rename(columns={'index':'original index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy raw into \"df\" object to preserve \"raw\" for comparison later, etc\n",
    "df = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA values in FY.x with FY.y values\n",
    "df['FY.x'] = df['FY.x'].fillna(df['FY.y'])\n",
    "\n",
    "# Rename FY.x to just be \"FY\"\n",
    "df = df.rename(columns={'FY.x': 'FY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Project Start/End Date with Budget Start/End Date\n",
    "df['PROJECT_START_DATE'] = df['PROJECT_START_DATE'].fillna(df['BUDGET_START_DATE'])\n",
    "df['PROJECT_END_DATE'] = df['PROJECT_END_DATE'].fillna(df['BUDGET_END_DATE'])\n",
    "\n",
    "#If START date is still missing, fill with FY\n",
    "df['PROJECT_START_DATE'] = df['PROJECT_START_DATE'].fillna(df['FY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with NULL abstracts\n",
    "df = df[~raw.ABSTRACT.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop abstracts with values of \"ABSTRACT NOT PROVIDED\" and \"No abstract provided \"\n",
    "df = df[df.ABSTRACT != 'ABSTRACT NOT PROVIDED']\n",
    "df = df[df.ABSTRACT != 'No abstract provided']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate counts for unique ORGANIZATION_NAMEs in rows with duplicated Abstract/Title/Project_Start_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group df by abstract/title/start_date (exact matches)\n",
    "all_grp = df.groupby(['ABSTRACT', 'PROJECT_TITLE', 'PROJECT_START_DATE'])\n",
    "\n",
    "# for each unique ABSTRACT/TITLE/START_DATE in df, count unique Organizations\n",
    "unique_all = all_grp.agg({'ORGANIZATION_NAME' : 'nunique'}) \n",
    "\n",
    "#rename column as \"count\" to be different than original column\n",
    "unique_all = unique_all.rename(columns={'ORGANIZATION_NAME': 'ORG_COUNT'})\n",
    "\n",
    "# merge df with \"unique_all\" to bring in the unique Organization counts for each \"duplicate\" group\n",
    "merged1 = df.merge(unique_all, left_on=['ABSTRACT', 'PROJECT_TITLE', 'PROJECT_START_DATE'], right_on=['ABSTRACT', 'PROJECT_TITLE', 'PROJECT_START_DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate counts for unique PIs in rows with duplicated Abstract/Title/Project_Start_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique ABSTRACT/TITLE/START_DATE in whole df, count unique PIs\n",
    "unique_pi = all_grp.agg({'CONTACT_PI_PROJECT_LEADER' : 'nunique'}) \n",
    "\n",
    "#rename column as \"count\" to be different than original column\n",
    "unique_pi = unique_pi.rename(columns={'CONTACT_PI_PROJECT_LEADER': 'PI_COUNT'})\n",
    "\n",
    "# merge data frame with \"unique_all\" to bring in the unique PI counts for each \"duplicate\" group\n",
    "merged2 = merged1.merge(unique_pi, left_on=['ABSTRACT', 'PROJECT_TITLE', 'PROJECT_START_DATE'], right_on=['ABSTRACT', 'PROJECT_TITLE', 'PROJECT_START_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort merged data so that duplicated rows occur in order of earliest to latest END date\n",
    "merged = merged2.sort_values(['PROJECT_END_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save NON-duplicated rows and the LAST occurrance of duplicated rows\n",
    "dedup = merged[~merged.duplicated(subset=['ABSTRACT',  'PROJECT_TITLE', 'PROJECT_START_DATE'], keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save final (deduplicated) dataframe as \"df\" to fit downstream code\n",
    "df = dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
