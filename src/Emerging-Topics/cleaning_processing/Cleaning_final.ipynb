{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning/Processing our dataset - part 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1156137, 26)\n"
     ]
    }
   ],
   "source": [
    "# reading in raw data\n",
    "\n",
    "# set data types\n",
    "cols = ['PROJECT_ID', 'ABSTRACT', 'FY.x', 'PROJECT_TERMS', 'PROJECT_TITLE', 'DEPARTMENT', 'AGENCY', 'IC_CENTER', \n",
    "        'PROJECT_NUMBER', 'PROJECT_START_DATE', 'PROJECT_END_DATE', 'CONTACT_PI_PROJECT_LEADER', 'OTHER_PIS', \n",
    "        'CONGRESSIONAL_DISTRICT', 'DUNS_NUMBER', 'ORGANIZATION_NAME', 'ORGANIZATION_CITY', 'ORGANIZATION_STATE', \n",
    "        'ORGANIZATION_ZIP', 'ORGANIZATION_COUNTRY', 'BUDGET_START_DATE', 'BUDGET_END_DATE', 'CFDA_CODE', 'FY.y', \n",
    "        'FY_TOTAL_COST', 'FY_TOTAL_COST_SUB_PROJECTS']\n",
    "dtypes = {col: 'str' for col in cols}\n",
    "dtypes[\"FY_TOTAL_COST\"] = 'float'\n",
    "dtypes[\"FY_TOTAL_COST_SUB_PROJECTS\"] = 'float'\n",
    "\n",
    "df = pd.read_csv('../../data/original/working_federal_reporter_2020.csv', dtype = dtypes, engine='python')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>FY.x</th>\n",
       "      <th>PROJECT_TERMS</th>\n",
       "      <th>PROJECT_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>AGENCY</th>\n",
       "      <th>IC_CENTER</th>\n",
       "      <th>PROJECT_NUMBER</th>\n",
       "      <th>PROJECT_START_DATE</th>\n",
       "      <th>PROJECT_END_DATE</th>\n",
       "      <th>CONTACT_PI_PROJECT_LEADER</th>\n",
       "      <th>OTHER_PIS</th>\n",
       "      <th>CONGRESSIONAL_DISTRICT</th>\n",
       "      <th>DUNS_NUMBER</th>\n",
       "      <th>ORGANIZATION_NAME</th>\n",
       "      <th>ORGANIZATION_CITY</th>\n",
       "      <th>ORGANIZATION_STATE</th>\n",
       "      <th>ORGANIZATION_ZIP</th>\n",
       "      <th>ORGANIZATION_COUNTRY</th>\n",
       "      <th>BUDGET_START_DATE</th>\n",
       "      <th>BUDGET_END_DATE</th>\n",
       "      <th>CFDA_CODE</th>\n",
       "      <th>FY.y</th>\n",
       "      <th>FY_TOTAL_COST</th>\n",
       "      <th>FY_TOTAL_COST_SUB_PROJECTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89996</td>\n",
       "      <td>This is a project to explore Game-based, Metap...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Achievement; analog; base; Cognitive Science; ...</td>\n",
       "      <td>RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0814512</td>\n",
       "      <td>9/15/2008</td>\n",
       "      <td>8/31/2012</td>\n",
       "      <td>REESE, DEBBIE D</td>\n",
       "      <td>CARTER, BEVERLY; WOOD, CHARLES; HITT, BEN</td>\n",
       "      <td>01</td>\n",
       "      <td>068719400</td>\n",
       "      <td>WHEELING JESUIT UNIVERSITY</td>\n",
       "      <td>WHEELING</td>\n",
       "      <td>WV</td>\n",
       "      <td>26003-6243</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008</td>\n",
       "      <td>1999467.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89997</td>\n",
       "      <td>Institution: Franklin Institute Science Museum...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Active Learning; Child; Computer software; des...</td>\n",
       "      <td>ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0741659</td>\n",
       "      <td>9/15/2008</td>\n",
       "      <td>8/31/2012</td>\n",
       "      <td>SNYDER, STEVEN</td>\n",
       "      <td>ELINICH, KAREN; YOON, SUSAN</td>\n",
       "      <td>02</td>\n",
       "      <td>001741859</td>\n",
       "      <td>FRANKLIN INSTITUTE</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>19103-1115</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008</td>\n",
       "      <td>1799699.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89998</td>\n",
       "      <td>Through programs (including small group conver...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Address; Age; Birth; Brain; Caregivers; Child;...</td>\n",
       "      <td>BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0813522</td>\n",
       "      <td>9/15/2008</td>\n",
       "      <td>8/31/2011</td>\n",
       "      <td>FINK, LAURIE KLEINBAUM</td>\n",
       "      <td>CADIGAN, KAREN; ELLENBOGEN, KIRSTEN</td>\n",
       "      <td>04</td>\n",
       "      <td>061451670</td>\n",
       "      <td>SCIENCE MUSEUM OF MINNESOTA</td>\n",
       "      <td>SAINT PAUL</td>\n",
       "      <td>MN</td>\n",
       "      <td>55102-1202</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.076</td>\n",
       "      <td>2008</td>\n",
       "      <td>1505858.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89999</td>\n",
       "      <td>In partnership with the American Chemical Soci...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Advanced Development; American; Chemicals; Che...</td>\n",
       "      <td>FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0838627</td>\n",
       "      <td>8/1/2008</td>\n",
       "      <td>12/31/2010</td>\n",
       "      <td>JOST, JOHN W</td>\n",
       "      <td>MILLER, BRADLEY; BOWMAN, KATHERINE</td>\n",
       "      <td>04</td>\n",
       "      <td>009059242</td>\n",
       "      <td>INTERNATIONAL UNION OF PURE AND APPLIED CHEMISTRY</td>\n",
       "      <td>DURHAM</td>\n",
       "      <td>NC</td>\n",
       "      <td>27709-3757</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.049</td>\n",
       "      <td>2008</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90000</td>\n",
       "      <td>Amphibian populations around the world are exp...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Amphibia; Central America; Communicable Diseas...</td>\n",
       "      <td>COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0815315</td>\n",
       "      <td>10/1/2008</td>\n",
       "      <td>9/30/2011</td>\n",
       "      <td>ZAMUDIO, KELLY R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>872612445</td>\n",
       "      <td>CORNELL UNIVERSITY ITHACA</td>\n",
       "      <td>ITHACA</td>\n",
       "      <td>NY</td>\n",
       "      <td>14850-2820</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.074</td>\n",
       "      <td>2008</td>\n",
       "      <td>370996.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PROJECT_ID                                           ABSTRACT  FY.x  \\\n",
       "0      89996  This is a project to explore Game-based, Metap...  2008   \n",
       "1      89997  Institution: Franklin Institute Science Museum...  2008   \n",
       "2      89998  Through programs (including small group conver...  2008   \n",
       "3      89999  In partnership with the American Chemical Soci...  2008   \n",
       "4      90000  Amphibian populations around the world are exp...  2008   \n",
       "\n",
       "                                       PROJECT_TERMS  \\\n",
       "0  Achievement; analog; base; Cognitive Science; ...   \n",
       "1  Active Learning; Child; Computer software; des...   \n",
       "2  Address; Age; Birth; Brain; Caregivers; Child;...   \n",
       "3  Advanced Development; American; Chemicals; Che...   \n",
       "4  Amphibia; Central America; Communicable Diseas...   \n",
       "\n",
       "                                       PROJECT_TITLE DEPARTMENT AGENCY  \\\n",
       "0  RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...        NSF    NSF   \n",
       "1  ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...        NSF    NSF   \n",
       "2  BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...        NSF    NSF   \n",
       "3  FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...        NSF    NSF   \n",
       "4  COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...        NSF    NSF   \n",
       "\n",
       "  IC_CENTER PROJECT_NUMBER PROJECT_START_DATE PROJECT_END_DATE  \\\n",
       "0       NaN        0814512          9/15/2008        8/31/2012   \n",
       "1       NaN        0741659          9/15/2008        8/31/2012   \n",
       "2       NaN        0813522          9/15/2008        8/31/2011   \n",
       "3       NaN        0838627           8/1/2008       12/31/2010   \n",
       "4       NaN        0815315          10/1/2008        9/30/2011   \n",
       "\n",
       "  CONTACT_PI_PROJECT_LEADER                                  OTHER_PIS  \\\n",
       "0           REESE, DEBBIE D  CARTER, BEVERLY; WOOD, CHARLES; HITT, BEN   \n",
       "1            SNYDER, STEVEN                ELINICH, KAREN; YOON, SUSAN   \n",
       "2    FINK, LAURIE KLEINBAUM        CADIGAN, KAREN; ELLENBOGEN, KIRSTEN   \n",
       "3              JOST, JOHN W         MILLER, BRADLEY; BOWMAN, KATHERINE   \n",
       "4          ZAMUDIO, KELLY R                                        NaN   \n",
       "\n",
       "  CONGRESSIONAL_DISTRICT DUNS_NUMBER  \\\n",
       "0                     01   068719400   \n",
       "1                     02   001741859   \n",
       "2                     04   061451670   \n",
       "3                     04   009059242   \n",
       "4                     22   872612445   \n",
       "\n",
       "                                   ORGANIZATION_NAME ORGANIZATION_CITY  \\\n",
       "0                         WHEELING JESUIT UNIVERSITY          WHEELING   \n",
       "1                                 FRANKLIN INSTITUTE      PHILADELPHIA   \n",
       "2                        SCIENCE MUSEUM OF MINNESOTA        SAINT PAUL   \n",
       "3  INTERNATIONAL UNION OF PURE AND APPLIED CHEMISTRY            DURHAM   \n",
       "4                          CORNELL UNIVERSITY ITHACA            ITHACA   \n",
       "\n",
       "  ORGANIZATION_STATE ORGANIZATION_ZIP ORGANIZATION_COUNTRY BUDGET_START_DATE  \\\n",
       "0                 WV       26003-6243        UNITED STATES               NaN   \n",
       "1                 PA       19103-1115        UNITED STATES               NaN   \n",
       "2                 MN       55102-1202        UNITED STATES               NaN   \n",
       "3                 NC       27709-3757        UNITED STATES               NaN   \n",
       "4                 NY       14850-2820        UNITED STATES               NaN   \n",
       "\n",
       "  BUDGET_END_DATE CFDA_CODE  FY.y  FY_TOTAL_COST  FY_TOTAL_COST_SUB_PROJECTS  \n",
       "0             NaN    47.076  2008      1999467.0                         NaN  \n",
       "1             NaN    47.076  2008      1799699.0                         NaN  \n",
       "2             NaN    47.076  2008      1505858.0                         NaN  \n",
       "3             NaN    47.049  2008        51000.0                         NaN  \n",
       "4             NaN    47.074  2008       370996.0                         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove null abstracts, fill in missing data, and deal with duplicate abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42380 null ABSTRACTs removed\n"
     ]
    }
   ],
   "source": [
    "#remove rows with NULL abstracts\n",
    "\n",
    "l1 = len(df)\n",
    "df = df[~df.ABSTRACT.isnull()]\n",
    "l2 = len(df)\n",
    "\n",
    "print(l1-l2, \"null ABSTRACTs removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324 ABSTRACT NOT PROVIDED and \"No abstract provided\" removed\n"
     ]
    }
   ],
   "source": [
    "# drop abstracts with values of \"ABSTRACT NOT PROVIDED\" and \"No abstract provided \"\n",
    "\n",
    "l1 = len(df)\n",
    "df = df[df.ABSTRACT != 'ABSTRACT NOT PROVIDED']\n",
    "df = df[df.ABSTRACT != 'No abstract provided']\n",
    "l2 = len(df)\n",
    "\n",
    "print(l1-l2, \"ABSTRACT NOT PROVIDED and \\\"No abstract provided\\\" removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FY.x is the reliable fiscal year information so we rename this column to FY\n",
    "\n",
    "df = df.rename(columns={'FY.x': 'FY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since we are tracking emerging abstract trends**, we will fill in missing information for:  \n",
    "- PROJECT_START_DATE\n",
    "- PROJECT_END_DATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Project Start/End Date with Budget Start/End Date\n",
    "df['PROJECT_START_DATE'] = df['PROJECT_START_DATE'].fillna(df['BUDGET_START_DATE'])\n",
    "df['PROJECT_END_DATE'] = df['PROJECT_END_DATE'].fillna(df['BUDGET_END_DATE'])\n",
    "\n",
    "#df.isnull().sum()\n",
    "\n",
    "#If START date is still missing, fill both start and end date with FY\n",
    "df['PROJECT_START_DATE'] = df['PROJECT_START_DATE'].fillna(df['FY'])\n",
    "df['PROJECT_END_DATE'] = df['PROJECT_END_DATE'].fillna(df['FY'])\n",
    "\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate counts for unique ORGANIZATION_NAMEs in rows with duplicated Abstract/Title/Project_Start_Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group df by abstract/title/start_date (exact matches)\n",
    "all_grp = df.groupby(['ABSTRACT', 'PROJECT_TITLE', 'PROJECT_START_DATE'])\n",
    "\n",
    "# for each unique ABSTRACT/TITLE/START_DATE in df, count unique Organizations\n",
    "unique_all = all_grp.agg({'ORGANIZATION_NAME' : 'nunique'}) \n",
    "\n",
    "#rename column as \"count\" to be different than original column\n",
    "unique_all = unique_all.rename(columns={'ORGANIZATION_NAME': 'ORG_COUNT'})\n",
    "\n",
    "# merge df with \"unique_all\" to bring in the unique Organization counts for each \"duplicate\" group\n",
    "merged1 = df.merge(unique_all, left_on=['ABSTRACT', 'PROJECT_TITLE', 'PROJECT_START_DATE'], \n",
    "                   right_on=['ABSTRACT', 'PROJECT_TITLE', 'PROJECT_START_DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate counts for unique PIs in rows with duplicated Abstract/Title/Project_Start_Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique ABSTRACT/TITLE/START_DATE in whole df, count unique PIs\n",
    "unique_pi = all_grp.agg({'CONTACT_PI_PROJECT_LEADER' : 'nunique'}) \n",
    "\n",
    "#rename column as \"count\" to be different than original column\n",
    "unique_pi = unique_pi.rename(columns={'CONTACT_PI_PROJECT_LEADER': 'PI_COUNT'})\n",
    "\n",
    "# merge data frame with \"unique_all\" to bring in the unique PI counts for each \"duplicate\" group\n",
    "merged2 = merged1.merge(unique_pi, left_on=['ABSTRACT', 'PROJECT_TITLE', 'PROJECT_START_DATE'], \n",
    "                        right_on=['ABSTRACT', 'PROJECT_TITLE', 'PROJECT_START_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort merged data so that duplicated rows occur in order of earliest to latest END date\n",
    "merged = merged2.sort_values(['PROJECT_END_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save NON-duplicated rows and the LAST occurrance of duplicated rows\n",
    "dedup = merged[~merged.duplicated(subset=['ABSTRACT',  'PROJECT_TITLE', 'PROJECT_START_DATE'], keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save final (deduplicated) dataframe as \"df\" to fit downstream code\n",
    "df = dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698600"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper function used throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empties(df, col):\n",
    "    \n",
    "    l1 = len(df)\n",
    "    ix = df[df[col].apply(len)==0].index\n",
    "    print(ix)\n",
    "    df.drop(ix,axis=0,inplace=True)\n",
    "    l2 = len(df)\n",
    "    \n",
    "    print(f\"dropped {l1-l2}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "dropped 0\n"
     ]
    }
   ],
   "source": [
    "# strip leading and trailing whitespace, save in a working abstract column that will be updated as text is cleaned\n",
    "\n",
    "# Note: we cannot lower case abstracts up front - capitalization is needed to find POS in preprocessing\n",
    " \n",
    "df = df.assign(working_abstract = [abstract.strip() for abstract in df[\"ABSTRACT\"]])\n",
    "df = drop_empties(df, \"working_abstract\")\n",
    "\n",
    "wa = 'working_abstract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(Start_Char = df['working_abstract'].apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2414 short abstracts removed\n"
     ]
    }
   ],
   "source": [
    "def remove_short_abstracts(df, limit):\n",
    "\n",
    "    # Remove abstracts with length < limit. 150 seems like a good cutoff, but it does lose some useful information.\n",
    "    \n",
    "    # what do we want to do for the cutoff?  -- SOLUTION UNTIL FURTHER EXPLORATION -> keep the same\n",
    "    \n",
    "    df['nchar']=df['working_abstract'].apply(len)\n",
    "    l1 = len(df)\n",
    "    df=df.loc[df['nchar']>=limit]\n",
    "    l2 = len(df)\n",
    "    \n",
    "    print(l1-l2, \"short abstracts removed\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = remove_short_abstracts(df,limit=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Strategy:\n",
    "1. Remove abstracts with all non-alphanumeric characters.\n",
    "2. Remove non-alphanumeric characters from the start and end of abstracts\n",
    "3. Remove other non-readable abstracts. (REMOVAL ABSTRACTS FOUND BY INSPECTION)\n",
    "4. Remove \"junk\" starting strings and ending strings\n",
    "5. Remove \"junk\" strings in the middle \n",
    "6. Remove title and organization name from abstracts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_nonalnum(word):\n",
    "    \n",
    "    # function strips non-alphanumeric characters from the beginning and end of a string\n",
    "    # adapted from: https://stackoverflow.com/questions/22650506/how-to-rermove-non-alphanumeric-characters-at-the-beginning-or-end-of-a-string\n",
    "        \n",
    "    if not word:\n",
    "        return word  # nothing to strip\n",
    "    if (len(word) == 1) and (not word[0].isalnum()):  \n",
    "        return \"\"\n",
    "    for start, c in enumerate(word):\n",
    "        if c.isalnum():\n",
    "            break\n",
    "    for end, c in enumerate(word[::-1]):\n",
    "        if c.isalnum():\n",
    "            break\n",
    "                  \n",
    "    return word[start:len(word) - end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_phrase(x, phrase,loc='Start'):\n",
    "    \n",
    "    # returns x with phrase removed. location can be \"Start\" of string, \"End\" of string, or \n",
    "    # \"Anywhere_All\"--anywhere will remove all instances and Anywhere_First will remove the first instance\n",
    "    # CASE info - this function assumes phrase is lower case, but that x is not.\n",
    "    \n",
    "    assert loc in ['Start','End']\n",
    "    \n",
    "    if loc=='End':\n",
    "        if x.lower().endswith(phrase):\n",
    "            return x[:-1*len(phrase)].strip()\n",
    "        else:\n",
    "            return x\n",
    "    elif loc=='Start':\n",
    "        if x.lower().startswith(phrase):\n",
    "            return x[len(phrase):].strip()\n",
    "        else:\n",
    "            return x\n",
    "    else:\n",
    "        return 'Error'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([179023, 738276, 835501], dtype='int64')\n",
      "dropped 3\n"
     ]
    }
   ],
   "source": [
    "# strip non-alphanum characters from the beginning and end of each abstract\n",
    "\n",
    "temp = [strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = df.assign(working_abstract = temp)\n",
    "\n",
    "df = drop_empties(df, \"working_abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove abstracts that are not readable: THIS NEEDS TO BE UPDATED BY HAND FOR EVERY NEW DATASET\n",
    "# For example: index = 490684: ¢ £/¥ ƒ § ¤ ƒ “ ƒ « ...\n",
    "\n",
    "df = df.assign(Start_Char = df['working_abstract'].apply(lambda x: x[0]))\n",
    "ix = df[df['Start_Char'] == 'ƒ'].index\n",
    "df.drop(index = ix, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"junk\" phrases at start to remove\n",
    "\n",
    "start_phrases=['abstract', 'summary', 'proposal', 'description', 'narrative', \n",
    "               'technical abstract',\n",
    "               'non technical abstract', \n",
    "               'non- technical abstract',\n",
    "               'non-technical abstract',                      \n",
    "               'nontechnical abstract',\n",
    "               'technical summary', \n",
    "               'nontechnical summary',\n",
    "               'non-technical summary',\n",
    "               'non-technical description',\n",
    "               'description (provided by the applicant)',\n",
    "               'description (provided by investigator)',  \n",
    "               'description (provided by applicant)',\n",
    "               'project summary/abstract',\n",
    "               'proposal abstract',\n",
    "               'research abstract',\n",
    "               'project summary',\n",
    "               'research summary',\n",
    "               'project description'\n",
    "               'see instructions):',\n",
    "               'for center application (provided by the investigator):',\n",
    "               'objective(s)',      \n",
    "               'exceed the space provided',\n",
    "               'provided by applicant',\n",
    "               'provided by candidate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "dropped 0\n"
     ]
    }
   ],
   "source": [
    "#Remove found start phrases\n",
    "\n",
    "for phrase in start_phrases:\n",
    "    temp = df[wa].apply(remove_phrase,args=[phrase,'Start'])\n",
    "    df = df.assign(working_abstract = temp) \n",
    "\n",
    "# strip non-alphanum characters from the beginning and end of each abstract\n",
    "\n",
    "temp = [strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = df.assign(working_abstract = temp)\n",
    "\n",
    "df = drop_empties(df, \"working_abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeated start phrase removal in case the order of project summary/abstract varies\n",
    "\n",
    "for phrase in start_phrases:\n",
    "    temp = df[wa].apply(remove_phrase,args=[phrase,'Start'])\n",
    "    df = df.assign(working_abstract = temp)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting_exact_phrases to remove\n",
    "\n",
    "#'This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.'\n",
    "#'This subproject is one of many research subprojects utilizing theresources provided by a Center grant funded by NIH/NCRR. The subproject andinvestigator (PI) may have received primary funding from another NIH source,and thus could be represented in other CRISP entries. The institution listed isfor the Center, which is not necessarily the institution for the investigator.'\n",
    "\n",
    "temp = df[wa].apply(lambda x: x.replace('This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.',\n",
    "                                       ''))\n",
    "df = df.assign(working_abstract = temp) \n",
    "\n",
    "expression=re.compile('This subproject is one of many research subprojects.*not necessarily the institution for the investigator.')\n",
    "temp = df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "df = df.assign(working_abstract = temp)\n",
    "\n",
    "expression=re.compile('This subproject is one of many research subprojects.*to the subproject or subproject staff.')\n",
    "temp = df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "df = df.assign(working_abstract = temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "dropped 0\n"
     ]
    }
   ],
   "source": [
    "# strip non-alphanum characters from the beginning and end of each abstract\n",
    "\n",
    "temp = [strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = df.assign(working_abstract = temp)\n",
    "\n",
    "df = drop_empties(df, \"working_abstract\")\n",
    "\n",
    "# update Start_Char column in df\n",
    "df = df.assign(Start_Char = df['working_abstract'].apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_phrases = ['(end of abstract',\n",
    "               'end of abstract', \n",
    "               '(abstract end',  \n",
    "               '(end of abstract',\n",
    "               '(end 0f abstract',\n",
    "               '(end of absract',\n",
    "               '(abstract below',\n",
    "               '(end of reviewers\\' comment',\n",
    "               '(end abstract',\n",
    "               'performance site ========================================section end',\n",
    "               'key personnel ========================================section end',\n",
    "               '[summary truncated at 7800 characters', \n",
    "               'this award reflects nsf\\'s statutory mission and has been deemed worthy of support through evaluation using the foundation\\'s intellectual merit and broader impacts review criteria',\n",
    "               'project description page 6', 'page 1 of 1', 'project summary/abstract page 6',\n",
    "               'project description page 7', 'project summary/abstract page 7', 'pag 1 o 1', \n",
    "               'page 2 number pages consecutively at the bottom throughout form page 2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "dropped 0\n"
     ]
    }
   ],
   "source": [
    "# end phrase removal\n",
    "\n",
    "for phrase in end_phrases:\n",
    "    temp = df[wa].apply(remove_phrase,args=[phrase,'End'])\n",
    "    df = df.assign(working_abstract = temp) \n",
    "\n",
    "# strip non-alphanum characters from the beginning and end of each abstract\n",
    "\n",
    "temp = [strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = df.assign(working_abstract = temp)\n",
    "\n",
    "df = drop_empties(df, \"working_abstract\")\n",
    "    \n",
    "# update Last Char column in df\n",
    "df = df.assign(LAST_CHAR = df['working_abstract'].apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"junk\" removal within text body - not necessarily at the start or end\n",
    "\n",
    "# 'Enter the text here that' ending with 'lines of text.'\n",
    "expression=re.compile('Enter the text here that.*lines of text')\n",
    "temp=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "df = df.assign(working_abstract = temp)\n",
    "\n",
    "expression=re.compile('PHS .*?Continuation Format Page')\n",
    "temp=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "df = df.assign(working_abstract = temp)\n",
    "\n",
    "expression=re.compile('OMB No .*?Continuation Format Page')\n",
    "temp=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "df = df.assign(working_abstract = temp)\n",
    "\n",
    "temp=df[wa].replace('Project Summary/Abstract','')\n",
    "df = df.assign(working_abstract = temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"If it starts with 'one page and must contain',\n",
    "This is an NIH thing and there aren't that many of them, but come from 3 different cfda\n",
    "it will start with \"one page and must contain a summary of the proposed activity suitable for dissemination to \n",
    "thepublic. It should be a self-contained description of the project and should contain a statement of objectives \n",
    "and methods to be employed. It should be informative to other persons working in the same or related fields and \n",
    "insofar as possible understandable to a technically liter-ate lay reader. This Abstract must not include any \n",
    "proprietary/confidential information.* Please click the add attachment button to complete this entry.\" plus some \n",
    "attachments, which includes tracking number, twice: following the second trackign number, there is a grant number\n",
    "followed by the actual content\" \n",
    "\n",
    "At the end of these files, they all end in 'Project Narrative File'(last instance) followed by more attachments, \n",
    "all of which can be discarded\n",
    "\"\"\"\n",
    "\n",
    "expression1=re.compile('one page and must.*?Tracking Number.*?(Tracking Number)')\n",
    "expression2=re.compile('Project Narrative File.*')\n",
    "\n",
    "def fix_abstract(abstract):\n",
    "    if abstract.startswith('one page and must contain'):\n",
    "        abstract=re.sub(expression1,'',abstract)\n",
    "        return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "\n",
    "temp=df[wa].apply(fix_abstract)\n",
    "df = df.assign(working_abstract = temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal of phrase at end or beginning?\n",
    "\n",
    "expression=re.compile('Project Summary/Abstract Page.*')\n",
    "\n",
    "def remove_contact_pd(x):\n",
    "    \n",
    "    \"\"\"removes clause at end that tends to occur: eg Project Summary/Abstract Page 222Contact PD/PI: Sampson, HughNarrative (\"\"\"\n",
    "    \n",
    "    if x.startswith('Contact PD/PI'):\n",
    "        return re.sub(expression,'',x)\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "temp=df[wa].apply(remove_contact_pd) \n",
    "df = df.assign(working_abstract = temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "dropped 0\n"
     ]
    }
   ],
   "source": [
    "# strip non-alphanum characters from the beginning and end of each abstract\n",
    "\n",
    "temp = [strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = df.assign(working_abstract = temp)\n",
    "\n",
    "df = drop_empties(df, \"working_abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_title_org(record):\n",
    "    \n",
    "    # This function removes project titles and organization names from abstracts\n",
    "    \n",
    "    \"\"\" ignores case to remove multi-word phrases in a particular order, especially those likely to run into other words,\n",
    "    e.g. Institution university of washingtonPI mary williams. This doesn't work when titles or insititutions have escape characters in them, which is a bummer\n",
    "    see for example ENHANCING THE USE OF NASA EARTH SCIENCE RESULTS / DATA / AND TECHNOLOGY BY ENGAGING THE FEDERATION OF EARTH SCIENCE INFORMATION PARTNERS COMMUNITIES OF\n",
    "    PRACTICE IN TARGET AREAS OF INTEREST TO NASA THE FEDERATION OF EARTH SCIENCE INFORMATION PARTNERS (''FED\"\"\"\n",
    "    \n",
    "    title=record['PROJECT_TITLE']\n",
    "    \n",
    "    try:\n",
    "        new_abstract=re.sub(title,'',record[wa],flags=re.IGNORECASE)      \n",
    "        return re.sub(record['ORGANIZATION_NAME'],'',new_abstract,flags=re.IGNORECASE)   \n",
    "    except:\n",
    "        try:\n",
    "            return re.sub(record['ORGANIZATION_NAME'],'',record[wa],flags=re.IGNORECASE)   \n",
    "        except:\n",
    "            return record[wa]\n",
    "        \n",
    "        \n",
    "temp=df.apply(lambda x: remove_title_org(x),axis=1)\n",
    "df = df.assign(working_abstract = temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 12392, 463597, 998105, 828642, 303523,  12493,  11956,  13988,\n",
      "             11786, 503566,\n",
      "            ...\n",
      "            910560, 183650, 386735, 719763, 920987, 301488, 199090, 292405,\n",
      "            909636, 919062],\n",
      "           dtype='int64', length=5327)\n",
      "dropped 5327\n"
     ]
    }
   ],
   "source": [
    "# strip non-alphanum characters from the beginning and end of each abstract\n",
    "\n",
    "temp = [strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = df.assign(working_abstract = temp)\n",
    "\n",
    "df = drop_empties(df, \"working_abstract\")\n",
    "\n",
    "df = df.assign(Start_Char = df[wa].apply(lambda x:x[0]))\n",
    "df = df.assign(LAST_CHAR = df[wa].apply(lambda x:x[-1]))\n",
    "df = df.assign(nchar = df[wa].apply(lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690855"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../../data/working/clean_data_7-20.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
