{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"more\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'ran', 'on', 'Mars', '.']\n",
      "I ran on Mars .\n"
     ]
    }
   ],
   "source": [
    "# Define the sentence to be lemmatized\n",
    "sentence = \"I ran on Mars.\"\n",
    "\n",
    "# Tokenize: Split the sentence into words\n",
    "word_list = nltk.word_tokenize(sentence)\n",
    "print(word_list)\n",
    "\n",
    "# Lemmatize list of words and join\n",
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jumped', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(['jumped']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('jumped-on', 'JJ'), ('Mars', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I jumped-on Mars.\"\n",
    "\n",
    "print(nltk.pos_tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumped\n"
     ]
    }
   ],
   "source": [
    "word = 'jumped'\n",
    "print(lemmatizer.lemmatize(word, get_wordnet_pos(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_wordnet_pos('run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'plant']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I have plants\"\n",
    "print([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STANZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 22:26:56 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "=======================\n",
      "\n",
      "2021-12-17 22:26:56 INFO: Use device: cpu\n",
      "2021-12-17 22:26:56 INFO: Loading: tokenize\n",
      "2021-12-17 22:26:56 INFO: Loading: pos\n",
      "2021-12-17 22:26:58 INFO: Loading: lemma\n",
      "2021-12-17 22:26:58 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en',processors='tokenize,pos,lemma',tokenize_batch_size=500,lemma_batch_size=500,\n",
    "                      use_gpu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_pos_lemma(doc, pretokened=False, keep_numbers=True):\n",
    "    \n",
    "    # This function uses the pipeline to tokenize, find POS, and lemmatize a document\n",
    "    \n",
    "    \"\"\"if pretokened, dont use this function, as it hasnt been adapted for it\"\"\"\n",
    "    \n",
    "    assert not pretokened #If these are already tokened per another pipeline, this function won't work correctly\n",
    "    \n",
    "    new_tokens=[]\n",
    "     \n",
    "    processed=nlp(doc)  # this is the line that does the tokenizing, pos, and lemmatizing\n",
    "    \n",
    "    for sent in processed.sentences:\n",
    "        for word in sent.words:\n",
    "            \n",
    "            #If its a regular noun, verb, adj, or adverb, keep lemmatized form\n",
    "            if word.pos in ['NOUN','VERB','ADJ','ADV']:\n",
    "                new_tokens.append(word.lemma)\n",
    "            \n",
    "            #If you decided to retain numbers, their lemma is kept here. \n",
    "            #Note that number catching isnt perfect by this lemmatizing.\n",
    "            elif word.pos=='NUM' and keep_numbers:\n",
    "                new_tokens.append(word.lemma)\n",
    "            \n",
    "            #Exact phrases are kept here with no attempt at lemmatization: e.g. mars does not become mars, \n",
    "            #and hopefully scientific words e.g. chemicals will be tagged as propn, x, or intj if needed\n",
    "            elif word.pos in ['PROPN','X','INTJ']: \n",
    "                new_tokens.append(word.text)\n",
    "            \n",
    "            #Note that no other tokens are kept        \n",
    "       \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token_pos_lemma(\"I am jumping on Mars.\")\n",
    "wds = token_pos_lemma(\"There is a technology trend to consolidate multiple applications onto a shared hardware platform to reduce the size, weight, power, and cost of real-time systems, such as self-driving vehicles and autonomous robots. Furthermore, modern platforms consist of Central Processing Units (CPUs) and Graphics Processing Units (GPUs) with an increasing number of processing cores that share resources.  Moreover, many current applications, such as artificial intelligence applications, have high computation needs and must execute in parallel to satisfy their real-time constraints. These technology trends demand that real-time systems be able to schedule real-time applications upon the shared multiple parallel resources efficiently.This research will investigate new parallel real-time scheduling frameworks for modern platforms with multiple resources. The scheduling problem is classified into two categories: staged-resources scheduling for alternating usage of different types of resources (e.g., alternatively executing on CPUs and GPUs), and vectorized-resources scheduling for simultaneously using multiple types of resources (e.g., running on processing units that share the last-level cache). The project will establish new parallel real-time task models for the two categories of resource usages. Based on the models, novel real-time schedulers and their corresponding analyses will be developed to achieve the goal of efficient utilization of multiple resources. The project will advance the understanding of parallel scheduling in real-time systems and serves as the initial steps of the challenge of efficient parallel real-time systems upon powerful and complex modern platforms. This project can have industrial impact on a wide range of today's artificial intelligence-based real-time systems to improve their responsiveness, efficiency, and scalability. The project includes enriching outreach activities and diversity programs to promote Science, Technology, Engineering and Mathematics (STEM) educational activity and broaden participation in computing and engineering.  Research products generated as part of this project will be retained, managed, and disseminated through resources available at the New Jersey Institute of Technology. The products will be preserved with the goal of storing them for at least three years after the completion of the project or the publication of the corresponding articles, whichever is later. The URL to the project repository is https://git.njit.edu/njit-prt.This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'technology', 'trend', 'consolidate', 'multiple', 'application', 'share', 'hardware', 'platform', 'reduce', 'size', 'weight', 'power', 'cost', 'real', 'time', 'system', 'such', 'self', 'driving', 'vehicle', 'autonomous', 'robot', 'furthermore', 'modern', 'platform', 'consist', 'Central', 'processing', 'unit', 'cpus', 'graphic', 'processing', 'unit', 'gpus', 'increase', 'number', 'processing', 'core', 'share', 'resource', 'moreover', 'many', 'current', 'application', 'such', 'artificial', 'intelligence', 'application', 'have', 'high', 'computation', 'need', 'execute', 'parallel', 'satisfy', 'real', 'time', 'constraint', 'technology', 'trend', 'demand', 'real', 'time', 'system', 'able', 'schedule', 'real', 'time', 'application', 'share', 'multiple', 'parallel', 'resource', 'efficiently', 'research', 'investigate', 'new', 'parallel', 'real', 'time', 'scheduling', 'framework', 'modern', 'platform', 'multiple', 'resource', 'scheduling', 'problem', 'classify', 'two', 'category', 'stage', 'resource', 'scheduling', 'alternate', 'usage', 'different', 'type', 'resource', 'e.g.', 'alternatively', 'execute', 'cpus', 'gpus', 'vectorize', 'resource', 'scheduling', 'simultaneously', 'use', 'multiple', 'type', 'resource', 'e.g.', 'run', 'processing', 'unit', 'share', 'last', 'level', 'cache', 'project', 'establish', 'new', 'parallel', 'real', 'time', 'task', 'model', 'two', 'category', 'resource', 'usage', 'base', 'model', 'novel', 'real', 'time', 'scheduler', 'correspond', 'analysis', 'develop', 'achieve', 'goal', 'efficient', 'utilization', 'multiple', 'resource', 'project', 'advance', 'understanding', 'parallel', 'scheduling', 'real', 'time', 'system', 'serve', 'initial', 'step', 'challenge', 'efficient', 'parallel', 'real', 'time', 'system', 'powerful', 'complex', 'modern', 'platform', 'project', 'have', 'industrial', 'impact', 'wide', 'range', 'today', 'artificial', 'intelligence', 'base', 'real', 'time', 'system', 'improve', 'responsiveness', 'efficiency', 'scalability', 'project', 'include', 'enrich', 'outreach', 'activity', 'diversity', 'program', 'promote', 'science', 'technology', 'engineering', 'Mathematics', 'stem', 'educational', 'activity', 'broad', 'participation', 'computing', 'engineering', 'Research', 'product', 'generate', 'part', 'project', 'retain', 'manage', 'disseminate', 'resource', 'available', 'New', 'Jersey', 'Institute', 'Technology', 'product', 'preserve', 'goal', 'store', 'at', 'least', 'three', 'year', 'completion', 'project', 'publication', 'correspond', 'article', 'later', 'url', 'project', 'repository', 'https://git.njit.edu/njit-prt.This', 'award', 'reflect', 'NSF', 'statutory', 'mission', 'deem', 'worthy', 'support', 'evaluation', 'use', 'Foundation', 'intellectual', 'merit', 'broader', 'impact', 'review', 'criterion']\n"
     ]
    }
   ],
   "source": [
    "print(wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: en-core-web-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (3.0.0)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.6.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: jinja2 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.24.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.50.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: packaging>=20.0 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /sfs/qumulo/qhome/kjl5t/.local/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (5.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: six in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.15.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /sfs/applications/202112/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\n",
    "nlp2 = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['technology', 'trend', 'consolidate', 'multiple', 'application', 'share', 'hardware', 'platform', 'reduce', 'size', 'weight', 'power', 'cost', 'real', 'time', 'system', 'self', 'drive', 'vehicle', 'autonomous', 'robot', 'furthermore', 'modern', 'platform', 'consist', 'Central', 'Processing', 'Units', 'CPUs', 'Graphics', 'Processing', 'Units', 'gpu', 'increase', 'number', 'processing', 'core', 'share', 'resource', 'current', 'application', 'artificial', 'intelligence', 'application', 'high', 'computation', 'need', 'execute', 'parallel', 'satisfy', 'real', 'time', 'constraint', 'technology', 'trend', 'demand', 'real', 'time', 'system', 'able', 'schedule', 'real', 'time', 'application', 'share', 'multiple', 'parallel', 'resource', 'efficiently', 'research', 'investigate', 'new', 'parallel', 'real', 'time', 'scheduling', 'framework', 'modern', 'platform', 'multiple', 'resource', 'scheduling', 'problem', 'classify', 'category', 'stage', 'resource', 'scheduling', 'alternate', 'usage', 'different', 'type', 'resource', 'e.g.', 'alternatively', 'execute', 'cpu', 'GPUs', 'vectorize', 'resource', 'scheduling', 'simultaneously', 'multiple', 'type', 'resource', 'e.g.', 'run', 'processing', 'unit', 'share', 'level', 'cache', 'project', 'establish', 'new', 'parallel', 'real', 'time', 'task', 'model', 'category', 'resource', 'usage', 'base', 'model', 'novel', 'real', 'time', 'scheduler', 'correspond', 'analysis', 'develop', 'achieve', 'goal', 'efficient', 'utilization', 'multiple', 'resource', 'project', 'advance', 'understanding', 'parallel', 'scheduling', 'real', 'time', 'system', 'serve', 'initial', 'step', 'challenge', 'efficient', 'parallel', 'real', 'time', 'system', 'powerful', 'complex', 'modern', 'platform', 'project', 'industrial', 'impact', 'wide', 'range', 'today', 'artificial', 'intelligence', 'base', 'real', 'time', 'system', 'improve', 'responsiveness', 'efficiency', 'scalability', 'project', 'include', 'enrich', 'outreach', 'activity', 'diversity', 'program', 'promote', 'Science', 'Technology', 'Engineering', 'Mathematics', 'STEM', 'educational', 'activity', 'broaden', 'participation', 'computing', 'engineering', 'research', 'product', 'generate', 'project', 'retain', 'manage', 'disseminate', 'resource', 'available', 'New', 'Jersey', 'Institute', 'Technology', 'product', 'preserve', 'goal', 'store', 'year', 'completion', 'project', 'publication', 'correspond', 'article', 'later', 'url', 'project', 'repository', 'https://git.njit.edu/njit-prt.This', 'award', 'reflect', 'NSF', 'statutory', 'mission', 'deem', 'worthy', 'support', 'evaluation', 'Foundation', 'intellectual', 'merit', 'broad', 'impact', 'review', 'criterion']\n"
     ]
    }
   ],
   "source": [
    "#sentence = \"I jumped on Mars.\"\n",
    "sentence = \"There is a technology trend to consolidate multiple applications onto a shared hardware platform to reduce the size, weight, power, and cost of real-time systems, such as self-driving vehicles and autonomous robots. Furthermore, modern platforms consist of Central Processing Units (CPUs) and Graphics Processing Units (GPUs) with an increasing number of processing cores that share resources.  Moreover, many current applications, such as artificial intelligence applications, have high computation needs and must execute in parallel to satisfy their real-time constraints. These technology trends demand that real-time systems be able to schedule real-time applications upon the shared multiple parallel resources efficiently.This research will investigate new parallel real-time scheduling frameworks for modern platforms with multiple resources. The scheduling problem is classified into two categories: staged-resources scheduling for alternating usage of different types of resources (e.g., alternatively executing on CPUs and GPUs), and vectorized-resources scheduling for simultaneously using multiple types of resources (e.g., running on processing units that share the last-level cache). The project will establish new parallel real-time task models for the two categories of resource usages. Based on the models, novel real-time schedulers and their corresponding analyses will be developed to achieve the goal of efficient utilization of multiple resources. The project will advance the understanding of parallel scheduling in real-time systems and serves as the initial steps of the challenge of efficient parallel real-time systems upon powerful and complex modern platforms. This project can have industrial impact on a wide range of today's artificial intelligence-based real-time systems to improve their responsiveness, efficiency, and scalability. The project includes enriching outreach activities and diversity programs to promote Science, Technology, Engineering and Mathematics (STEM) educational activity and broaden participation in computing and engineering.  Research products generated as part of this project will be retained, managed, and disseminated through resources available at the New Jersey Institute of Technology. The products will be preserved with the goal of storing them for at least three years after the completion of the project or the publication of the corresponding articles, whichever is later. The URL to the project repository is https://git.njit.edu/njit-prt.This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.\"\n",
    "\n",
    "# Parse the sentence using the loaded 'en' model object `nlp`\n",
    "doc = nlp2(sentence)\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ in ['NOUN', 'VERB', 'ADJ', 'ADV', 'PROPN', 'INTJ', 'NUM', 'X'] and not token.is_stop:\n",
    "        tokens.append(token.lemma_)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'technology', 'trend', 'consolidate', 'multiple', 'application', 'share', 'hardware', 'platform', 'reduce', 'size', 'weight', 'power', 'cost', 'real', 'time', 'system', 'such', 'self', 'driving', 'vehicle', 'autonomous', 'robot', 'furthermore', 'modern', 'platform', 'consist', 'Central', 'processing', 'unit', 'cpus', 'graphic', 'processing', 'unit', 'gpus', 'increase', 'number', 'processing', 'core', 'share', 'resource', 'moreover', 'many', 'current', 'application', 'such', 'artificial', 'intelligence', 'application', 'have', 'high', 'computation', 'need', 'execute', 'parallel', 'satisfy', 'real', 'time', 'constraint', 'technology', 'trend', 'demand', 'real', 'time', 'system', 'able', 'schedule', 'real', 'time', 'application', 'share', 'multiple', 'parallel', 'resource', 'efficiently', 'research', 'investigate', 'new', 'parallel', 'real', 'time', 'scheduling', 'framework', 'modern', 'platform', 'multiple', 'resource', 'scheduling', 'problem', 'classify', 'two', 'category', 'stage', 'resource', 'scheduling', 'alternate', 'usage', 'different', 'type', 'resource', 'e.g.', 'alternatively', 'execute', 'cpus', 'gpus', 'vectorize', 'resource', 'scheduling', 'simultaneously', 'use', 'multiple', 'type', 'resource', 'e.g.', 'run', 'processing', 'unit', 'share', 'last', 'level', 'cache', 'project', 'establish', 'new', 'parallel', 'real', 'time', 'task', 'model', 'two', 'category', 'resource', 'usage', 'base', 'model', 'novel', 'real', 'time', 'scheduler', 'correspond', 'analysis', 'develop', 'achieve', 'goal', 'efficient', 'utilization', 'multiple', 'resource', 'project', 'advance', 'understanding', 'parallel', 'scheduling', 'real', 'time', 'system', 'serve', 'initial', 'step', 'challenge', 'efficient', 'parallel', 'real', 'time', 'system', 'powerful', 'complex', 'modern', 'platform', 'project', 'have', 'industrial', 'impact', 'wide', 'range', 'today', 'artificial', 'intelligence', 'base', 'real', 'time', 'system', 'improve', 'responsiveness', 'efficiency', 'scalability', 'project', 'include', 'enrich', 'outreach', 'activity', 'diversity', 'program', 'promote', 'science', 'technology', 'engineering', 'Mathematics', 'stem', 'educational', 'activity', 'broad', 'participation', 'computing', 'engineering', 'Research', 'product', 'generate', 'part', 'project', 'retain', 'manage', 'disseminate', 'resource', 'available', 'New', 'Jersey', 'Institute', 'Technology', 'product', 'preserve', 'goal', 'store', 'at', 'least', 'three', 'year', 'completion', 'project', 'publication', 'correspond', 'article', 'later', 'url', 'project', 'repository', 'https://git.njit.edu/njit-prt.This', 'award', 'reflect', 'NSF', 'statutory', 'mission', 'deem', 'worthy', 'support', 'evaluation', 'use', 'Foundation', 'intellectual', 'merit', 'broader', 'impact', 'review', 'criterion']\n"
     ]
    }
   ],
   "source": [
    "print(wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp2(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "datum\n",
      "NOUN\n",
      "NNS\n",
      "\n",
      "xxxx\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(doc[i].text)\n",
    "print(doc[i].lemma_)\n",
    "print(doc[i].pos_)\n",
    "print(doc[i].tag_)\n",
    "print(doc[i].dep_)\n",
    "print(doc[i].shape_)\n",
    "print(doc[i].is_alpha)\n",
    "print(doc[i].is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'VERB' in ['NOUN', 'VERB', 'ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CPUs',\n",
       " 'Engineering',\n",
       " 'GPUs',\n",
       " 'Graphics',\n",
       " 'Processing',\n",
       " 'STEM',\n",
       " 'Science',\n",
       " 'Units',\n",
       " 'broaden',\n",
       " 'cpu',\n",
       " 'drive',\n",
       " 'gpu'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tokens) - set(wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Research',\n",
       " 'at',\n",
       " 'be',\n",
       " 'broader',\n",
       " 'cpus',\n",
       " 'driving',\n",
       " 'gpus',\n",
       " 'graphic',\n",
       " 'have',\n",
       " 'last',\n",
       " 'least',\n",
       " 'many',\n",
       " 'moreover',\n",
       " 'part',\n",
       " 'science',\n",
       " 'stem',\n",
       " 'such',\n",
       " 'three',\n",
       " 'two',\n",
       " 'use'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(wds) - set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beforehand', 'four', 'all', 'indeed', 'from', 'very', '’ll', '’ve', '’re', 'wherever', 'another', 'i', 'then', 'alone', 'already', 'take', 'none', 'whether', 'whole', 'elsewhere', 'he', 'beside', 'somewhere', 'its', 'nothing', 'at', 'around', 'eight', 'their', 'latterly', 'down', 'during', 'go', 'only', 'nor', 'did', 'of', 'being', 'becoming', 'never', 'fifteen', 'per', 'together', 'ca', 'above', 'say', 'neither', 'various', 'too', 'seems', 'should', 'when', 'yet', 'really', 'six', 'via', 'you', 'somehow', 'itself', 'formerly', 'used', 'her', 'still', 'much', 'whither', 'your', 'if', 'move', 'whose', 'serious', 'bottom', '‘ll', 'most', 'towards', 'every', 'afterwards', 'may', \"n't\", 'before', 'just', 'hereupon', 'hereafter', 'each', 'out', 'us', 'twenty', 'thus', 'either', 'moreover', 'also', 'everyone', 'now', 'seem', 'along', 'has', '‘m', 'be', 'see', 'so', 'off', 'his', 'or', 'these', 'here', 'the', 'any', 'two', 'though', 'empty', 'wherein', 'full', 'behind', 'almost', 'although', 'regarding', 'sometimes', 'one', 'we', 'yourself', 'further', 'make', 'it', 'that', 'does', 'him', 'through', 'therein', '’m', 'therefore', 'same', 'always', 'everywhere', 'someone', 'onto', 'ourselves', 'seeming', 'against', 'why', 'whatever', 'call', 'as', 'but', 'which', \"'s\", 'because', 'besides', 'been', 'whence', 'hundred', 'up', 'however', \"'re\", \"'ll\", 'else', 'amongst', 'hence', 'how', 'after', 'themselves', 'are', 'amount', 'had', 'below', 'do', 'might', 'get', 'please', 'than', 'fifty', 'is', 'whom', 'a', 'thereafter', 'often', 'mine', 'next', 'them', 'thereupon', 'give', 'both', 'our', 'put', '’d', 'first', 'and', 'nevertheless', '‘s', 'eleven', 'least', 'they', 'part', 'others', 'myself', 'nowhere', 'those', 'enough', 'about', 'few', 'three', 'own', 'whenever', 're', 'whereby', 'ever', 'anything', 'n‘t', 'became', 'former', 'hers', '’s', 'whereafter', 'since', 'yourselves', 'me', 'herself', 'cannot', \"'d\", 'what', '‘re', 'forty', 'not', 'hereby', 'whereas', 'sometime', 'while', 'namely', 'mostly', 'twelve', 'except', 'my', 'am', 'himself', 'to', 'quite', 'between', 'done', 'herein', '‘d', 'front', \"'m\", 'anyhow', 'no', 'was', 'name', 'on', 'ten', 'throughout', 'where', 'several', 'such', 'many', 'anyone', 'ours', 'some', 'for', 'become', 'have', 'five', 'thereby', 'anywhere', 'must', 'everything', 'whoever', 'even', 'over', 'keep', 'otherwise', 'across', 'again', 'once', 'can', 'into', '‘ve', 'thru', 'in', 'by', 'an', 'meanwhile', 'could', 'within', 'toward', 'anyway', 'this', 'more', 'rather', 'latter', 'without', 'upon', 'beyond', 'well', 'nobody', 'n’t', 'due', 'third', 'perhaps', 'were', 'top', 'there', 'made', 'nine', 'becomes', 'who', 'will', 'last', 'under', 'with', 'doing', 'until', 'unless', 'using', 'less', 'whereupon', \"'ve\", 'seemed', 'noone', 'thence', 'show', 'among', 'side', 'back', 'other', 'something', 'yours', 'she', 'would', 'sixty'}\n"
     ]
    }
   ],
   "source": [
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKE AWAY - USE SPACY!!  \n",
    "\n",
    "# will tokenize, pos, lemmatize, remove stop words all in one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
